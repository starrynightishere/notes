\documentclass[12pt,a4paper]{article}

% ================== Packages ==================
\usepackage{amsmath,amssymb}
\usepackage{geometry}
\usepackage{setspace}
\usepackage{bm}
\usepackage{hyperref}
\usepackage{physics}

\geometry{margin=1in}
\onehalfspacing

\begin{document}

\begin{center}
    {\Large \textbf{Chapter 1: The Language of Motion}}
\end{center}

\vspace{1em}

\section*{Why this chapter exists}

Before we talk about:
\begin{itemize}
    \item waves,
    \item forces,
    \item stress,
    \item matrices,
    \item or inversion,
\end{itemize}
we must first answer a very simple question:

\begin{quote}
\textbf{What does it mean to say that something moves?}
\end{quote}

If we cannot answer this clearly, then every equation later will feel mysterious.

This chapter introduces the \emph{language} used to describe motion in solids.
Nothing else.


\section{From Everyday Motion to Mathematical Description}

\subsection{How we normally think about motion}

In everyday life, when we say something moves, we usually mean:
\begin{itemize}
    \item its position changes with time,
    \item we can point to where it was and where it is now.
\end{itemize}

For example:
\begin{itemize}
    \item a car moves along a road,
    \item a ball falls through the air.
\end{itemize}

In these cases, we track \emph{objects}.

But the Earth is not one object.


\subsection{Why the Earth is different}

The Earth is made of:
\begin{itemize}
    \item an enormous number of particles,
    \item tightly packed together,
    \item interacting with their neighbors.
\end{itemize}

When seismic waves travel:
\begin{itemize}
    \item no single particle travels far,
    \item instead, particles oscillate about their original positions.
\end{itemize}

So we do not track particles.
We track \emph{motion of matter itself}.


\section{The Continuum Idea}

\subsection{Why we cannot track atoms}

At microscopic scales, matter is made of atoms.
But seismic waves have:
\begin{itemize}
    \item wavelengths from meters to kilometers,
    \item frequencies of a few Hz to tens of Hz.
\end{itemize}

At these scales:
\begin{itemize}
    \item individual atoms are invisible,
    \item tracking them would be impossible.
\end{itemize}

So we introduce a modeling idea.


\subsection{The continuum hypothesis}

\textbf{Continuum hypothesis:}

\begin{quote}
Matter is treated as continuously distributed in space, so that physical quantities vary smoothly and can be differentiated.
\end{quote}

This means:
\begin{itemize}
    \item we pretend matter fills space without gaps,
    \item we ignore atomic structure,
    \item we describe motion using smooth functions.
\end{itemize}

This assumption is not careless.
It is what makes calculus possible.


\section{Material Points}

\subsection{What is a material point?}

A \textbf{material point} is:
\begin{itemize}
    \item a very small piece of matter,
    \item small enough to be considered a point,
    \item large enough to contain many atoms.
\end{itemize}

Each material point represents a tiny volume of the Earth.


\subsection{Labeling material points}

To describe motion, we must label material points.

We choose their positions in an undeformed, reference state:
\begin{equation}
\bm{x} = (x,y,z)
\end{equation}

This vector is a \emph{label}, not a variable that moves with time.

This is extremely important.


\section{Reference Configuration}

\subsection{The idea of a reference state}

Imagine the Earth at rest, before any waves pass.

This imagined state is called the \textbf{reference configuration}.

In this configuration:
\begin{itemize}
    \item every material point has a fixed label $\bm{x}$,
    \item distances and shapes are known.
\end{itemize}

We never lose this reference.
All motion is described relative to it.


\subsection{Why this is powerful}

By fixing labels:
\begin{itemize}
    \item we always know which piece of matter we are talking about,
    \item boundary conditions become clear,
    \item conservation laws are easier to write.
\end{itemize}

This point of view is called the \textbf{Lagrangian description}.


\section{The Displacement Field}

\subsection{Definition}

When the Earth deforms, material points move.

We describe this motion using the \textbf{displacement field}:
\begin{equation}
\boxed{
\bm{u}(\bm{x},t)
=
\begin{bmatrix}
u_x(\bm{x},t) \\
u_y(\bm{x},t) \\
u_z(\bm{x},t)
\end{bmatrix}
}
\end{equation}

This is the most important quantity in elasticity.


\subsection{What displacement means}

If a material point was originally at $\bm{x}$, then at time $t$ it is located at:
\begin{equation}
\bm{x}_{\text{current}} = \bm{x} + \bm{u}(\bm{x},t)
\end{equation}

Important:
\begin{itemize}
    \item $\bm{x}$ identifies the point,
    \item $\bm{u}$ tells us how far it moved.
\end{itemize}


\section{Why Displacement Comes First}

\subsection{Why not velocity?}

Velocity is the time derivative of displacement:
\[
\bm{v} = \frac{\partial \bm{u}}{\partial t}
\]

Velocity tells us how fast a point moves.

But it does not tell us:
\begin{itemize}
    \item whether distances change,
    \item whether the body stretches or shears.
\end{itemize}

Deformation is about \emph{relative motion}, not speed.


\subsection{Why not force?}

Forces cause motion, but:
\begin{itemize}
    \item forces depend on deformation,
    \item deformation depends on displacement.
\end{itemize}

So displacement comes first.


\section{Why Spatial Derivatives Matter}

\subsection{Relative motion of neighboring points}

Consider two nearby material points:
\[
\bm{x}
\quad \text{and} \quad
\bm{x} + d\bm{x}
\]

Their displacements are:
\[
\bm{u}(\bm{x},t),
\quad
\bm{u}(\bm{x}+d\bm{x},t)
\]

The difference in displacement is:
\begin{equation}
d\bm{u}
=
\bm{u}(\bm{x}+d\bm{x},t) - \bm{u}(\bm{x},t)
\end{equation}

Using Taylor expansion:
\begin{equation}
\boxed{
d\bm{u}
=
\frac{\partial u_i}{\partial x_j} dx_j
}
\end{equation}

This gradient measures how neighboring points separate or slide.


\section{Rigid Motion vs Deformation}

\subsection{Rigid translation}

If:
\[
\bm{u}(\bm{x},t) = \bm{c}(t)
\]

Then:
\begin{itemize}
    \item every point moves the same amount,
    \item distances do not change,
    \item no deformation occurs.
\end{itemize}


\subsection{Rigid rotation}

If:
\[
\bm{u}(\bm{x},t) = \bm{\Omega}(t) \times \bm{x}
\]

Then:
\begin{itemize}
    \item the body rotates,
    \item shapes remain unchanged,
    \item again, no deformation occurs.
\end{itemize}


\section{What We Have and Have Not Done}

At this point:
\begin{itemize}
    \item We have \textbf{not} introduced forces,
    \item We have \textbf{not} introduced stress,
    \item We have \textbf{not} introduced waves.
\end{itemize}

What we \emph{have} done is more important:

\begin{quote}
We have defined the mathematical language needed to describe motion in solids.
\end{quote}


\section*{Summary of Chapter 1}

You should now be comfortable with:
\begin{itemize}
    \item the continuum hypothesis,
    \item material points,
    \item reference configuration,
    \item displacement as the fundamental unknown,
    \item why spatial derivatives appear.
\end{itemize}

This foundation will never change.

\pagebreak
\begin{center}
    {\Large \textbf{Chapter 2: Strain — Measuring Deformation}}
\end{center}

\vspace{1em}

\section*{Why this chapter exists}

In Chapter 1, we learned how to \emph{describe motion} using the displacement field
\[
\bm{u}(\bm{x},t).
\]

But motion alone is not deformation.

This chapter answers a very precise question:

\begin{quote}
\textbf{How do we mathematically measure changes in shape and size?}
\end{quote}

The answer is \textbf{strain}.



\section{What Do We Mean by Deformation?}

\subsection{An everyday picture}

Imagine drawing a small square on a rubber sheet.

Now:
\begin{itemize}
    \item stretch the sheet,
    \item shear it sideways,
    \item compress it.
\end{itemize}

The square may:
\begin{itemize}
    \item become longer,
    \item tilt into a parallelogram,
    \item change area.
\end{itemize}

All of these are \emph{deformations}.

But if you simply:
\begin{itemize}
    \item move the sheet,
    \item rotate it,
\end{itemize}
the square does not change shape.

So deformation is about \emph{relative change}, not motion.



\section{From Displacement to Deformation}

\subsection{Neighboring material points}

Recall from Chapter 1:

Two nearby material points are labeled by:
\[
\bm{x}
\quad \text{and} \quad
\bm{x} + d\bm{x}.
\]

Their displacements are:
\[
\bm{u}(\bm{x},t),
\quad
\bm{u}(\bm{x}+d\bm{x},t).
\]

The difference is:
\[
d\bm{u}
=
\bm{u}(\bm{x}+d\bm{x},t) - \bm{u}(\bm{x},t).
\]

This difference tells us how the distance between points changes.



\subsection{Taylor expansion (no fear)}

Because $\bm{u}$ is a smooth function, we expand:
\[
\bm{u}(\bm{x}+d\bm{x},t)
=
\bm{u}(\bm{x},t)
+
\frac{\partial u_i}{\partial x_j} dx_j
+
\text{higher-order terms}.
\]

For small deformations, we neglect higher-order terms and obtain:
\[
\boxed{
d\bm{u}
=
\frac{\partial u_i}{\partial x_j} dx_j
}
\]

This object, $\partial u_i/\partial x_j$, is called the
\textbf{displacement gradient}.



\section{What the Displacement Gradient Contains}

The displacement gradient includes:
\begin{itemize}
    \item stretching,
    \item shear,
    \item rotation.
\end{itemize}

But rotation is not deformation.

We must separate these effects.



\section{Symmetric and Antisymmetric Parts}

Any matrix can be split as:
\[
A = \frac{1}{2}(A + A^T) + \frac{1}{2}(A - A^T).
\]

We apply this idea to the displacement gradient.



\subsection{Definition of strain}

The \textbf{infinitesimal strain tensor} is defined as the symmetric part:
\[
\boxed{
\varepsilon_{ij}
=
\frac{1}{2}
\left(
\frac{\partial u_i}{\partial x_j}
+
\frac{\partial u_j}{\partial x_i}
\right)
}
\]

This is not an arbitrary definition.
It is the \emph{only linear choice} that removes rigid rotation.



\subsection{Why symmetry removes rotation}

Consider a rigid rotation:
\[
\bm{u} = \bm{\Omega} \times \bm{x}.
\]

Its gradient satisfies:
\[
\frac{\partial u_i}{\partial x_j}
=
- \frac{\partial u_j}{\partial x_i}.
\]

The symmetric part is zero.

Thus:
\begin{quote}
\textbf{Rigid rotation produces zero strain.}
\end{quote}

Exactly what we want.



\section{Physical Meaning of Strain Components}

\subsection{Normal strain}

The diagonal components:
\[
\varepsilon_{xx} = \frac{\partial u_x}{\partial x}, \quad
\varepsilon_{yy}, \quad
\varepsilon_{zz}
\]

measure:
\begin{itemize}
    \item extension if positive,
    \item compression if negative.
\end{itemize}

Example:
If $\varepsilon_{xx} = 0.01$, a length in the $x$ direction increases by 1\%.



\subsection{Shear strain}

The off-diagonal components:
\[
\varepsilon_{xz}
=
\frac{1}{2}
\left(
\frac{\partial u_x}{\partial z}
+
\frac{\partial u_z}{\partial x}
\right)
\]

measure changes in angle between originally perpendicular lines.

Shear strain turns squares into parallelograms.



\section{Why Strain Is a Tensor}

Strain depends on:
\begin{itemize}
    \item direction,
    \item orientation,
    \item coordinate system.
\end{itemize}

It transforms properly under rotation of axes.

Scalars are insufficient.

Vectors are insufficient.

A \textbf{second-order tensor} is required.



\section{Small-Strain Approximation}

The strain definition assumes:
\[
\left| \frac{\partial u_i}{\partial x_j} \right| \ll 1.
\]

This is valid for seismic waves:
\begin{itemize}
    \item particle motions are tiny,
    \item wavelengths are large.
\end{itemize}

This approximation greatly simplifies mathematics without losing accuracy.



\section{What Strain Is Not}

Strain is:
\begin{itemize}
    \item not stress,
    \item not force,
    \item not energy.
\end{itemize}

Strain is \emph{pure geometry}.

It tells us \textbf{how much} a body deforms, not \textbf{why}.

The ``why'' comes next.



\section*{Summary of Chapter 2}

You should now understand:
\begin{itemize}
    \item how deformation is measured,
    \item why strain uses displacement gradients,
    \item why strain is symmetric,
    \item what each strain component means physically.
\end{itemize}

We now have a precise measure of deformation.

What we do \emph{not} yet have is a law connecting deformation to force.
\pagebreak
\begin{center}
    {\Large \textbf{Chapter 3: Stress — How Forces Are Transmitted}}
\end{center}

\vspace{1em}

\section*{Why this chapter exists}

In Chapter 2, we learned how to \emph{measure deformation} using strain.

But deformation does not happen by itself.

Something must:
\begin{itemize}
    \item resist stretching,
    \item resist compression,
    \item resist shear.
\end{itemize}

That ``something'' is \textbf{internal force}.

This chapter introduces the mathematical object that describes how forces are transmitted through a solid: \textbf{stress}.



\section{Forces Inside Matter}

\subsection{External vs internal forces}

We are familiar with external forces:
\begin{itemize}
    \item gravity,
    \item applied loads,
    \item contact forces.
\end{itemize}

But solids also experience \emph{internal} forces:
\begin{itemize}
    \item forces between neighboring material points,
    \item forces that resist deformation.
\end{itemize}

Stress is the way we describe these internal forces.



\section{The Traction Vector}

\subsection{Cutting the body (thought experiment)}

Imagine cutting the solid along an imaginary surface.

The two sides of the cut exert forces on each other.

We ask:
\begin{quote}
\emph{What is the force per unit area acting across this surface?}
\end{quote}

This quantity is called the \textbf{traction}.



\subsection{Definition of traction}

Let:
\begin{itemize}
    \item $dA$ be a small surface area,
    \item $\bm{n}$ be the unit normal to the surface.
\end{itemize}

The traction vector $\bm{t}$ is defined by:
\[
\boxed{
\bm{t}(\bm{n})
=
\lim_{dA \to 0}
\frac{\text{Force on } dA}{dA}
}
\]

Traction has units of force per area.



\section{Why Stress Must Be a Tensor}

\subsection{Dependence on direction}

The traction depends on:
\begin{itemize}
    \item the location in the body,
    \item the orientation of the surface (the normal $\bm{n}$).
\end{itemize}

A single vector is not enough.

We need an object that maps:
\[
\text{surface normal} \;\longrightarrow\; \text{traction}
\]

That object is the stress tensor.



\section{Cauchy Stress Tensor}

\subsection{Definition}

The \textbf{Cauchy stress tensor} $\bm{\sigma}$ is defined by:
\[
\boxed{
\bm{t}(\bm{n}) = \bm{\sigma} \cdot \bm{n}
}
\]

In components:
\[
t_i = \sigma_{ij} n_j
\]

This is a linear mapping from surface normal to traction.



\subsection{Matrix form}

The stress tensor is written as:
\[
\bm{\sigma}
=
\begin{bmatrix}
\sigma_{xx} & \sigma_{xy} & \sigma_{xz} \\
\sigma_{yx} & \sigma_{yy} & \sigma_{yz} \\
\sigma_{zx} & \sigma_{zy} & \sigma_{zz}
\end{bmatrix}
\]

Interpretation:
\begin{itemize}
    \item $\sigma_{ij}$ = force in direction $i$ acting on a surface normal to $j$
\end{itemize}



\section{Normal and Shear Stress}

\subsection{Normal stress}

Normal stress acts perpendicular to a surface.

Examples:
\begin{itemize}
    \item $\sigma_{zz}$: vertical compression or tension
    \item $\sigma_{xx}$: horizontal compression or tension
\end{itemize}

Positive normal stress usually means tension (by convention).



\subsection{Shear stress}

Shear stress acts parallel to a surface.

Examples:
\begin{itemize}
    \item $\sigma_{xz}$: horizontal force on a vertical surface
    \item $\sigma_{zx}$: vertical force on a horizontal surface
\end{itemize}

Shear stress is what resists sliding.



\section{Why Stress Must Be Symmetric}

\subsection{Angular momentum balance}

Consider a tiny cube of material.

If:
\[
\sigma_{ij} \neq \sigma_{ji}
\]

then unbalanced torques would cause the cube to spin infinitely fast.

This is physically impossible.



\subsection{Symmetry condition}

Angular momentum conservation requires:
\[
\boxed{
\sigma_{ij} = \sigma_{ji}
}
\]

This reduces the number of independent stress components from 9 to 6.

This is not an assumption — it is a physical law.



\section{Stress Varies in Space and Time}

Stress is not constant.

It depends on:
\begin{itemize}
    \item position $\bm{x}$,
    \item time $t$,
    \item deformation state.
\end{itemize}

We write:
\[
\bm{\sigma} = \bm{\sigma}(\bm{x},t)
\]

Later, we will connect this dependence to strain.



\section{What Stress Is (and Is Not)}

Stress is:
\begin{itemize}
    \item not displacement,
    \item not strain,
    \item not energy.
\end{itemize}

Stress is:
\begin{itemize}
    \item force transmission,
    \item internal reaction to deformation.
\end{itemize}

It tells us \emph{how hard the material pushes back}.



\section{What We Have Built So Far}

At this point, we have:
\begin{itemize}
    \item a way to describe motion (displacement),
    \item a way to measure deformation (strain),
    \item a way to describe internal forces (stress).
\end{itemize}

But we do not yet know how stress and strain are related.

That relationship is the heart of material physics.



\section*{Summary of Chapter 3}

You should now understand:
\begin{itemize}
    \item what traction is,
    \item why stress is a tensor,
    \item physical meaning of stress components,
    \item why stress must be symmetric.
\end{itemize}

The next step is unavoidable.
\pagebreak
\begin{center}
    {\Large \textbf{Chapter 4: Constitutive Laws}}
\end{center}

\vspace{1em}

\section*{Why this chapter exists}

So far, we have:
\begin{itemize}
    \item displacement $\rightarrow$ motion,
    \item strain $\rightarrow$ deformation,
    \item stress $\rightarrow$ internal force.
\end{itemize}

But we do \emph{not} yet know how stress is produced.

This chapter answers the most important modeling question in elasticity:

\begin{quote}
\textbf{Given a deformation, how does the material respond?}
\end{quote}

The answer is a \textbf{constitutive law}.



\section{What Is a Constitutive Law?}

\subsection{Cause and effect}

A constitutive law is a rule that connects:
\[
\text{cause} \quad \longrightarrow \quad \text{effect}
\]

In elasticity:
\[
\text{strain} \quad \longrightarrow \quad \text{stress}
\]

This rule is \emph{not} dictated by Newton’s laws.
It must be supplied from material physics or experiments.



\subsection{Why constitutive laws are models}

Two different materials can experience:
\begin{itemize}
    \item the same strain,
    \item but produce very different stresses.
\end{itemize}

Therefore:
\begin{quote}
\textbf{The constitutive law is where material identity lives.}
\end{quote}

Everything before this chapter was geometry.
Everything after this chapter depends on this choice.



\section{Linear Elasticity}

\subsection{The simplest reasonable assumption}

For small deformations, experiments show:
\begin{itemize}
    \item stress is approximately proportional to strain,
    \item unloading follows the same path.
\end{itemize}

This leads to \textbf{linear elasticity}.



\subsection{General linear relation}

The most general linear relation is:
\[
\boxed{
\sigma_{ij}
=
C_{ijkl}\,\varepsilon_{kl}
}
\]

Here:
\begin{itemize}
    \item $C_{ijkl}$ is the \textbf{elastic stiffness tensor},
    \item it contains all elastic material properties.
\end{itemize}

This is a fourth-order tensor.



\section{Symmetries of the Stiffness Tensor}

\subsection{Why $C_{ijkl}$ has many symmetries}

Because:
\begin{itemize}
    \item $\sigma_{ij} = \sigma_{ji}$ (stress symmetry),
    \item $\varepsilon_{kl} = \varepsilon_{lk}$ (strain symmetry),
\end{itemize}

the stiffness tensor satisfies:
\[
C_{ijkl} = C_{jikl} = C_{ijlk}
\]

Additionally, energy considerations imply:
\[
C_{ijkl} = C_{klij}
\]

These symmetries reduce the number of independent constants.



\section{Isotropic Elasticity}

\subsection{What isotropy means}

A material is \textbf{isotropic} if:
\begin{quote}
Its response is the same in all directions.
\end{quote}

This dramatically simplifies the constitutive law.



\subsection{Lamé parameters}

For isotropic materials:
\[
\boxed{
\sigma_{ij}
=
\lambda\,\delta_{ij}\,\varepsilon_{kk}
+
2\mu\,\varepsilon_{ij}
}
\]

Where:
\begin{itemize}
    \item $\lambda$ and $\mu$ are the \textbf{Lamé parameters},
    \item $\mu$ is the shear modulus,
    \item $\delta_{ij}$ is the Kronecker delta.
\end{itemize}

This remarkable result shows:
\begin{quote}
\textbf{Isotropic linear elasticity needs only two constants.}
\end{quote}



\section{Physical Meaning of $\lambda$ and $\mu$}

\subsection{Shear modulus $\mu$}

$\mu$ controls resistance to shear.

If $\mu = 0$:
\begin{itemize}
    \item the material cannot support shear stress,
    \item it behaves like a fluid.
\end{itemize}

This parameter directly controls S-waves.



\subsection{Lamé parameter $\lambda$}

$\lambda$ controls resistance to volume change.

It appears in compressional behavior.

Together, $\lambda$ and $\mu$ determine P-wave behavior.



\section{Stress-Strain Relation in Matrix Form}

In vector-matrix notation:
\[
\bm{\sigma} = \bm{C}\,\bm{\varepsilon}
\]

This form will later allow us to:
\begin{itemize}
    \item write equations compactly,
    \item build matrix operators,
    \item extend to anisotropy and non-locality.
\end{itemize}



\section{Energy Perspective (Important)}

Elastic energy density is:
\[
W = \frac{1}{2}\,\sigma_{ij}\,\varepsilon_{ij}
\]

This must be positive for all nonzero strains.

This requirement imposes constraints on $\lambda$ and $\mu$:
\[
\mu > 0, \quad 3\lambda + 2\mu > 0
\]

These are \textbf{stability conditions}.



\section{Why This Chapter Matters for Waves}

The constitutive law tells us:
\begin{itemize}
    \item how deformation produces force,
    \item how force produces acceleration (next chapter),
    \item therefore how waves propagate.
\end{itemize}

Every wave speed, dispersion curve, and eigenfunction depends on this law.



\section*{Summary of Chapter 4}

You should now understand:
\begin{itemize}
    \item what a constitutive law is,
    \item why it is a modeling choice,
    \item the general linear elastic relation,
    \item isotropic elasticity and Lamé parameters,
    \item why this is the gateway to wave physics.
\end{itemize}
\pagebreak
\begin{center}
    {\Large \textbf{Chapter 5: Equations of Motion — How Waves Are Born}}
\end{center}

\vspace{1em}

\section*{Why this chapter is special}

Everything so far has been \emph{static}:
\begin{itemize}
    \item geometry of motion,
    \item geometry of deformation,
    \item internal forces,
    \item material response.
\end{itemize}

Nothing has moved yet.

In this chapter, we add:
\begin{quote}
\textbf{Newton’s Second Law}
\end{quote}

With that single step, waves appear — inevitably.



\section{Newton’s Second Law in a Solid}

\subsection{From particles to continua}

For a particle, Newton’s law is:
\[
\text{force} = \text{mass} \times \text{acceleration}.
\]

For a \emph{continuum}, we apply this law to a \emph{small volume}.



\subsection{Mass and acceleration}

Consider a small volume element $dV$.

Its mass is:
\[
dm = \rho\, dV,
\]
where $\rho$ is the mass density.

Its acceleration is:
\[
\pdv[2]{\bm{u}}{t}.
\]

So inertia contributes:
\[
\rho\, dV\, \pdv[2]{\bm{u}}{t}.
\]



\section{Forces Acting on a Volume Element}

\subsection{Body forces}

Body forces act throughout the volume:
\begin{itemize}
    \item gravity,
    \item electromagnetic forces (usually negligible here).
\end{itemize}

We denote body force per unit volume by $\bm{f}$.

Total body force:
\[
\bm{f}\, dV.
\]



\subsection{Surface forces (stress)}

Surface forces act on the boundary of the volume.

From Chapter 3:
\[
\bm{t} = \bm{\sigma} \cdot \bm{n}.
\]

The net surface force is obtained by integrating traction over the surface.



\section{Balance of Linear Momentum}

Applying Newton’s law to a volume element:
\[
\text{(surface forces)} + \text{(body forces)} = \text{mass} \times \text{acceleration}.
\]

Using the divergence theorem, surface forces become:
\[
\int_{\partial V} \bm{\sigma} \cdot \bm{n}\, dA
=
\int_V \nabla \cdot \bm{\sigma}\, dV.
\]

Thus, the local form is:
\[
\boxed{
\rho\, \pdv[2]{\bm{u}}{t}
=
\nabla \cdot \bm{\sigma}
+
\bm{f}
}
\]

This is the \textbf{equation of motion} for a solid.



\section{Ignoring Body Forces (for Waves)}

For seismic waves:
\begin{itemize}
    \item gravity sets the background state,
    \item wave motion is a small perturbation.
\end{itemize}

So we set:
\[
\bm{f} = \bm{0}.
\]

The equation becomes:
\[
\boxed{
\rho\, \pdv[2]{\bm{u}}{t}
=
\nabla \cdot \bm{\sigma}
}
\]

This single equation governs all elastic waves.



\section{Substituting the Constitutive Law}

From Chapter 4 (isotropic elasticity):
\[
\sigma_{ij}
=
\lambda\, \delta_{ij}\, \varepsilon_{kk}
+
2\mu\, \varepsilon_{ij}.
\]

From Chapter 2 (strain definition):
\[
\varepsilon_{ij}
=
\frac{1}{2}
\left(
\frac{\partial u_i}{\partial x_j}
+
\frac{\partial u_j}{\partial x_i}
\right).
\]

Substitute both into the equation of motion.

After careful algebra, we obtain:

\[
\boxed{
\rho\, \pdv[2]{\bm{u}}{t}
=
(\lambda + \mu)\, \nabla(\nabla \cdot \bm{u})
+
\mu\, \nabla^2 \bm{u}
}
\]

This is the \textbf{elastic wave equation}.



\section{Why This Equation Produces Waves}

This equation contains:
\begin{itemize}
    \item second derivatives in time,
    \item second derivatives in space.
\end{itemize}

This structure guarantees:
\begin{itemize}
    \item finite propagation speed,
    \item oscillatory solutions,
    \item wave motion.
\end{itemize}

Waves are not assumed — they are required.



\section{One Equation, Two Kinds of Motion}

This single vector equation contains:
\begin{itemize}
    \item compressional motion,
    \item shear motion.
\end{itemize}

We will separate these motions in the next chapter.



\section{What We Have Achieved}

For the first time, we now have:
\begin{itemize}
    \item a dynamic equation,
    \item material properties,
    \item inertia,
    \item internal forces.
\end{itemize}

This equation is the starting point of all wave physics:
\begin{itemize}
    \item P waves,
    \item S waves,
    \item Rayleigh waves,
    \item dispersion,
    \item everything you coded.
\end{itemize}



\section*{Summary of Chapter 5}

You should now understand:
\begin{itemize}
    \item how Newton’s law applies to a continuum,
    \item how stress produces acceleration,
    \item where density enters,
    \item how the elastic wave equation arises.
\end{itemize}

\pagebreak
\begin{center}
    {\Large \textbf{Chapter 6: Plane Waves and Fourier Thinking}}
\end{center}

\vspace{1em}

\section*{Why this chapter exists}

In Chapter 5, we derived the elastic wave equation:
\[
\rho\, \pdv[2]{\bm{u}}{t}
=
(\lambda + \mu)\, \nabla(\nabla \cdot \bm{u})
+
\mu\, \nabla^2 \bm{u}.
\]

This is a partial differential equation in space and time.

Before solving complicated boundary-value problems, we must answer:

\begin{quote}
\textbf{What kinds of motion does this equation naturally allow?}
\end{quote}

The answer comes from \textbf{plane waves} and \textbf{Fourier thinking}.



\section{Why Plane Waves Matter}

\subsection{A key idea (very important)}

Any sufficiently smooth motion can be written as a superposition of plane waves.

This is not philosophy — it is Fourier analysis.

Plane waves are the \emph{building blocks} of all wave motion.



\subsection{What is a plane wave?}

A plane wave has the form:
\[
\boxed{
\bm{u}(\bm{x},t)
=
\bm{A}\,
e^{i(\bm{k}\cdot\bm{x} - \omega t)}
}
\]

Where:
\begin{itemize}
    \item $\bm{A}$ is a constant vector (polarization),
    \item $\bm{k}$ is the wavevector,
    \item $\omega$ is angular frequency.
\end{itemize}

Surfaces of constant phase are planes:
\[
\bm{k}\cdot\bm{x} = \text{constant}.
\]



\section{Why Time-Harmonic Solutions Are Natural}

\subsection{Linearity}

The elastic wave equation is:
\begin{itemize}
    \item linear in $\bm{u}$,
    \item has constant coefficients (for homogeneous media).
\end{itemize}

For such equations:
\begin{itemize}
    \item exponentials are eigenfunctions,
    \item sinusoids never change shape.
\end{itemize}



\subsection{Why complex exponentials}

We use:
\[
e^{i(\bm{k}\cdot\bm{x} - \omega t)}
\]
instead of sines and cosines because:
\begin{itemize}
    \item derivatives become multiplication,
    \item algebra becomes simpler,
    \item physical solutions are real parts.
\end{itemize}

There is no loss of physics.



\section{Substituting a Plane Wave}

Substitute:
\[
\bm{u} = \bm{A} e^{i(\bm{k}\cdot\bm{x} - \omega t)}
\]

into the wave equation.

Time derivatives give:
\[
\pdv[2]{\bm{u}}{t}
=
- \omega^2 \bm{u}.
\]

Spatial derivatives give:
\[
\nabla \rightarrow i\bm{k}.
\]

The PDE becomes an algebraic equation.



\section{The Algebraic Eigenvalue Problem}

After substitution, we obtain:
\[
\rho \omega^2 \bm{A}
=
(\lambda + \mu)\, \bm{k}(\bm{k}\cdot\bm{A})
+
\mu\, k^2 \bm{A}.
\]

This is an \textbf{eigenvalue problem} for $\bm{A}$.

Different eigenvectors correspond to different wave types.



\section{Longitudinal (P) Waves}

\subsection{Assume polarization parallel to propagation}

Let:
\[
\bm{A} \parallel \bm{k}.
\]

Then:
\[
\bm{k} \cdot \bm{A} = kA.
\]

Substitution gives:
\[
\rho \omega^2 = (\lambda + 2\mu) k^2.
\]

Thus the phase velocity is:
\[
\boxed{
c_P = \sqrt{\frac{\lambda + 2\mu}{\rho}}
}
\]

These are \textbf{compressional (P) waves}.



\section{Transverse (S) Waves}

\subsection{Assume polarization perpendicular to propagation}

Let:
\[
\bm{A} \cdot \bm{k} = 0.
\]

Then:
\[
\bm{k}(\bm{k}\cdot\bm{A}) = \bm{0}.
\]

The equation reduces to:
\[
\rho \omega^2 = \mu k^2.
\]

Thus:
\[
\boxed{
c_S = \sqrt{\frac{\mu}{\rho}}
}
\]

These are \textbf{shear (S) waves}.



\section{Key Physical Insight}

One equation produced two wave speeds.

Why?

Because:
\begin{itemize}
    \item solids resist compression,
    \item solids resist shear.
\end{itemize}

Fluids resist compression but not shear.

This is why fluids have P waves but no S waves.



\section{Dispersion or No Dispersion?}

Notice:
\[
\omega = c\,k
\]

This is a linear relationship.

Therefore:
\begin{itemize}
    \item all frequencies travel at the same speed,
    \item bulk elastic waves are \textbf{non-dispersive}.
\end{itemize}

Dispersion appears only when:
\begin{itemize}
    \item boundaries exist,
    \item layering exists,
    \item non-local effects exist.
\end{itemize}

This is crucial for Rayleigh waves.



\section{Why Fourier Thinking Matters Later}

Every numerical method you used:
\begin{itemize}
    \item vertical slowness $q$,
    \item exponential decay,
    \item modal superposition,
\end{itemize}
comes from this plane-wave idea.

You are now thinking the right way.



\section*{Summary of Chapter 6}

You now understand:
\begin{itemize}
    \item why plane waves are fundamental,
    \item why time-harmonic solutions are used,
    \item how P and S waves emerge,
    \item where wave speeds come from.
\end{itemize}

This chapter is the bridge between equations and physics.
\pagebreak
\begin{center}
    {\Large \textbf{Chapter 7: P and S Waves in Depth}}
\end{center}

\vspace{1em}

\section*{Why this chapter exists}

In Chapter 6, we discovered that the elastic wave equation admits two kinds of plane-wave solutions:
\begin{itemize}
    \item compressional (P) waves,
    \item shear (S) waves.
\end{itemize}

In this chapter, we answer deeper questions:
\begin{quote}
\begin{itemize}
    \item How do particles actually move?
    \item What directions matter?
    \item How does energy flow?
\end{itemize}
\end{quote}

This chapter builds the physical intuition you later used when interpreting eigenfunctions and dispersion curves.



\section{Wavevector and Polarization}

\subsection{Two independent directions}

Every plane wave involves two distinct vectors:
\begin{itemize}
    \item the \textbf{wavevector} $\bm{k}$,
    \item the \textbf{polarization} $\bm{A}$.
\end{itemize}

The wavevector $\bm{k}$ tells us:
\begin{itemize}
    \item direction of propagation,
    \item wavelength ($|\bm{k}| = 2\pi/\lambda$).
\end{itemize}

The polarization $\bm{A}$ tells us:
\begin{itemize}
    \item how particles move.
\end{itemize}



\section{Geometry of P Waves}

\subsection{Longitudinal motion}

For P waves:
\[
\bm{A} \parallel \bm{k}.
\]

This means particles move:
\begin{itemize}
    \item forward and backward,
    \item along the direction of propagation.
\end{itemize}



\subsection{Volume change}

Because motion is longitudinal:
\begin{itemize}
    \item distances between particles change,
    \item the material locally compresses and expands.
\end{itemize}

Mathematically:
\[
\nabla \cdot \bm{u} \neq 0.
\]

P waves are \textbf{dilatational} waves.



\section{Geometry of S Waves}

\subsection{Transverse motion}

For S waves:
\[
\bm{A} \cdot \bm{k} = 0.
\]

This means particles move:
\begin{itemize}
    \item sideways,
    \item perpendicular to propagation.
\end{itemize}



\subsection{No volume change}

Because motion is transverse:
\[
\nabla \cdot \bm{u} = 0.
\]

S waves produce:
\begin{itemize}
    \item shear deformation,
    \item no change in volume.
\end{itemize}



\section{Why Fluids Cannot Support S Waves}

In a fluid:
\[
\mu = 0.
\]

From Chapter 6:
\[
c_S = \sqrt{\frac{\mu}{\rho}} = 0.
\]

Thus:
\begin{itemize}
    \item no restoring force for shear,
    \item no transverse wave propagation.
\end{itemize}

This explains a fundamental geophysical fact:
\begin{quote}
\textbf{S waves do not travel through liquids.}
\end{quote}



\section{Particle Motion Pictures (Very Important)}

\subsection{P wave particle motion}

At a fixed point in space:
\[
\bm{u}(t) = \bm{A}\cos(\bm{k}\cdot\bm{x}-\omega t)
\]

Particles oscillate:
\begin{itemize}
    \item back and forth,
    \item along $\bm{k}$.
\end{itemize}



\subsection{S wave particle motion}

Particles oscillate:
\begin{itemize}
    \item perpendicular to $\bm{k}$,
    \item tracing straight lines.
\end{itemize}

Later, when P and S mix (Rayleigh waves), motion becomes elliptical.



\section{Energy in Elastic Waves}

\subsection{Kinetic energy density}

The kinetic energy density is:
\[
T = \frac{1}{2}\rho \left|\pdv{\bm{u}}{t}\right|^2.
\]

This measures motion of mass.



\subsection{Strain energy density}

The elastic (potential) energy density is:
\[
V = \frac{1}{2}\sigma_{ij}\varepsilon_{ij}.
\]

This measures stored deformation energy.



\subsection{Energy balance}

For harmonic waves:
\begin{itemize}
    \item time-averaged kinetic energy,
    \item equals time-averaged potential energy.
\end{itemize}

This balance is a deep property of linear waves.



\section{Energy Flux and Propagation}

\subsection{Energy travels with the wave}

Energy is not stored at a point.
It flows.

The energy flux vector (Poynting-like vector) is proportional to:
\[
\bm{S} \propto \bm{\sigma} \cdot \pdv{\bm{u}}{t}.
\]

For plane waves:
\begin{itemize}
    \item energy flows in direction $\bm{k}$,
    \item at speed equal to wave speed.
\end{itemize}



\section{Why This Chapter Matters for Rayleigh Waves}

Rayleigh waves are:
\begin{itemize}
    \item not pure P waves,
    \item not pure S waves,
    \item a coupled motion of both.
\end{itemize}

Understanding P and S motion separately is essential before mixing them.

This chapter prepares you for:
\begin{itemize}
    \item vertical slowness,
    \item surface-bound decay,
    \item elliptical particle motion.
\end{itemize}



\section*{Summary of Chapter 7}

You should now understand:
\begin{itemize}
    \item the difference between propagation direction and polarization,
    \item physical meaning of P and S waves,
    \item why fluids support only P waves,
    \item how energy is stored and transported.
\end{itemize}
\pagebreak
\begin{center}
    {\Large \textbf{Chapter 8: Boundary Conditions — Why Surfaces Change Everything}}
\end{center}

\vspace{1em}

\section*{Why this chapter exists}

So far, we have studied waves in an \emph{infinite} medium.

In reality:
\begin{itemize}
    \item the Earth has a surface,
    \item layers have interfaces,
    \item materials meet other materials.
\end{itemize}

Waves must obey rules at these boundaries.

These rules are called \textbf{boundary conditions}.

This chapter explains:
\begin{quote}
\textbf{What conditions displacement and stress must satisfy at surfaces and interfaces.}
\end{quote}



\section{Why Boundaries Matter}

\subsection{A simple analogy}

Think of a vibrating string:
\begin{itemize}
    \item fixed ends produce standing waves,
    \item free ends produce different patterns.
\end{itemize}

The equation is the same.
Only the boundary conditions differ.

The same is true for elastic waves.



\section{Types of Boundaries in Elastic Media}

There are three fundamental types:
\begin{itemize}
    \item free surfaces,
    \item rigid (clamped) boundaries,
    \item interfaces between two solids.
\end{itemize}

Rayleigh waves exist because of \textbf{free surfaces}.



\section{The Free Surface}

\subsection{Physical meaning}

A free surface is a boundary where:
\begin{itemize}
    \item no external forces act,
    \item the material is in contact with air or vacuum.
\end{itemize}

Examples:
\begin{itemize}
    \item Earth’s surface,
    \item a crack face.
\end{itemize}



\subsection{Traction-free condition}

From Chapter 3:
\[
\bm{t} = \bm{\sigma} \cdot \bm{n}.
\]

At a free surface:
\[
\boxed{
\bm{t} = \bm{0}
}
\]

This means:
\[
\boxed{
\bm{\sigma} \cdot \bm{n} = \bm{0}
}
\]



\section{Free Surface in Coordinates}

\subsection{Surface normal}

Assume the free surface is:
\[
z = 0,
\quad
\text{with normal } \bm{n} = \hat{\bm{z}}.
\]

Then the traction condition becomes:
\[
\bm{\sigma} \cdot \hat{\bm{z}} = \bm{0}.
\]



\subsection{Component form}

This gives two scalar conditions (in 2D):
\[
\boxed{
\sigma_{xz}(x,0,t) = 0,
\qquad
\sigma_{zz}(x,0,t) = 0.
}
\]

These two equations will determine Rayleigh waves.



\section{Interfaces Between Two Solids}

\subsection{Physical requirements}

At a perfectly bonded interface:
\begin{itemize}
    \item the material does not separate,
    \item forces are transmitted.
\end{itemize}

This leads to two conditions.



\subsection{Continuity of displacement}

Material points remain attached:
\[
\boxed{
\bm{u}^{(1)} = \bm{u}^{(2)}
}
\]

No gaps, no overlaps.



\subsection{Continuity of traction}

Forces balance across the interface:
\[
\boxed{
\bm{\sigma}^{(1)} \cdot \bm{n}
=
\bm{\sigma}^{(2)} \cdot \bm{n}
}
\]

This enforces Newton’s third law locally.



\section{Why Boundary Conditions Create New Waves}

In an infinite medium:
\begin{itemize}
    \item plane waves propagate freely,
    \item energy spreads in all directions.
\end{itemize}

At a free surface:
\begin{itemize}
    \item waves reflect,
    \item P and S waves couple,
    \item energy can become trapped.
\end{itemize}

This trapping creates \textbf{surface waves}.



\section{Dimensional Reduction at the Surface}

Near the surface:
\begin{itemize}
    \item motion is primarily in the $x$–$z$ plane,
    \item waves propagate along $x$,
    \item amplitudes decay with depth $z$.
\end{itemize}

This is the setting of Rayleigh waves.



\section{Why Rayleigh Waves Must Decay with Depth}

If motion did not decay:
\begin{itemize}
    \item energy would leak into the half-space,
    \item surface localization would be impossible.
\end{itemize}

Therefore:
\[
\bm{u}(x,z,t) \to 0 \quad \text{as } z \to +\infty.
\]

This requirement selects only special solutions.



\section{Preview: What Comes Next}

In the next chapter, we will:
\begin{itemize}
    \item assume a surface-wave form,
    \item combine P and S components,
    \item enforce the traction-free conditions,
    \item derive the Rayleigh secular equation.
\end{itemize}

Nothing will be guessed.

Everything will be forced by boundary conditions.



\section*{Summary of Chapter 8}

You should now understand:
\begin{itemize}
    \item what boundary conditions are,
    \item what a free surface means physically,
    \item why traction must vanish at a free surface,
    \item how boundaries create new wave phenomena.
\end{itemize}

\pagebreak
\begin{center}
    {\large Lifetime Notes}\\[1em]
    {\Large \textbf{Chapter 9: Rayleigh Wave Ansatz}}
\end{center}

\vspace{1em}

\section*{Why this chapter exists}

We now have all the ingredients:
\begin{itemize}
    \item elastic wave equation,
    \item P and S plane waves,
    \item free-surface boundary conditions,
    \item requirement of decay with depth.
\end{itemize}

The only task left is to combine them \emph{consistently}.

This chapter builds the Rayleigh wave step by step.



\section{Geometry of the Problem}

\subsection{Half-space model}

We consider an elastic half-space:
\[
z \ge 0,
\]
with a free surface at:
\[
z = 0.
\]

Assumptions:
\begin{itemize}
    \item homogeneous,
    \item isotropic,
    \item linear elastic.
\end{itemize}



\subsection{Dimensional reduction}

Rayleigh waves:
\begin{itemize}
    \item propagate along $x$,
    \item do not vary along $y$,
    \item decay with depth $z$.
\end{itemize}

Thus:
\[
\bm{u} = (u_x(x,z,t),\,0,\,u_z(x,z,t)).
\]

This is called \textbf{plane strain}.



\section{Time-Harmonic Surface-Wave Form}

We seek solutions of the form:
\[
\boxed{
\bm{u}(x,z,t)
=
\bm{U}(z)\,
e^{i(kx - \omega t)}
}
\]

Here:
\begin{itemize}
    \item $k$ is horizontal wavenumber,
    \item $\omega$ is angular frequency,
    \item $\bm{U}(z)$ contains depth dependence.
\end{itemize}



\section{Why P and SV Waves Must Mix}

In the bulk:
\begin{itemize}
    \item P waves involve compression,
    \item SV waves involve vertical shear.
\end{itemize}

At the surface:
\begin{itemize}
    \item normal stress must vanish,
    \item shear stress must vanish.
\end{itemize}

No single wave type can satisfy both conditions alone.

Therefore:
\[
\boxed{
\text{Rayleigh waves are a coupled P–SV motion.}
}
\]



\section{Vertical Slowness}

From Chapter 6, plane waves satisfy:
\[
k_x^2 + k_z^2 = \frac{\omega^2}{c^2}.
\]

For surface waves:
\[
k_x = k,
\quad
k_z = i q,
\]

so that motion decays as $e^{-qz}$.



\subsection{Definitions}

For P waves:
\[
\boxed{
q_P
=
\sqrt{
k^2 - \frac{\omega^2}{V_P^2}
}
}
\]

For S waves:
\[
\boxed{
q_S
=
\sqrt{
k^2 - \frac{\omega^2}{V_S^2}
}
}
\]

Rayleigh waves require:
\[
k > \frac{\omega}{V_S} > \frac{\omega}{V_P}.
\]



\section{General Rayleigh Wave Ansatz}

The displacement field is written as:
\[
\bm{u}
=
\left[
A_P
\begin{pmatrix}
ik \\ -q_P
\end{pmatrix}
e^{-q_P z}
+
A_S
\begin{pmatrix}
-q_S \\ ik
\end{pmatrix}
e^{-q_S z}
\right]
e^{i(kx-\omega t)}.
\]

Here:
\begin{itemize}
    \item $A_P$ is P-wave amplitude,
    \item $A_S$ is SV-wave amplitude.
\end{itemize}

This form automatically:
\begin{itemize}
    \item satisfies the wave equation,
    \item decays with depth.
\end{itemize}



\section{Compute Stress Components}

Using the constitutive law:
\[
\sigma_{ij}
=
\lambda \delta_{ij} \varepsilon_{kk}
+
2\mu \varepsilon_{ij},
\]

we compute:
\begin{itemize}
    \item $\sigma_{xz}$,
    \item $\sigma_{zz}$.
\end{itemize}

After differentiation and algebra (details omitted here but exact), both stresses can be written as linear combinations of $A_P$ and $A_S$.



\section{Free-Surface Boundary Conditions}

At $z = 0$:
\[
\boxed{
\sigma_{xz} = 0,
\quad
\sigma_{zz} = 0.
}
\]

These give two homogeneous linear equations:
\[
\begin{bmatrix}
F_{11} & F_{12} \\
F_{21} & F_{22}
\end{bmatrix}
\begin{bmatrix}
A_P \\ A_S
\end{bmatrix}
=
\bm{0}.
\]



\section{The Secular Equation}

A nontrivial solution exists only if:
\[
\boxed{
\det \bm{F}(k,\omega) = 0.
}
\]

This determinant equation is called the
\textbf{Rayleigh secular equation}.

It determines allowed phase velocities:
\[
c = \frac{\omega}{k}.
\]



\section{Meaning of the Secular Equation}

This equation:
\begin{itemize}
    \item is transcendental,
    \item has no closed-form solution,
    \item has exactly one physically meaningful root.
\end{itemize}

That root is the Rayleigh wave speed.



\section{Why the Rayleigh Velocity Is Less Than $V_S$}

Because:
\begin{itemize}
    \item motion is confined near the surface,
    \item part of the energy is stored in evanescent fields,
    \item coupling reduces effective speed.
\end{itemize}

This explains the empirical fact:
\[
c_R \approx 0.92\, V_S.
\]



\section*{Summary of Chapter 9}

You now understand:
\begin{itemize}
    \item why Rayleigh waves require P–SV coupling,
    \item why amplitudes decay with depth,
    \item how vertical slowness appears,
    \item how the secular equation arises.
\end{itemize}

Rayleigh waves are not mysterious.
They are \emph{forced by physics}.
\pagebreak
\begin{center}
    {\Large \textbf{Chapter 10: The Rayleigh Secular Equation}}
\end{center}

\vspace{1em}

\section*{Why this chapter exists}

In Chapter 9, we arrived at a determinant condition:
\[
\det \bm{F}(k,\omega) = 0,
\]
which selects allowed Rayleigh wave velocities.

This chapter answers deeper questions:
\begin{quote}
\begin{itemize}
    \item Why does this equation have solutions at all?
    \item Why is there only one physical root?
    \item Why is the Rayleigh velocity always less than $V_S$?
\end{itemize}
\end{quote}

We are not chasing numbers.  
We are understanding structure.



\section{Writing the Secular Equation Explicitly}

\subsection{Non-dimensionalization}

Define the phase velocity:
\[
c = \frac{\omega}{k}.
\]

Introduce dimensionless variables:
\[
\alpha = \sqrt{1 - \frac{c^2}{V_P^2}},
\qquad
\beta = \sqrt{1 - \frac{c^2}{V_S^2}}.
\]

These represent normalized vertical slownesses.



\subsection{Classical Rayleigh equation}

After algebraic simplification, the Rayleigh secular equation can be written as:
\[
\boxed{
(2 - \beta^2)^2 - 4\sqrt{1-\alpha^2}\sqrt{1-\beta^2} = 0
}
\]

Equivalently, in the more common form:
\[
\boxed{
(2 - \beta^2)^2 - 4\sqrt{(1-\alpha^2)(1-\beta^2)} = 0.
}
\]

This is a nonlinear algebraic equation for $c$.



\section{Domain of Admissible Solutions}

\subsection{Decay condition}

For surface localization:
\[
q_P > 0,
\quad
q_S > 0.
\]

This requires:
\[
c < V_S < V_P.
\]

Thus, we only search for roots in:
\[
0 < c < V_S.
\]

This immediately excludes many mathematical solutions.



\section{Existence of a Rayleigh Root}

\subsection{Evaluate at endpoints}

Define:
\[
R(c) = (2 - \beta^2)^2 - 4\sqrt{(1-\alpha^2)(1-\beta^2)}.
\]

At $c \to 0$:
\[
\beta \to 1,
\quad
R(c) > 0.
\]

At $c \to V_S$:
\[
\beta \to 0,
\quad
R(c) < 0.
\]

By continuity:
\[
\boxed{
\text{At least one root exists in } (0, V_S).
}
\]



\section{Uniqueness of the Rayleigh Root}

\subsection{Monotonic behavior}

Careful analysis shows:
\begin{itemize}
    \item $R(c)$ is strictly decreasing,
    \item it crosses zero exactly once.
\end{itemize}

Therefore:
\[
\boxed{
\text{There is exactly one physically admissible Rayleigh mode in a half-space.}
}
\]

This is a deep and important result.



\section{Why the Rayleigh Velocity Is Less Than $V_S$}

This is not accidental.

Physically:
\begin{itemize}
    \item part of the motion is compressional,
    \item part is shear,
    \item energy is trapped near the surface.
\end{itemize}

Mathematically:
\begin{itemize}
    \item decay requires $c < V_S$,
    \item boundary conditions forbid $c = V_S$.
\end{itemize}



\section{Approximate Value of Rayleigh Velocity}

For typical Poisson solids:
\[
\frac{V_P}{V_S} \approx 1.7 \text{ to } 2.
\]

Solving the secular equation numerically gives:
\[
\boxed{
c_R \approx 0.92\, V_S.
}
\]

This is the value you validated in code.



\section{Sensitivity to Material Properties}

The Rayleigh velocity depends primarily on:
\begin{itemize}
    \item shear modulus $\mu$,
    \item weakly on $\lambda$.
\end{itemize}

Thus:
\begin{quote}
\textbf{Rayleigh waves are primarily sensitive to $V_S$.}
\end{quote}

This fact drives surface-wave inversion.



\section{Eigenvector Interpretation}

At a root:
\[
\bm{F}
\begin{bmatrix}
A_P \\ A_S
\end{bmatrix}
=
\bm{0}.
\]

This is an eigenvalue problem.

The ratio:
\[
\frac{A_S}{A_P}
\]
determines:
\begin{itemize}
    \item relative P and SV content,
    \item particle-motion ellipticity.
\end{itemize}



\section{Why Numerical Root-Finding Is Required}

The secular equation:
\begin{itemize}
    \item is transcendental,
    \item cannot be solved analytically,
    \item must be solved numerically.
\end{itemize}

This motivates:
\begin{itemize}
    \item determinant evaluation,
    \item root bracketing,
    \item stability considerations.
\end{itemize}

Exactly what your code does.



\section{Preview: From Half-Space to Layers}

In layered media:
\begin{itemize}
    \item multiple Rayleigh modes exist,
    \item dispersion appears,
    \item matrices replace scalars.
\end{itemize}

But the logic remains identical.



\section*{Summary of Chapter 10}

You now understand:
\begin{itemize}
    \item the explicit form of the Rayleigh equation,
    \item why a root exists,
    \item why it is unique,
    \item why $c_R < V_S$,
    \item why numerical methods are needed.
\end{itemize}

This chapter closes the theory of Rayleigh waves in a half-space.
\pagebreak
\begin{center}
    {\Large \textbf{Chapter 11: State Vectors and Matrix Formulation}}
\end{center}

\vspace{1em}

\section*{Why this chapter exists}

Up to Chapter 10, we worked with:
\begin{itemize}
    \item partial differential equations,
    \item scalar secular equations,
    \item analytical reasoning.
\end{itemize}

That approach works for a homogeneous half-space.

But real Earth models are:
\begin{itemize}
    \item layered,
    \item heterogeneous,
    \item anisotropic.
\end{itemize}

To handle this complexity, we must:
\begin{quote}
\textbf{Rewrite elasticity as a first-order matrix system.}
\end{quote}

This chapter introduces the **state vector** — the most important computational idea in your project.



\section{Why We Change Variables}

\subsection{The problem with second-order equations}

The elastic wave equation involves:
\begin{itemize}
    \item second derivatives in space,
    \item second derivatives in time.
\end{itemize}

Layered media introduce:
\begin{itemize}
    \item discontinuous material properties,
    \item interface conditions.
\end{itemize}

Second-order equations are awkward at interfaces.



\subsection{The key idea}

We replace:
\[
\text{second-order equations}
\quad \longrightarrow \quad
\text{first-order system}
\]

by enlarging the set of variables.

This is the same idea used in:
\begin{itemize}
    \item classical mechanics,
    \item control theory,
    \item quantum mechanics.
\end{itemize}



\section{Choice of State Variables}

\subsection{What must be continuous across layers?}

At an interface:
\begin{itemize}
    \item displacement must be continuous,
    \item traction must be continuous.
\end{itemize}

Therefore, we choose the state vector as:
\[
\boxed{
\bm{U}(z)
=
\begin{bmatrix}
u_x \\
u_z \\
\sigma_{xz} \\
\sigma_{zz}
\end{bmatrix}
}
\]

This choice is not arbitrary.
It is forced by physics.



\section{Time-Harmonic Reduction}

Assume time-harmonic motion:
\[
\bm{u}(x,z,t)
=
\bm{u}(z)\, e^{i(kx - \omega t)}.
\]

All time derivatives become algebraic:
\[
\pdv{}{t} \rightarrow -i\omega,
\qquad
\pdv{}{x} \rightarrow ik.
\]

The problem reduces to ordinary differential equations in $z$.



\section{First-Order System in Depth}

\subsection{Governing equation}

In a homogeneous layer, the state vector satisfies:
\[
\boxed{
\frac{d}{dz}\bm{U}(z)
=
\bm{G}\, \bm{U}(z)
}
\]

Here:
\begin{itemize}
    \item $\bm{G}$ is a $4\times4$ system matrix,
    \item it depends on $k, \omega, \rho, V_P, V_S$.
\end{itemize}

This is a linear ODE system with constant coefficients.



\section{Solution by Eigen-Decomposition}

The solution of:
\[
\frac{d\bm{U}}{dz} = \bm{G}\bm{U}
\]

is:
\[
\bm{U}(z) = e^{\bm{G}z}\, \bm{U}(0).
\]

The matrix exponential contains all depth dependence.



\section{Physical Meaning of Eigenvalues}

The eigenvalues of $\bm{G}$ are:
\[
\pm q_P, \quad \pm q_S
\]

where:
\[
q_P = \sqrt{k^2 - \frac{\omega^2}{V_P^2}},
\qquad
q_S = \sqrt{k^2 - \frac{\omega^2}{V_S^2}}.
\]

These are exactly the vertical slownesses introduced earlier.



\section{The Y-Matrix (Eigenvector Matrix)}

\subsection{Definition}

Let the eigenvectors of $\bm{G}$ form the columns of:
\[
\boxed{
\bm{Y}
=
\begin{bmatrix}
\bm{y}_1 & \bm{y}_2 & \bm{y}_3 & \bm{y}_4
\end{bmatrix}
}
\]

Each column corresponds to:
\begin{itemize}
    \item a P or SV wave,
    \item upward or downward decaying.
\end{itemize}

This is the famous \textbf{Y-matrix} used in your code.



\section{Diagonal Propagation Matrix}

Define:
\[
\boxed{
\bm{D}(z)
=
\mathrm{diag}
\left(
e^{-q_P z},
e^{+q_P z},
e^{-q_S z},
e^{+q_S z}
\right)
}
\]

This matrix contains \emph{only} depth dependence.



\section{General Solution in a Layer}

The complete solution is:
\[
\boxed{
\bm{U}(z)
=
\bm{Y}\,
\bm{D}(z)\,
\bm{a}
}
\]

where:
\[
\bm{a}
=
\begin{bmatrix}
A_P^- \\
A_P^+ \\
A_S^- \\
A_S^+
\end{bmatrix}
\]

are wave amplitudes.

This equation is the heart of multilayer modeling.



\section{Why This Form Is So Powerful}

This representation:
\begin{itemize}
    \item separates physics (Y),
    \item separates geometry (D),
    \item separates amplitudes (a).
\end{itemize}

It allows:
\begin{itemize}
    \item exact layer propagation,
    \item stable numerical computation,
    \item clean interface conditions.
\end{itemize}



\section{Preview: Propagator Matrices}

If a layer has thickness $h$:
\[
\bm{U}(h)
=
\bm{Y}\bm{D}(h)\bm{Y}^{-1}
\bm{U}(0).
\]

This defines the \textbf{layer propagator}.

Stacking layers becomes matrix multiplication.



\section*{Summary of Chapter 11}

You now understand:
\begin{itemize}
    \item why we introduce a state vector,
    \item why displacement and stress are chosen,
    \item how second-order PDEs become first-order ODEs,
    \item where the Y-matrix comes from,
    \item why your code has exponential matrices.
\end{itemize}

This chapter is the true bridge from theory to algorithms.
\pagebreak
\begin{center}
    {\Large \textbf{Chapter 12: Propagator Matrices — How Layers Are Stacked}}
\end{center}

\vspace{1em}

\section*{Why this chapter exists}

In Chapter 11, we introduced the state vector:
\[
\bm{U}(z)
=
\begin{bmatrix}
u_x \\
u_z \\
\sigma_{xz} \\
\sigma_{zz}
\end{bmatrix},
\]
and showed that within a homogeneous layer:
\[
\bm{U}(z) = \bm{Y}\bm{D}(z)\bm{a}.
\]

This chapter explains:
\begin{quote}
\textbf{How a finite-thickness layer transforms the state vector from top to bottom.}
\end{quote}

This is the key step that makes multilayer modeling possible.



\section{One Layer as a Linear Operator}

\subsection{Top and bottom of a layer}

Consider a layer of thickness $h$.

Let:
\begin{itemize}
    \item $\bm{U}(0)$ be the state at the top,
    \item $\bm{U}(h)$ be the state at the bottom.
\end{itemize}

We wish to relate these two vectors.



\subsection{Eliminating wave amplitudes}

From Chapter 11:
\[
\bm{U}(0) = \bm{Y}\bm{a},
\qquad
\bm{U}(h) = \bm{Y}\bm{D}(h)\bm{a}.
\]

Eliminate $\bm{a}$:
\[
\bm{a} = \bm{Y}^{-1}\bm{U}(0).
\]

Substitute into $\bm{U}(h)$:
\[
\boxed{
\bm{U}(h)
=
\bm{Y}\bm{D}(h)\bm{Y}^{-1}\bm{U}(0)
}
\]



\section{The Propagator Matrix}

\subsection{Definition}

We define the \textbf{layer propagator}:
\[
\boxed{
\bm{P}
=
\bm{Y}\bm{D}(h)\bm{Y}^{-1}
}
\]

Then:
\[
\boxed{
\bm{U}(h) = \bm{P}\,\bm{U}(0).
}
\]

A layer is now a linear operator.



\section{Physical Meaning of the Propagator}

The propagator:
\begin{itemize}
    \item contains all material properties,
    \item contains the layer thickness,
    \item exactly propagates displacement and stress.
\end{itemize}

No approximations are made.



\section{Why Matrix Multiplication Is Natural}

Suppose we have two layers with propagators $\bm{P}_1$ and $\bm{P}_2$.

Then:
\[
\bm{U}(h_1 + h_2)
=
\bm{P}_2 \bm{P}_1 \bm{U}(0).
\]

This is just matrix multiplication.

Thus:
\[
\boxed{
\text{Layer stacking} = \text{matrix multiplication}.
}
\]



\section{Many Layers: The Global Propagator}

For $N$ layers:
\[
\boxed{
\bm{M}
=
\bm{P}_N \bm{P}_{N-1} \cdots \bm{P}_1
}
\]

This matrix maps:
\[
\bm{U}_{\text{top}}
\quad \longrightarrow \quad
\bm{U}_{\text{bottom}}.
\]

This is exactly what your forward-model code computes.



\section{Numerical Stability Issues}

\subsection{Exponentials grow and decay}

The diagonal matrix $\bm{D}(h)$ contains:
\[
e^{\pm q_P h}, \quad e^{\pm q_S h}.
\]

Some terms:
\begin{itemize}
    \item grow exponentially,
    \item others decay exponentially.
\end{itemize}

This can lead to ill-conditioning.



\subsection{Physical interpretation}

Growing exponentials correspond to:
\begin{itemize}
    \item upward-propagating waves,
    \item physically forbidden modes in the half-space.
\end{itemize}

They must be carefully controlled numerically.



\section{Conditioning of the Y-Matrix}

The matrix $\bm{Y}$:
\begin{itemize}
    \item contains eigenvectors of the system,
    \item can become ill-conditioned near mode cutoffs.
\end{itemize}

This explains:
\begin{itemize}
    \item numerical warnings you observed,
    \item the need for pseudo-inverses in code.
\end{itemize}



\section{Why We Still Use Propagators}

Despite numerical challenges:
\begin{itemize}
    \item propagators are exact,
    \item physically transparent,
    \item easy to implement.
\end{itemize}

Later, alternative formulations (stiffness matrices) improve stability.

But propagators are conceptually fundamental.



\section{Preview: Boundary Conditions Revisited}

Now that we can propagate states through layers, we must:
\begin{itemize}
    \item enforce free-surface conditions at the top,
    \item enforce radiation conditions in the half-space.
\end{itemize}

This will lead to a matrix determinant condition.



\section*{Summary of Chapter 12}

You should now understand:
\begin{itemize}
    \item how one layer acts as a linear operator,
    \item why the propagator has the form $YDY^{-1}$,
    \item how stacking layers becomes matrix multiplication,
    \item why numerical conditioning matters.
\end{itemize}

This chapter explains the backbone of your forward model.
\pagebreak
\begin{center}
    {\Large \textbf{Chapter 13: Global Dispersion Equation}}
\end{center}

\vspace{1em}

\section*{Why this chapter exists}

By the end of Chapter 12, we had:
\begin{itemize}
    \item a state vector $\bm{U}(z)$,
    \item exact propagation through each layer,
    \item a global propagator for all layers.
\end{itemize}

But propagation alone does not select a wave.

This chapter answers the final forward-model question:

\begin{quote}
\textbf{Which values of $(\omega,k)$ are allowed by the boundary conditions?}
\end{quote}

The answer is a \textbf{determinant equation}.



\section{The Physical Setup}

\subsection{Layered half-space}

We consider:
\begin{itemize}
    \item $N$ horizontal layers of finite thickness,
    \item underlain by a semi-infinite half-space.
\end{itemize}

The free surface is at:
\[
z = 0,
\]
and depth increases downward.



\section{The Global Propagator}

From Chapter 12, define the total propagator:
\[
\boxed{
\bm{M}
=
\bm{P}_N \bm{P}_{N-1} \cdots \bm{P}_1
}
\]

This matrix relates:
\[
\bm{U}_{\text{surface}}
\quad \longleftrightarrow \quad
\bm{U}_{\text{top of half-space}}.
\]



\section{Half-Space Radiation Condition}

\subsection{Physical requirement}

In the half-space:
\begin{itemize}
    \item waves must decay with depth,
    \item no energy may come from infinity.
\end{itemize}

Therefore:
\[
A_P^+ = 0,
\qquad
A_S^+ = 0.
\]

Only downward-decaying modes are allowed.



\subsection{Half-space state vector}

At the top of the half-space:
\[
\bm{U}_H
=
\bm{Y}_H
\begin{bmatrix}
A_P^- \\
0 \\
A_S^- \\
0
\end{bmatrix}
\]

Partition this as:
\[
\bm{U}_H
=
\begin{bmatrix}
\bm{U}_u \\
\bm{U}_\sigma
\end{bmatrix},
\]
where:
\begin{itemize}
    \item $\bm{U}_u$ = displacement components,
    \item $\bm{U}_\sigma$ = traction components.
\end{itemize}



\section{Propagating to the Surface}

Using the global propagator:
\[
\bm{U}_{\text{surface}}
=
\bm{M}\bm{U}_H.
\]

Partition $\bm{M}$ as:
\[
\bm{M}
=
\begin{bmatrix}
\bm{M}_{11} & \bm{M}_{12} \\
\bm{M}_{21} & \bm{M}_{22}
\end{bmatrix}.
\]

Then:
\[
\bm{U}_{\text{surface}}
=
\begin{bmatrix}
\bm{M}_{11} & \bm{M}_{12} \\
\bm{M}_{21} & \bm{M}_{22}
\end{bmatrix}
\begin{bmatrix}
\bm{U}_u \\
\bm{U}_\sigma
\end{bmatrix}.
\]



\section{Free-Surface Boundary Condition}

At the surface:
\[
\boxed{
\bm{U}_\sigma^{\text{surface}} = \bm{0}.
}
\]

Thus:
\[
\bm{M}_{21}\bm{U}_u + \bm{M}_{22}\bm{U}_\sigma = \bm{0}.
\]

Substitute $\bm{U}_u = \bm{Y}_{u}\bm{a}$,
$\bm{U}_\sigma = \bm{Y}_{\sigma}\bm{a}$.



\section{The Global Dispersion Matrix}

After algebraic elimination, we obtain:
\[
\boxed{
\bm{A}(k,\omega)\,\bm{a} = \bm{0}.
}
\]

Here:
\[
\bm{A}
=
\bm{M}_{21}
-
\bm{Y}_{u}\bm{Y}_{\sigma}^{-1}\bm{M}_{22}.
\]

This is a $2\times2$ matrix.



\section{The Dispersion Condition}

A nontrivial solution exists only if:
\[
\boxed{
\det \bm{A}(k,\omega) = 0.
}
\]

This is the \textbf{global Rayleigh dispersion equation}.

It generalizes:
\begin{itemize}
    \item the half-space secular equation,
    \item to arbitrarily many layers.
\end{itemize}



\section{Multiple Modes}

Unlike the half-space case:
\begin{itemize}
    \item $\det \bm{A}=0$ may have multiple roots,
    \item each root corresponds to a Rayleigh mode.
\end{itemize}

These are labeled:
\[
R_0, R_1, R_2, \dots
\]

This explains:
\begin{itemize}
    \item multimode dispersion curves,
    \item mode cut-on and cut-off.
\end{itemize}



\section{Why Dispersion Appears}

Dispersion arises because:
\begin{itemize}
    \item wavelengths interact with layer thickness,
    \item different frequencies sample different depths.
\end{itemize}

Thus:
\[
c = c(\omega).
\]

This is exactly what surface-wave inversion exploits.



\section{Numerical Implementation}

Your code does exactly this:
\begin{itemize}
    \item build $\bm{M}$ by multiplying propagators,
    \item assemble $\bm{A}(k,\omega)$,
    \item evaluate $\det \bm{A}$,
    \item find roots in $c = \omega/k$.
\end{itemize}

Every line now has meaning.



\section*{Summary of Chapter 13}

You now understand:
\begin{itemize}
    \item how the multilayer problem is assembled,
    \item why the dispersion equation is a determinant,
    \item why multiple Rayleigh modes exist,
    \item how boundary conditions select allowed waves.
\end{itemize}

This completes the **classical forward model**.

\pagebreak
\begin{center}
    {\Large \textbf{Chapter 14: Mode Tracking and Dispersion Curves}}
\end{center}

\vspace{1em}

\section*{Why this chapter exists}

In Chapter 13, we derived the global dispersion condition:
\[
\det \bm{A}(k,\omega) = 0.
\]

Solving this equation numerically at a fixed frequency yields:
\begin{itemize}
    \item multiple roots,
    \item unordered phase velocities,
    \item roots that appear and disappear.
\end{itemize}

This chapter answers:
\begin{quote}
\textbf{How do we organize these roots into physical Rayleigh modes?}
\end{quote}



\section{What a Dispersion Curve Really Is}

\subsection{Definition}

A \textbf{dispersion curve} is a continuous function:
\[
c_j(\omega),
\]
where:
\begin{itemize}
    \item $\omega$ is frequency,
    \item $c_j$ is the phase velocity of the $j$-th mode.
\end{itemize}

Each curve represents:
\begin{quote}
\textbf{one physical mode evolving with frequency.}
\end{quote}



\section{Roots at a Fixed Frequency}

At a fixed frequency $\omega$:
\begin{itemize}
    \item the dispersion equation is scalar,
    \item its roots are isolated points in $c$.
\end{itemize}

These roots have no intrinsic ordering.

Sorting by magnitude alone is insufficient.



\section{Why Mode Tracking Is Necessary}

\subsection{Frequency sampling}

Numerically, we compute roots at discrete frequencies:
\[
\omega_1, \omega_2, \dots, \omega_N.
\]

At each frequency:
\[
\{c^{(i)}_1, c^{(i)}_2, \dots\}.
\]

We must connect these points across frequency.



\subsection{What goes wrong without tracking}

If we simply plot:
\begin{itemize}
    \item all roots at all frequencies,
\end{itemize}
we obtain:
\begin{itemize}
    \item crossing curves,
    \item broken branches,
    \item physically meaningless plots.
\end{itemize}

This is exactly what you observed initially.



\section{Physical Principle Behind Mode Tracking}

Rayleigh modes satisfy:
\begin{itemize}
    \item continuity in frequency,
    \item smooth variation of phase velocity.
\end{itemize}

Therefore:
\[
c_j(\omega + \Delta\omega)
\approx
c_j(\omega).
\]

This simple idea is the foundation of mode tracking.



\section{Nearest-Neighbor Tracking Algorithm}

\subsection{Basic algorithm}

At frequency $\omega_i$:
\begin{enumerate}
    \item Compute all roots $\{c_k^{(i)}\}$.
    \item For each mode $j$, select the root closest to $c_j^{(i-1)}$.
\end{enumerate}

Mathematically:
\[
c_j^{(i)}
=
\arg\min_{c \in \{c_k^{(i)}\}}
\left|c - c_j^{(i-1)}\right|.
\]

This is exactly what your code does.



\section{Initialization of Modes}

\subsection{Fundamental mode}

At low frequency:
\begin{itemize}
    \item only one Rayleigh mode exists,
    \item this is the fundamental mode $R_0$.
\end{itemize}

Thus:
\[
c_0(\omega_{\min}) = \min \{c_k\}.
\]

This initializes the tracking.



\subsection{Higher modes}

Higher modes appear only above cutoff frequencies.

They must be:
\begin{itemize}
    \item detected,
    \item added dynamically.
\end{itemize}

This explains why mode count increases with frequency.



\section{Mode Cut-On and Cut-Off}

\subsection{Physical meaning}

A mode:
\begin{itemize}
    \item appears when the wavelength fits inside layers,
    \item disappears when confinement is lost.
\end{itemize}

Mathematically:
\begin{itemize}
    \item roots enter or leave the admissible domain.
\end{itemize}

This is not numerical noise — it is physics.



\section{Fundamental Mode Behavior}

The fundamental mode:
\begin{itemize}
    \item exists at all frequencies,
    \item asymptotically approaches:
    \begin{itemize}
        \item surface-layer velocity at high frequency,
        \item half-space velocity at low frequency.
    \end{itemize}
\end{itemize}

This explains its diagnostic power in inversion.



\section{Smoothing and Regularization}

Numerical root-finding introduces:
\begin{itemize}
    \item small fluctuations,
    \item discretization noise.
\end{itemize}

Light smoothing (e.g., Savitzky–Golay) may be applied:
\[
\text{only for visualization, never for physics.}
\]



\section{What a Clean Dispersion Plot Means}

A physically correct dispersion plot shows:
\begin{itemize}
    \item smooth curves,
    \item no sudden jumps,
    \item clear separation of modes.
\end{itemize}

This is the benchmark for forward-model correctness.



\section{Connection to Inversion}

In inversion:
\begin{itemize}
    \item observed dispersion curves are given,
    \item model parameters are unknown.
\end{itemize}

Reliable mode tracking is essential because:
\begin{itemize}
    \item mislabeling modes produces false gradients,
    \item inversion becomes unstable.
\end{itemize}



\section*{Summary of Chapter 14}

You now understand:
\begin{itemize}
    \item what dispersion curves really represent,
    \item why roots must be tracked,
    \item how nearest-neighbor tracking works,
    \item why higher modes appear and disappear.
\end{itemize}
\pagebreak
\begin{center}
    {\Large \textbf{Chapter 15: Eigenfunctions and Mode Shapes}}
\end{center}

\vspace{1em}

\section*{Why this chapter exists}

In previous chapters, we focused on:
\begin{itemize}
    \item dispersion curves $c(\omega)$,
    \item eigenvalues of the Rayleigh problem.
\end{itemize}

But an eigenvalue alone does not describe a wave.

This chapter answers:
\begin{quote}
\textbf{What does a Rayleigh wave actually look like as a function of depth?}
\end{quote}

The answer is given by the \textbf{eigenfunction}.



\section{Eigenvalues vs Eigenfunctions}

\subsection{Analogy from linear algebra}

In linear algebra:
\[
\bm{A}\bm{x} = \lambda \bm{x}
\]

\begin{itemize}
    \item $\lambda$ is the eigenvalue,
    \item $\bm{x}$ is the eigenvector.
\end{itemize}

The eigenvalue gives scale.
The eigenvector gives structure.

Rayleigh waves are no different.



\section{The Eigenvalue Problem Revisited}

At a Rayleigh mode:
\[
\bm{A}(k,\omega)\bm{a} = \bm{0}.
\]

Here:
\begin{itemize}
    \item $\bm{A}$ is the dispersion matrix,
    \item $\bm{a}$ is the null-space vector.
\end{itemize}

The vector $\bm{a}$ determines relative wave amplitudes.



\section{Modal Amplitude Vector}

For a half-space:
\[
\bm{a}
=
\begin{bmatrix}
A_P^- \\
A_S^-
\end{bmatrix}.
\]

For layered media:
\[
\bm{a}
=
\begin{bmatrix}
A_P^- \\
A_P^+ \\
A_S^- \\
A_S^+
\end{bmatrix}.
\]

This vector contains no depth dependence — only weights.



\section{Reconstructing the State Vector}

From Chapter 11:
\[
\boxed{
\bm{U}(z)
=
\bm{Y}\bm{D}(z)\bm{a}
}
\]

Recall:
\[
\bm{U}(z)
=
\begin{bmatrix}
u_x(z) \\
u_z(z) \\
\sigma_{xz}(z) \\
\sigma_{zz}(z)
\end{bmatrix}.
\]

Thus, the eigenfunction is obtained by direct substitution.



\section{Displacement Eigenfunctions}

The displacement components are:
\[
\boxed{
\begin{aligned}
u_x(z) &= \left[\bm{Y}_{1,:}\bm{D}(z)\bm{a}\right], \\
u_z(z) &= \left[\bm{Y}_{2,:}\bm{D}(z)\bm{a}\right].
\end{aligned}
}
\]

These are complex-valued functions of depth.

The physical displacement is:
\[
\Re\{\bm{u}(z)e^{i(kx-\omega t)}\}.
\]



\section{Depth Localization}

Rayleigh eigenfunctions:
\begin{itemize}
    \item decay exponentially with depth,
    \item are strongest near the surface.
\end{itemize}

This explains why:
\begin{itemize}
    \item Rayleigh waves are surface-sensitive,
    \item deeper layers are sampled by lower frequencies.
\end{itemize}



\section{Particle Motion}

\subsection{Elliptical motion}

At a fixed depth $z$, the particle trajectory is:
\[
x(t) = \Re\{u_x e^{-i\omega t}\},
\quad
z(t) = \Re\{u_z e^{-i\omega t}\}.
\]

This traces an ellipse.

Near the surface:
\begin{itemize}
    \item motion is retrograde,
    \item vertical motion dominates.
\end{itemize}



\section{Higher Modes}

Higher Rayleigh modes:
\begin{itemize}
    \item have nodes in depth,
    \item penetrate deeper,
    \item resemble standing waves trapped between layers.
\end{itemize}

This explains why:
\begin{itemize}
    \item higher modes are more sensitive to deeper structure,
    \item they appear only above cutoff frequencies.
\end{itemize}



\section{Why Eigenfunctions Are Not Unique}

If $\bm{a}$ is a solution, so is $C\bm{a}$.

Thus:
\[
\bm{u}(z) \quad \text{and} \quad C\bm{u}(z)
\]
represent the same physical mode.

Eigenfunctions must be normalized.



\section{Preview: Normalization and Energy}

In the next chapter, we will:
\begin{itemize}
    \item define modal energy,
    \item normalize eigenfunctions physically,
    \item compare modes quantitatively.
\end{itemize}

Normalization is essential for inversion.



\section*{Summary of Chapter 15}

You now understand:
\begin{itemize}
    \item the difference between eigenvalues and eigenfunctions,
    \item how displacement profiles are constructed,
    \item why Rayleigh waves are surface-localized,
    \item what higher modes represent physically.
\end{itemize}

This chapter explains the plots you generated of $u_x(z)$ and $u_z(z)$.
\pagebreak
\begin{center}
    {\Large \textbf{Chapter 16: Normalization and Energy Integrals}}
\end{center}

\vspace{1em}

\section*{Why this chapter exists}

In Chapter 15, we constructed Rayleigh wave eigenfunctions:
\[
u_x(z), \quad u_z(z).
\]

However, these functions are not unique:
\[
\bm{u}(z) \quad \text{and} \quad C\,\bm{u}(z)
\]
describe the same mode.

To:
\begin{itemize}
    \item compare modes,
    \item compute sensitivities,
    \item perform inversion,
\end{itemize}
we must \textbf{normalize} them.

Normalization requires defining \textbf{energy}.



\section{What Energy Means in Elastic Waves}

\subsection{Two forms of energy}

Elastic waves carry:
\begin{itemize}
    \item kinetic energy,
    \item strain (potential) energy.
\end{itemize}

For time-harmonic motion, these energies are equal on average.

We choose to work with kinetic energy.



\section{Kinetic Energy Density}

For a particle of density $\rho$ and velocity $\dot{\bm{u}}$:
\[
\boxed{
\mathcal{E}_K
=
\frac{1}{2}
\rho
\left|\dot{\bm{u}}\right|^2
}
\]

For time-harmonic motion:
\[
\bm{u}(t) = \Re\{\bm{u}e^{-i\omega t}\}
\quad \Rightarrow \quad
\dot{\bm{u}} = -i\omega \bm{u}.
\]

Thus:
\[
\boxed{
\mathcal{E}_K
=
\frac{1}{2}
\rho
\omega^2
\left(
|u_x|^2 + |u_z|^2
\right)
}
\]



\section{Depth-Integrated Modal Energy}

The total kinetic energy per unit surface area is:
\[
\boxed{
E
=
\frac{1}{2}
\omega^2
\int_0^{\infty}
\rho(z)
\left(
|u_x(z)|^2 + |u_z(z)|^2
\right)
dz
}
\]

This integral converges because Rayleigh modes decay with depth.



\section{Normalization Condition}

We define normalized eigenfunctions by requiring:
\[
\boxed{
\int_0^{\infty}
\rho(z)
\left(
|u_x(z)|^2 + |u_z(z)|^2
\right)
dz
=
1
}
\]

This choice:
\begin{itemize}
    \item removes arbitrary scaling,
    \item simplifies sensitivity kernels,
    \item is standard in surface-wave inversion.
\end{itemize}



\section{How Normalization Is Applied}

Given unnormalized eigenfunctions:
\[
u_x^{(0)}(z), \quad u_z^{(0)}(z),
\]

compute:
\[
N
=
\left[
\int_0^{\infty}
\rho(z)
\left(
|u_x^{(0)}|^2 + |u_z^{(0)}|^2
\right)
dz
\right]^{1/2}.
\]

Then define:
\[
\boxed{
u_x = \frac{u_x^{(0)}}{N},
\quad
u_z = \frac{u_z^{(0)}}{N}.
}
\]

This is exactly what your code does.



\section{Layered Media}

For layered Earth models:
\[
\int_0^{\infty}
\rightarrow
\sum_{j=1}^{N}
\int_{z_{j-1}}^{z_j}.
\]

Density $\rho(z)$ is piecewise constant.

The normalization integral becomes a sum over layers.



\section{Why Normalization Does Not Change Dispersion}

Important:
\[
\boxed{
\text{Normalization does NOT change phase velocity.}
}
\]

Dispersion depends only on:
\begin{itemize}
    \item boundary conditions,
    \item material contrasts.
\end{itemize}

Normalization affects:
\begin{itemize}
    \item amplitudes,
    \item energies,
    \item inversion kernels.
\end{itemize}



\section{Physical Interpretation}

After normalization:
\begin{itemize}
    \item each mode carries unit kinetic energy,
    \item amplitudes are comparable across frequencies,
    \item mode contributions can be weighted consistently.
\end{itemize}

This is essential for probabilistic inversion.



\section{Connection to Your Code}

Your function:
\[
\texttt{normalize\_mode(z, ux, uz, layers)}
\]
implements exactly:
\[
\int \rho(|u_x|^2 + |u_z|^2)\,dz = 1.
\]

The printed diagnostic:
\[
\texttt{Modal kinetic energy (before normalization)}
\]
is the value of $N^2$.



\section{Preview: Apparent Phase Velocity and Observables}

In real experiments:
\begin{itemize}
    \item receivers measure surface motion,
    \item phase velocity is inferred indirectly.
\end{itemize}

In the next chapter, we connect:
\[
\text{eigenfunctions} \rightarrow \text{observed dispersion}.
\]



\section*{Summary of Chapter 16}

You now understand:
\begin{itemize}
    \item why eigenfunctions need normalization,
    \item how modal energy is defined,
    \item why the energy integral converges,
    \item how normalization is implemented numerically.
\end{itemize}
\pagebreak
\begin{center}
    {\Large \textbf{Chapter 17: Apparent Phase Velocity and Observables}}
\end{center}

\vspace{1em}

\section*{Why this chapter exists}

Up to Chapter 16, we worked with:
\begin{itemize}
    \item exact eigenvalues $c(\omega)$,
    \item exact eigenfunctions $u_x(z), u_z(z)$,
    \item physically normalized modes.
\end{itemize}

But field data does not give us these directly.

This chapter answers:
\begin{quote}
\textbf{What does an experiment actually measure, and how does it relate to the Rayleigh modes we computed?}
\end{quote}



\section{What Is Measured in Practice}

\subsection{Surface motion}

A seismic station measures:
\[
\bm{u}(x=0,z=0,t).
\]

That is:
\begin{itemize}
    \item displacement at the surface,
    \item at discrete times,
    \item at discrete spatial locations.
\end{itemize}

No depth information is measured directly.



\section{Phase Velocity vs Apparent Phase Velocity}

\subsection{True phase velocity}

From theory:
\[
c(\omega) = \frac{\omega}{k}.
\]

This is an eigenvalue of the boundary-value problem.



\subsection{Apparent phase velocity}

In experiments, velocity is inferred from:
\[
\Delta \phi(\omega) = k(\omega)\,\Delta x,
\]

so that:
\[
\boxed{
c_{\text{app}}(\omega)
=
\frac{\omega\,\Delta x}{\Delta \phi(\omega)}.
}
\]

This is called the \textbf{apparent phase velocity}.



\section{Why the Apparent Velocity Can Differ}

If:
\begin{itemize}
    \item only one mode dominates,
    \item signal-to-noise ratio is high,
\end{itemize}

then:
\[
c_{\text{app}} \approx c_R.
\]

But if:
\begin{itemize}
    \item multiple modes interfere,
    \item amplitudes vary with frequency,
\end{itemize}

then:
\[
c_{\text{app}} \neq c_j.
\]

This is crucial for interpretation.



\section{Modal Superposition at the Surface}

The surface displacement is:
\[
u_x(0,\omega)
=
\sum_j A_j(\omega)\, u_x^{(j)}(0,\omega),
\]
\[
u_z(0,\omega)
=
\sum_j A_j(\omega)\, u_z^{(j)}(0,\omega).
\]

Each mode contributes with a frequency-dependent weight.



\section{Why Fundamental Mode Dominates}

The fundamental Rayleigh mode:
\begin{itemize}
    \item has largest surface amplitude,
    \item decays most slowly with depth,
    \item carries most energy near the surface.
\end{itemize}

Thus:
\[
A_0(\omega) \gg A_{j>0}(\omega)
\]
in many surveys.

This justifies single-mode inversion at first order.



\section{Depth Sensitivity and Wavelength}

The effective sampling depth of a Rayleigh wave is:
\[
\boxed{
z_{\text{sens}} \sim \frac{\lambda}{2}
=
\frac{c(\omega)}{2f}.
}
\]

Thus:
\begin{itemize}
    \item high frequency → shallow sensitivity,
    \item low frequency → deep sensitivity.
\end{itemize}

This explains dispersion-based inversion.



\section{Apparent Velocity from Eigenfunctions}

Using normalized eigenfunctions:
\[
c_{\text{app}}(\omega)
\approx
\frac{
\int \rho(z)\, \omega^2 |u(z)|^2 dz
}{
\int \rho(z)\, k \omega |u(z)|^2 dz
}.
\]

This expression connects:
\begin{itemize}
    \item modal energy,
    \item observed phase velocity.
\end{itemize}

Your code approximates this implicitly.



\section{Group Velocity (Preview)}

Phase velocity describes:
\begin{itemize}
    \item phase propagation.
\end{itemize}

Energy travels at the \textbf{group velocity}:
\[
c_g = \frac{d\omega}{dk}.
\]

Group velocity controls:
\begin{itemize}
    \item wave packets,
    \item arrival times,
    \item amplitude focusing.
\end{itemize}

We return to this later.



\section{Why Dispersion Curves Are Enough}

For inversion:
\begin{itemize}
    \item apparent phase velocity curves are sufficient,
    \item full waveform modeling is not required initially.
\end{itemize}

This is why Rayleigh dispersion inversion is powerful and stable.



\section{Connection to Your Forward Model}

Your forward model provides:
\begin{itemize}
    \item $c_j(\omega)$ (true phase velocity),
    \item $u_x^{(j)}(z), u_z^{(j)}(z)$ (mode shapes),
    \item normalized modal energies.
\end{itemize}

This is exactly what is needed to interpret observations.



\section{Preview: Inversion as an Optimization Problem}

We now have:
\begin{itemize}
    \item a forward map: $\text{model} \rightarrow c(\omega)$,
    \item observed dispersion curves.
\end{itemize}

The next step:
\[
\text{find the model that best explains the data}.
\]

This is the inverse problem.



\section*{Summary of Chapter 17}

You now understand:
\begin{itemize}
    \item what apparent phase velocity means,
    \item how it is measured,
    \item why it approximates Rayleigh velocity,
    \item why dispersion curves encode depth information.
\end{itemize}
\pagebreak
\begin{center}
    {\Large \textbf{Chapter 18: Inverse Problem Formulation}}
\end{center}

\vspace{1em}

\section*{Why this chapter exists}

Up to Chapter 17, we constructed a complete \emph{forward model}:
\[
\text{Earth model} \;\longrightarrow\; \text{Rayleigh dispersion curves}.
\]

But in practice, we face the opposite situation.

We observe:
\[
\text{Rayleigh dispersion curves},
\]
and want to infer:
\[
\text{Earth structure}.
\]

This reversal is the \textbf{inverse problem}.



\section{What Is an Inverse Problem?}

\subsection{Forward vs inverse}

Let:
\[
\bm{m} = \text{model parameters},
\qquad
\bm{d} = \text{observed data}.
\]

The forward problem is:
\[
\boxed{
\bm{d} = \mathcal{F}(\bm{m})
}
\]

The inverse problem asks:
\[
\boxed{
\text{Given } \bm{d}, \text{ find } \bm{m}.
}
\]

This problem is fundamentally harder.



\section{What Is the Model Vector?}

For layered Rayleigh-wave inversion, a typical model vector is:
\[
\bm{m}
=
\begin{bmatrix}
V_{S,1} \\
V_{S,2} \\
\vdots \\
V_{S,N}
\end{bmatrix}
\]

Why $V_S$?
\begin{itemize}
    \item Rayleigh waves are most sensitive to shear velocity,
    \item sensitivity to $V_P$ and $\rho$ is weaker.
\end{itemize}

This choice simplifies the inverse problem.



\section{What Is the Data Vector?}

The data vector consists of observed phase velocities:
\[
\bm{d}
=
\begin{bmatrix}
c_{\text{obs}}(\omega_1) \\
c_{\text{obs}}(\omega_2) \\
\vdots \\
c_{\text{obs}}(\omega_M)
\end{bmatrix}
\]

Each entry corresponds to one frequency.



\section{The Forward Operator}

Using your code, the forward operator is:
\[
\mathcal{F}(\bm{m})
=
\begin{bmatrix}
c(\omega_1;\bm{m}) \\
c(\omega_2;\bm{m}) \\
\vdots \\
c(\omega_M;\bm{m})
\end{bmatrix}
\]

This mapping is:
\begin{itemize}
    \item nonlinear,
    \item implicit,
    \item computationally expensive.
\end{itemize}



\section{Why the Inverse Problem Is Ill-Posed}

According to Hadamard, a well-posed problem must:
\begin{enumerate}
    \item have a solution,
    \item have a unique solution,
    \item depend continuously on data.
\end{enumerate}

Rayleigh-wave inversion violates all three.



\subsection{Non-uniqueness}

Different models can produce almost identical dispersion curves:
\[
\mathcal{F}(\bm{m}_1) \approx \mathcal{F}(\bm{m}_2).
\]

This explains the flat misfit valley you observed.



\subsection{Instability}

Small noise in $c_{\text{obs}}$ can produce large changes in $\bm{m}$.

This is why regularization is required.



\section{Inversion as Optimization}

We recast inversion as minimization.

Define the misfit function:
\[
\boxed{
\Phi(\bm{m})
=
\frac{1}{2}
\sum_{i=1}^{M}
\left[
c_{\text{obs}}(\omega_i)
-
c(\omega_i;\bm{m})
\right]^2
}
\]

The inverse problem becomes:
\[
\boxed{
\bm{m}^*
=
\arg\min_{\bm{m}} \Phi(\bm{m})
}
\]

This is exactly what your least-squares code solved.



\section{Gradient-Based Inversion}

Iterative methods update:
\[
\bm{m}_{k+1}
=
\bm{m}_k
-
\alpha_k
\nabla \Phi(\bm{m}_k).
\]

The gradient requires sensitivity kernels:
\[
\frac{\partial c(\omega)}{\partial V_{S,j}}.
\]

These depend on eigenfunctions.



\section{Why Your Sanity-Check Inversion Looked Strange}

You observed:
\begin{itemize}
    \item correct dispersion fit,
    \item incorrect recovered $V_S$.
\end{itemize}

This is not an error.

It is a direct consequence of:
\begin{itemize}
    \item limited frequency bandwidth,
    \item depth-averaging of Rayleigh waves,
    \item trade-offs between layers.
\end{itemize}

This confirms your forward model is correct.



\section{Regularization}

To stabilize inversion, we add a penalty:
\[
\Phi_{\text{reg}}(\bm{m})
=
\Phi(\bm{m})
+
\lambda
\|\bm{L}(\bm{m}-\bm{m}_0)\|^2.
\]

Here:
\begin{itemize}
    \item $\bm{m}_0$ is a prior model,
    \item $\bm{L}$ enforces smoothness,
    \item $\lambda$ controls strength.
\end{itemize}

This is essential in practice.



\section{Bayesian Interpretation (Preview)}

In Bayesian inversion:
\[
P(\bm{m}|\bm{d})
\propto
P(\bm{d}|\bm{m}) P(\bm{m}).
\]

The misfit is the negative log-likelihood.

This connects inversion to probability.



\section{Connection to Your Project}

Your project plan:
\begin{itemize}
    \item finish accurate forward modeling \checkmark
    \item understand non-uniqueness \checkmark
    \item move to probabilistic inversion \checkmark
\end{itemize}

You are exactly on track.



\section*{Summary of Chapter 18}

You now understand:
\begin{itemize}
    \item what an inverse problem is,
    \item why Rayleigh inversion is ill-posed,
    \item how misfit functions are constructed,
    \item why regularization is necessary.
\end{itemize}
\pagebreak
\begin{center}
    {\Large \textbf{Chapter 19: Sensitivity Kernels}}
\end{center}

\vspace{1em}

\section*{Why this chapter exists}

In Chapter 18, we saw that Rayleigh-wave inversion is:
\begin{itemize}
    \item non-unique,
    \item depth-averaged,
    \item ill-posed.
\end{itemize}

This chapter answers the fundamental question:

\begin{quote}
\textbf{How does a Rayleigh wave “sense” changes in Earth structure at depth?}
\end{quote}

The answer is given by \textbf{sensitivity kernels}.



\section{What Is a Sensitivity Kernel?}

\subsection{Basic idea}

Suppose we perturb the shear velocity:
\[
V_S(z) \rightarrow V_S(z) + \delta V_S(z).
\]

The Rayleigh phase velocity changes:
\[
c(\omega) \rightarrow c(\omega) + \delta c(\omega).
\]

For small perturbations:
\[
\boxed{
\delta c(\omega)
=
\int_0^{\infty}
K_{V_S}(z,\omega)\,
\delta V_S(z)\, dz
}
\]

The function $K_{V_S}$ is the sensitivity kernel.



\section{Interpretation of the Kernel}

The kernel answers:
\begin{itemize}
    \item where the wave is sensitive,
    \item how strongly it responds,
    \item how depth contributions are weighted.
\end{itemize}

It is not arbitrary.
It is determined by eigenfunctions.



\section{Why Rayleigh Waves Are Depth-Averaging}

Rayleigh eigenfunctions decay with depth:
\[
|u(z)| \sim e^{-qz}.
\]

Thus:
\begin{itemize}
    \item shallow layers dominate high-frequency kernels,
    \item deeper layers contribute only at low frequencies.
\end{itemize}

No Rayleigh wave is localized at a single depth.



\section{Formal Derivation (Variational Principle)}

\subsection{Perturbing the dispersion relation}

The dispersion condition is:
\[
\det \bm{A}(k,\omega;\bm{m}) = 0.
\]

Perturb the model $\bm{m}$:
\[
\bm{m} \rightarrow \bm{m} + \delta \bm{m}.
\]

Differentiate implicitly:
\[
\pdv{\det \bm{A}}{\bm{m}} \cdot \delta \bm{m}
+
\pdv{\det \bm{A}}{c} \delta c = 0.
\]

This yields:
\[
\delta c = - \frac{\pdv{\det \bm{A}}{\bm{m}}}{\pdv{\det \bm{A}}{c}} \cdot \delta \bm{m}.
\]



\section{Kernel Expression Using Eigenfunctions}

After algebra, the kernel for shear velocity becomes:
\[
\boxed{
K_{V_S}(z,\omega)
\propto
\rho(z)
\left[
|u_x(z)|^2
+
|u_z(z)|^2
\right]
}
\]

This is the most important result in surface-wave theory.



\section{Why the Kernel Is Always Positive}

Because:
\begin{itemize}
    \item it depends on squared amplitudes,
    \item energy density is positive definite.
\end{itemize}

Thus:
\[
\delta V_S > 0
\quad \Rightarrow \quad
\delta c > 0.
\]

This explains monotonic behavior.



\section{Normalized Kernels}

Using normalized eigenfunctions:
\[
\int_0^{\infty} K_{V_S}(z,\omega)\,dz = 1.
\]

This makes kernels directly interpretable as depth weights.



\section{Kernels in Layered Media}

For layered Earth models:
\[
\delta c
=
\sum_{j=1}^{N}
K_j(\omega)\,\delta V_{S,j}.
\]

Each $K_j$ is an integral of the continuous kernel over a layer.

This explains why inversion parameters are layer-averaged.



\section{Resolution Limits}

A layer thinner than:
\[
\sim \frac{\lambda}{4}
\]
cannot be resolved.

This is a physical limit, not a numerical one.



\section{Why Trade-Offs Occur}

If two layers have overlapping kernels:
\[
K_1(z) \approx K_2(z),
\]
then:
\[
\delta V_{S,1} \text{ and } \delta V_{S,2}
\]
produce similar effects.

This leads to non-uniqueness.



\section{Connection to Your Misfit Surface}

Your misfit surface:
\begin{itemize}
    \item elongated valley,
    \item flat directions.
\end{itemize}

This is the geometric manifestation of kernel overlap.

The code is correct.
The physics demands it.



\section{Why Sensitivity Kernels Matter for Anisotropy}

Anisotropic parameters:
\begin{itemize}
    \item modify eigenfunctions,
    \item redistribute kernel weight.
\end{itemize}

Understanding isotropic kernels is essential before extending the model.



\section{Preview: What Comes After}

You now have:
\begin{itemize}
    \item complete forward model,
    \item eigenfunctions,
    \item normalization,
    \item sensitivity kernels.
\end{itemize}

The next step is uncertainty-aware inversion.



\section*{Summary of Chapter 19}

You now understand:
\begin{itemize}
    \item what sensitivity kernels are,
    \item why Rayleigh waves average in depth,
    \item why inversion is non-unique,
    \item how eigenfunctions control resolution.
\end{itemize}
\pagebreak
\begin{center}
    {\Large \textbf{Chapter 20: Probabilistic Inversion}}
\end{center}

\vspace{1em}

\section*{Why this chapter exists}

In Chapter 18, we formulated inversion as:
\[
\bm{m}^* = \arg\min \Phi(\bm{m}),
\]
which gives a single “best-fit” model.

But Chapter 19 showed:
\begin{itemize}
    \item many models fit the data nearly equally well,
    \item misfit valleys are flat,
    \item solutions are non-unique.
\end{itemize}

This chapter answers:
\begin{quote}
\textbf{How do we describe \emph{all} models consistent with the data?}
\end{quote}

The answer is probability.



\section{From Deterministic to Probabilistic Thinking}

\subsection{The key shift}

Instead of asking:
\[
\text{What is the best model?}
\]

we ask:
\[
\boxed{
\text{What models are plausible, and how plausible are they?}
}
\]

This is a conceptual shift, not just a technical one.



\section{Bayes’ Theorem}

The foundation is Bayes’ theorem:
\[
\boxed{
P(\bm{m} \mid \bm{d})
=
\frac{
P(\bm{d} \mid \bm{m}) \, P(\bm{m})
}{
P(\bm{d})
}
}
\]

Where:
\begin{itemize}
    \item $P(\bm{m} \mid \bm{d})$ = posterior (what we want),
    \item $P(\bm{d} \mid \bm{m})$ = likelihood,
    \item $P(\bm{m})$ = prior,
    \item $P(\bm{d})$ = evidence (normalization).
\end{itemize}



\section{Likelihood Function}

\subsection{Noise model}

Assume observed dispersion data:
\[
\bm{d}_{\text{obs}} = \bm{d}(\bm{m}) + \bm{\epsilon},
\]
with Gaussian noise:
\[
\bm{\epsilon} \sim \mathcal{N}(0,\sigma^2).
\]

Then the likelihood is:
\[
\boxed{
P(\bm{d}_{\text{obs}} \mid \bm{m})
\propto
\exp\!\left(
-\frac{1}{2\sigma^2}
\|\bm{d}_{\text{obs}} - \mathcal{F}(\bm{m})\|^2
\right)
}
\]

Notice: the exponent is exactly the least-squares misfit.



\section{Prior Information}

\subsection{Why priors matter}

Because the problem is ill-posed:
\begin{itemize}
    \item data alone cannot constrain all parameters,
    \item prior knowledge stabilizes inversion.
\end{itemize}

Examples of priors:
\begin{itemize}
    \item smoothness,
    \item bounds on $V_S$,
    \item geological layering.
\end{itemize}



\subsection{Gaussian prior}

A common choice:
\[
\boxed{
P(\bm{m})
\propto
\exp\!\left(
-\frac{1}{2}
\|\bm{L}(\bm{m} - \bm{m}_0)\|^2
\right)
}
\]

This penalizes rough models.



\section{Posterior Distribution}

Combining likelihood and prior:
\[
\boxed{
P(\bm{m} \mid \bm{d})
\propto
\exp\!\left(
-\Phi(\bm{m})
-
\frac{1}{2}
\|\bm{L}(\bm{m} - \bm{m}_0)\|^2
\right)
}
\]

Thus:
\begin{itemize}
    \item least-squares inversion finds the \emph{mode} of the posterior,
    \item probabilistic inversion characterizes its \emph{shape}.
\end{itemize}



\section{What the Posterior Tells Us}

From $P(\bm{m} \mid \bm{d})$, we can compute:
\begin{itemize}
    \item mean model,
    \item standard deviations,
    \item parameter correlations,
    \item uncertainty bounds.
\end{itemize}

These are scientifically meaningful results.



\section{Sampling the Posterior}

\subsection{Why sampling is needed}

The posterior lives in a high-dimensional space.

We cannot visualize it directly.

We approximate it using samples.



\subsection{Markov Chain Monte Carlo (MCMC)}

MCMC generates samples:
\[
\bm{m}_1, \bm{m}_2, \dots \sim P(\bm{m} \mid \bm{d}).
\]

Each sample:
\begin{itemize}
    \item is a valid Earth model,
    \item fits the data within noise.
\end{itemize}

The ensemble tells the full story.



\section{Connection to FW-MDN}

FW-MDN learns:
\[
P(\bm{m} \mid \bm{d})
\]
directly using a neural network.

Instead of sampling explicitly:
\begin{itemize}
    \item the network outputs a distribution,
    \item non-uniqueness is built in.
\end{itemize}

This is exactly aligned with your project plan.



\section{Why Probabilistic Inversion Is Honest}

Deterministic inversion hides uncertainty.

Probabilistic inversion:
\begin{itemize}
    \item reveals trade-offs,
    \item avoids false confidence,
    \item matches physical reality.
\end{itemize}

This is why modern research has moved here.



\section{Preview: Where Nonlocal Physics Fits}

Nonlocal elasticity:
\begin{itemize}
    \item adds new parameters,
    \item increases non-uniqueness.
\end{itemize}

Probabilistic methods are \emph{required} to handle this.



\section*{Summary of Chapter 20}

You now understand:
\begin{itemize}
    \item why deterministic inversion is insufficient,
    \item how Bayesian inversion is formulated,
    \item how misfit becomes likelihood,
    \item why probability is the natural language.
\end{itemize}
\pagebreak
\begin{center}
    {\Large \textbf{Chapter 21: Nonlocal Elasticity}}
\end{center}

\vspace{1em}

\section*{Why this chapter exists}

All previous chapters assumed \textbf{local elasticity}:
\begin{quote}
\emph{Stress at a point depends only on strain at that same point.}
\end{quote}

This assumption works well at macroscopic scales.

But many real materials exhibit:
\begin{itemize}
    \item microstructure,
    \item long-range interactions,
    \item size-dependent behavior.
\end{itemize}

This chapter explains:
\begin{quote}
\textbf{Why local elasticity fails and how nonlocal elasticity generalizes it.}
\end{quote}



\section{The Local Constitutive Law}

In classical elasticity:
\[
\boxed{
\sigma_{ij}(\bm{x})
=
C_{ijkl}(\bm{x})\, \varepsilon_{kl}(\bm{x})
}
\]

This law assumes:
\begin{itemize}
    \item perfect locality,
    \item no internal length scale.
\end{itemize}

As a result:
\begin{itemize}
    \item wave speeds are scale-independent,
    \item dispersion arises only from layering.
\end{itemize}



\section{Why Local Elasticity Breaks Down}

Local elasticity fails when:
\begin{itemize}
    \item wavelengths approach grain size,
    \item materials have internal heterogeneity,
    \item long-range forces are present.
\end{itemize}

Observed consequences:
\begin{itemize}
    \item anomalous dispersion,
    \item size effects,
    \item frequency-dependent stiffness.
\end{itemize}

These cannot be explained by local theory.



\section{The Core Idea of Nonlocal Elasticity}

The key idea is simple but profound:

\begin{quote}
\textbf{Stress at a point depends on strain in a neighborhood.}
\end{quote}

Mathematically:
\[
\boxed{
\sigma_{ij}(\bm{x})
=
\int_{\Omega}
C_{ijkl}(\bm{x},\bm{x}')
\,\varepsilon_{kl}(\bm{x}')
\, d\bm{x}'
}
\]

This replaces multiplication by convolution.



\section{Seismic Impedance Tensor Formulation}

A commonly used form is:
\[
\boxed{
\sigma_{ij}(\bm{x})
=
\int_{\Omega}
V(|\bm{x}-\bm{x}'|)
\, C_{ijkl}(\bm{x}')
\, \varepsilon_{kl}(\bm{x}')
\, d\bm{x}'
}
\]

Where:
\begin{itemize}
    \item $C_{ijkl}$ is anisotropic stiffness,
    \item $V(r)$ is a nonlocal kernel.
\end{itemize}

This is exactly the form in your proposal.



\section{The Nonlocal Kernel}

\subsection{Physical meaning}

The kernel $V(r)$:
\begin{itemize}
    \item weights distant interactions,
    \item introduces a material length scale $\ell$.
\end{itemize}

Typical properties:
\[
\int V(r)\,dr = 1,
\qquad
V(r) \to 0 \text{ as } r \to \infty.
\]



\subsection{Common kernel choices}

Examples:
\[
V(r) = \frac{1}{2\ell} e^{-r/\ell}
\quad \text{(exponential)}
\]

\[
V(r) = \frac{1}{\sqrt{2\pi}\ell} e^{-r^2/2\ell^2}
\quad \text{(Gaussian)}
\]

The parameter $\ell$ controls nonlocality strength.



\section{Reduction to Local Elasticity}

As $\ell \to 0$:
\[
V(|\bm{x}-\bm{x}'|)
\to
\delta(\bm{x}-\bm{x}')
\]

Thus:
\[
\sigma_{ij}(\bm{x}) \to C_{ijkl}(\bm{x})\,\varepsilon_{kl}(\bm{x})
\]

Local elasticity is a special case.



\section{Nonlocal Wave Equation}

Substituting the nonlocal law into momentum balance:
\[
\rho \ddot{u}_i
=
\partial_j
\int V(|\bm{x}-\bm{x}'|)
\, C_{ijkl}(\bm{x}')
\, \varepsilon_{kl}(\bm{x}')
\, d\bm{x}'
\]

This is an integro-differential equation.



\section{Why Nonlocality Produces Dispersion}

In Fourier space:
\[
\boxed{
\sigma_{ij}(\bm{k})
=
\hat{V}(k)\,
C_{ijkl}\,
\varepsilon_{kl}(\bm{k})
}
\]

Where:
\[
\hat{V}(k) = \text{Fourier transform of } V(r).
\]

Thus:
\begin{itemize}
    \item stiffness becomes wavenumber-dependent,
    \item wave speed depends on frequency.
\end{itemize}

Dispersion now arises even in homogeneous media.



\section{Implications for Rayleigh Waves}

Nonlocality modifies:
\begin{itemize}
    \item vertical slowness $q_P, q_S$,
    \item decay rates,
    \item dispersion curves.
\end{itemize}

Rayleigh waves become sensitive to:
\begin{itemize}
    \item material length scale $\ell$,
    \item microstructural effects.
\end{itemize}



\section{Why This Matters for Your Project}

Your guide’s project statement:
\begin{itemize}
    \item layered,
    \item anisotropic,
    \item nonlocal Earth media.
\end{itemize}

Nonlocal elasticity:
\begin{itemize}
    \item extends classical theory,
    \item explains unexplained dispersion,
    \item introduces new inversion parameters.
\end{itemize}

This is genuine novelty.



\section{Computational Strategy (Preview)}

Direct integro-differential solvers are expensive.

Instead:
\begin{itemize}
    \item work in Fourier domain,
    \item modify stiffness tensors,
    \item reuse the existing forward model.
\end{itemize}

This is how your current code will be extended.



\section*{Summary of Chapter 21}

You now understand:
\begin{itemize}
    \item what nonlocal elasticity means physically,
    \item how it generalizes classical elasticity,
    \item why it introduces intrinsic dispersion,
    \item how it fits naturally into Rayleigh-wave theory.
\end{itemize}
\pagebreak
\begin{center}
    {\Large \textbf{Chapter 22: Anisotropy and Tensorial Elasticity}}
\end{center}

\vspace{1em}

\section*{Why this chapter exists}

All previous chapters assumed \textbf{isotropy}:
\begin{quote}
Material properties are identical in all directions.
\end{quote}

Real Earth materials are rarely isotropic.

This chapter explains:
\begin{quote}
\textbf{How elastic behavior depends on direction, and how to model it mathematically.}
\end{quote}

This is essential for:
\begin{itemize}
    \item realistic crustal models,
    \item layered sediments,
    \item fractured and textured media,
    \item anisotropic nonlocal elasticity.
\end{itemize}



\section{Isotropy Revisited}

In isotropic elasticity:
\[
\sigma_{ij} = \lambda \delta_{ij}\varepsilon_{kk} + 2\mu \varepsilon_{ij}.
\]

Only two parameters exist:
\begin{itemize}
    \item $\lambda$,
    \item $\mu$.
\end{itemize}

This extreme simplicity hides internal structure.



\section{What Is Anisotropy?}

Anisotropy means:
\begin{quote}
\textbf{Material response depends on direction of deformation.}
\end{quote}

Examples:
\begin{itemize}
    \item sedimentary layering,
    \item aligned cracks,
    \item mineral fabric,
    \item stress-induced anisotropy.
\end{itemize}

Wave speeds differ by direction.



\section{General Elastic Constitutive Law}

The most general linear elastic law is:
\[
\boxed{
\sigma_{ij}
=
C_{ijkl}\,\varepsilon_{kl}
}
\]

Where:
\begin{itemize}
    \item $C_{ijkl}$ is the stiffness tensor,
    \item it has four indices.
\end{itemize}

This tensor encodes all directional behavior.



\section{Symmetries of the Stiffness Tensor}

Physical constraints impose:
\[
C_{ijkl} = C_{jikl} = C_{ijlk} = C_{klij}.
\]

These symmetries reduce independent components.

In 3D:
\begin{itemize}
    \item 81 components initially,
    \item only 21 independent remain.
\end{itemize}



\section{Voigt Notation}

To simplify notation, we use Voigt indexing:
\[
\begin{aligned}
11 &\rightarrow 1, \\
22 &\rightarrow 2, \\
33 &\rightarrow 3, \\
23,32 &\rightarrow 4, \\
13,31 &\rightarrow 5, \\
12,21 &\rightarrow 6.
\end{aligned}
\]

Then:
\[
\boxed{
\sigma_\alpha = C_{\alpha\beta}\varepsilon_\beta
}
\]

with $C$ a $6\times6$ matrix.



\section{Common Anisotropic Symmetries}

\subsection{Transverse isotropy (TI)}

Most common in seismology.

Properties:
\begin{itemize}
    \item isotropic in a plane,
    \item different along symmetry axis.
\end{itemize}

Vertical TI (VTI) is widely used.



\subsection{VTI stiffness matrix}

For VTI:
\[
C =
\begin{bmatrix}
C_{11} & C_{12} & C_{13} & 0 & 0 & 0 \\
C_{12} & C_{11} & C_{13} & 0 & 0 & 0 \\
C_{13} & C_{13} & C_{33} & 0 & 0 & 0 \\
0 & 0 & 0 & C_{44} & 0 & 0 \\
0 & 0 & 0 & 0 & C_{44} & 0 \\
0 & 0 & 0 & 0 & 0 & C_{66}
\end{bmatrix}
\]

Only five independent parameters remain.



\section{Wave Propagation in Anisotropic Media}

In anisotropic media:
\begin{itemize}
    \item P and S waves are no longer pure,
    \item wave polarization depends on direction,
    \item phase velocity differs from group velocity.
\end{itemize}

This complicates Rayleigh waves.



\section{Christoffel Equation}

Plane-wave propagation is governed by:
\[
\boxed{
\left(
\Gamma_{ij} - \rho v^2 \delta_{ij}
\right) u_j = 0
}
\]

Where:
\[
\Gamma_{ij} = C_{ijkl} n_k n_l
\]

is the Christoffel matrix.



\section{Anisotropic Rayleigh Waves}

In anisotropic media:
\begin{itemize}
    \item vertical slownesses become tensorial,
    \item multiple evanescent modes exist,
    \item surface waves split and hybridize.
\end{itemize}

Rayleigh waves are no longer unique.



\section{State Vector in Anisotropic Media}

The state vector remains:
\[
\bm{U} =
\begin{bmatrix}
u_x \\
u_z \\
\sigma_{xz} \\
\sigma_{zz}
\end{bmatrix}
\]

But:
\begin{itemize}
    \item $Y$-matrix entries change,
    \item $q_P, q_S$ are replaced by eigenvalues of $\Gamma$.
\end{itemize}

This allows reuse of the propagator framework.



\section{Why Anisotropy Matters for Inversion}

Anisotropy introduces:
\begin{itemize}
    \item directional sensitivity,
    \item additional trade-offs,
    \item frequency-dependent polarization.
\end{itemize}

Ignoring anisotropy can bias $V_S$ estimates.



\section{Connection to Nonlocal Elasticity}

In nonlocal anisotropic media:
\[
C_{ijkl} \rightarrow C_{ijkl}(\bm{x},\bm{x}')
\]

The kernel modifies:
\begin{itemize}
    \item stiffness magnitude,
    \item directional coupling.
\end{itemize}

This is the full physics target of your project.



\section{Computational Strategy}

Practically:
\begin{itemize}
    \item modify stiffness tensor in Fourier space,
    \item recompute $Y$-matrices,
    \item reuse propagators and dispersion solvers.
\end{itemize}

Your current code structure is ideal for this.



\section*{Summary of Chapter 22}

You now understand:
\begin{itemize}
    \item what elastic anisotropy is,
    \item how stiffness tensors encode direction,
    \item how Rayleigh waves change in anisotropic media,
    \item why this extension is physically necessary.
\end{itemize}
\pagebreak
\begin{center}
    {\Large \textbf{Chapter 23: Unified Anisotropic–Nonlocal Rayleigh Model}}
\end{center}

\vspace{1em}

\section*{Why this chapter exists}

Up to now, we developed:
\begin{itemize}
    \item classical Rayleigh waves,
    \item layered propagator formulation,
    \item eigenfunctions and normalization,
    \item sensitivity kernels and inversion,
    \item nonlocal elasticity,
    \item anisotropic stiffness tensors.
\end{itemize}

This chapter answers the final forward-model question:

\begin{quote}
\textbf{How do we write one single Rayleigh-wave model that includes layering, anisotropy, and nonlocal physics?}
\end{quote}

This is the mathematical core of your first paper.



\section{Unified Constitutive Law}

We start from the generalized nonlocal anisotropic elasticity law:
\[
\boxed{
\sigma_{ij}(\bm{x})
=
\int_{\Omega}
V(|\bm{x}-\bm{x}'|)
\,
C_{ijkl}(\bm{x}')
\,
\varepsilon_{kl}(\bm{x}')
\, d\bm{x}'
}
\]

Where:
\begin{itemize}
    \item $C_{ijkl}$ is anisotropic stiffness,
    \item $V(r)$ is the nonlocal kernel,
    \item $\Omega$ spans the layered half-space.
\end{itemize}

This single equation replaces the classical Hooke’s law.



\section{Fourier Representation}

Assuming horizontal invariance and time-harmonic motion:
\[
\bm{u}(x,z,t)
=
\bm{u}(z)\,e^{i(kx-\omega t)}.
\]

The convolution becomes multiplication in $k$-space:
\[
\boxed{
\sigma_{ij}(k,z)
=
\hat{V}(k)
\,
C_{ijkl}(z)
\,
\varepsilon_{kl}(k,z)
}
\]

Thus:
\begin{itemize}
    \item nonlocality modifies stiffness,
    \item anisotropy controls directionality.
\end{itemize}



\section{Effective Stiffness Tensor}

Define the effective stiffness:
\[
\boxed{
\tilde{C}_{ijkl}(k,z)
=
\hat{V}(k)\,
C_{ijkl}(z)
}
\]

This tensor:
\begin{itemize}
    \item depends on wavenumber,
    \item reduces to classical elasticity when $\hat{V}(k)=1$.
\end{itemize}

All nonlocal physics is absorbed here.



\section{Modified Christoffel Equation}

Wave propagation is governed by:
\[
\left(
\tilde{\Gamma}_{ij}(k)
-
\rho v^2 \delta_{ij}
\right) u_j = 0,
\quad
\tilde{\Gamma}_{ij}
=
\tilde{C}_{ijkl} n_k n_l.
\]

Vertical slownesses are now eigenvalues of $\tilde{\Gamma}$.



\section{State Vector Formulation}

The state vector remains unchanged:
\[
\bm{U}(z)
=
\begin{bmatrix}
u_x \\
u_z \\
\sigma_{xz} \\
\sigma_{zz}
\end{bmatrix}
\]

But:
\begin{itemize}
    \item $\sigma_{ij}$ uses $\tilde{C}_{ijkl}$,
    \item $Y$-matrices become $k$-dependent.
\end{itemize}

This preserves numerical structure.



\section{Layerwise Propagators}

For each layer:
\[
\bm{P}_\ell(k,\omega)
=
\bm{Y}_\ell(k)
\bm{D}_\ell(k,h_\ell)
\bm{Y}_\ell^{-1}(k)
\]

Where:
\begin{itemize}
    \item anisotropy enters via $C_{ijkl}^{(\ell)}$,
    \item nonlocality enters via $\hat{V}(k)$.
\end{itemize}

No change to stacking logic is required.



\section{Global Dispersion Condition}

As before:
\[
\boxed{
\det \bm{A}(k,\omega) = 0
}
\]

But now:
\begin{itemize}
    \item $\bm{A}$ includes anisotropic–nonlocal physics,
    \item dispersion arises from three mechanisms:
    \begin{itemize}
        \item layering,
        \item anisotropy,
        \item nonlocality.
    \end{itemize}
\end{itemize}

This is a new, publishable forward model.



\section{Limiting Cases}

The model recovers known results:

\begin{itemize}
    \item $\hat{V}(k)=1$ → anisotropic local Rayleigh waves
    \item isotropic $C_{ijkl}$ → nonlocal isotropic Rayleigh waves
    \item both → classical layered Rayleigh waves
\end{itemize}

This guarantees physical consistency.



\section{New Observables}

The unified model predicts:
\begin{itemize}
    \item frequency-dependent stiffness,
    \item mode splitting,
    \item altered penetration depths,
    \item anomalous dispersion.
\end{itemize}

These are signatures you can test against data.



\section{Inversion Implications}

New parameters include:
\begin{itemize}
    \item anisotropic stiffness components,
    \item nonlocal length scale $\ell$.
\end{itemize}

These increase non-uniqueness — hence probabilistic inversion is essential.



\section{Computational Feasibility}

Crucially:
\begin{itemize}
    \item the forward model reuses your existing code,
    \item only $Y$-matrix construction changes,
    \item complexity grows moderately.
\end{itemize}

This is why your guide insisted on finishing the local model first.



\section{What Makes This a Paper}

This chapter defines:
\begin{itemize}
    \item a new forward operator,
    \item a clear reduction to classical theory,
    \item a pathway to inversion.
\end{itemize}

This is sufficient for:
\begin{itemize}
    \item a methods paper,
    \item followed by application and inversion papers.
\end{itemize}



\section*{Summary of Chapter 23}

You now have:
\begin{itemize}
    \item one unified Rayleigh-wave model,
    \item consistent physics across scales,
    \item a clean computational framework,
    \item a defensible research contribution.
\end{itemize}

\pagebreak
\begin{center}
    {\Large \textbf{Chapter 24: Numerical Implementation Strategy}}
\end{center}

\vspace{1em}

\section*{Why this chapter exists}

All previous chapters developed:
\begin{itemize}
    \item exact governing equations,
    \item boundary conditions,
    \item dispersion relations,
    \item eigenfunctions and kernels.
\end{itemize}

This chapter answers the practical question:

\begin{quote}
\textbf{How do we implement the unified anisotropic–nonlocal Rayleigh model in a stable, reusable, and extensible codebase?}
\end{quote}

This is the chapter your guide will scrutinize.



\section{Design Philosophy}

A correct numerical implementation must:
\begin{itemize}
    \item preserve mathematical structure,
    \item separate physics from numerics,
    \item allow incremental extensions.
\end{itemize}

We therefore use a \textbf{modular architecture}.



\section{Core Mathematical Objects}

The theory defines four irreducible objects:

\begin{enumerate}
    \item material model $(\rho, C_{ijkl}, V(r))$,
    \item vertical slownesses $q_j(k,\omega)$,
    \item state matrix $\bm{Y}$,
    \item propagator $\bm{P}$.
\end{enumerate}

Each corresponds to a module.



\section{Code Architecture Overview}

\begin{verbatim}
rayleigh/
|
+-- core/
|   +-- slowness.py
|   +-- stiffness.py
|   +-- y_matrix.py
|   `-- propagator.py
|
+-- dispersion/
|   +-- secular_equation.py
|   `-- root_finding.py
|
+-- eigenfunctions/
|   +-- compute_modeshape.py
|   `-- normalization.py
|
+-- inversion/
|   +-- misfit.py
|   `-- optimization.py
|
+-- nonlocal/
|   +-- kernels.py
|   `-- effective_stiffness.py
|
`-- experiments/
    +-- plot_dispersion.py
    `-- plot_eigenfunctions.py
\end{verbatim}

This structure mirrors the mathematics.



\section{Vertical Slowness Computation}

From theory:
\[
q^2 = k^2 - \frac{\omega^2}{v^2}.
\]

Implementation rule:
\begin{itemize}
    \item always enforce $\Re(q) > 0$,
    \item allow complex values.
\end{itemize}

This guarantees evanescent decay.



\section{Effective Stiffness Module}

Nonlocal physics is absorbed into:
\[
\tilde{C}_{ijkl}(k) = \hat{V}(k)\,C_{ijkl}.
\]

Implementation:
\begin{itemize}
    \item compute $\hat{V}(k)$ once per frequency,
    \item scale stiffness tensor.
\end{itemize}

No integro-differential solver is needed.



\section{Y-Matrix Construction}

The $Y$-matrix encodes:
\begin{itemize}
    \item displacement,
    \item traction,
    \item polarization.
\end{itemize}

Each column corresponds to one partial wave.

This matrix is the numerical representation of elastodynamics.



\section{Propagator Matrix}

For each layer:
\[
\bm{P}_\ell = \bm{Y}_\ell \bm{D}_\ell \bm{Y}_\ell^{-1}.
\]

Key numerical rule:
\begin{itemize}
    \item use pseudo-inverse if condition number is large.
\end{itemize}

This prevents catastrophic instability.



\section{Global Matrix Assembly}

Stack layers via matrix multiplication:
\[
\bm{M} = \bm{P}_1 \bm{P}_2 \cdots \bm{P}_N.
\]

Order matters.

Always propagate from bottom to top.



\section{Dispersion Function}

The Rayleigh condition:
\[
\det \bm{A}(k,\omega) = 0.
\]

Numerically:
\begin{itemize}
    \item use real part of determinant,
    \item bracket roots using sign changes.
\end{itemize}

Avoid complex root finding when possible.



\section{Mode Tracking}

At successive frequencies:
\begin{itemize}
    \item choose root closest to previous,
    \item prevent mode jumping.
\end{itemize}

This is essential for clean dispersion curves.



\section{Eigenfunction Computation}

Given $(k,\omega)$:
\begin{enumerate}
    \item compute null vector of $\bm{A}$,
    \item propagate amplitudes downward,
    \item evaluate $\bm{u}(z)$ on a depth grid.
\end{enumerate}

This produces physical mode shapes.



\section{Normalization}

Normalize eigenfunctions using kinetic energy:
\[
\int \rho(z)\left(|u_x|^2 + |u_z|^2\right)dz = 1.
\]

This ensures:
\begin{itemize}
    \item consistent amplitudes,
    \item meaningful kernels.
\end{itemize}



\section{Numerical Stability Checklist}

Every correct implementation must:
\begin{itemize}
    \item avoid growing exponentials,
    \item monitor condition numbers,
    \item use consistent units,
    \item test limiting cases.
\end{itemize}

You already implemented these checks.



\section{Validation Strategy}

Mandatory tests:
\begin{enumerate}
    \item homogeneous half-space ($c \approx 0.92V_S$),
    \item monotonic dispersion,
    \item smooth eigenfunctions,
    \item kernel positivity.
\end{enumerate}

Passing these confirms correctness.

\section{Extensibility}

With this structure:
\begin{itemize}
    \item anisotropy modifies stiffness only,
    \item nonlocality modifies stiffness only,
    \item inversion modules remain unchanged.
\end{itemize}

This is exactly what research-grade code should do.

\end{document}