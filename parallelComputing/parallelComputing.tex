\documentclass[11pt,a4paper]{article}

% =========================
% Packages
% =========================
\usepackage[margin=1in]{geometry}
\usepackage{amsmath,amssymb}
\usepackage{physics}
\usepackage{graphicx}
\usepackage{float}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{enumitem}
\usepackage{booktabs}
\usepackage{listings}
\usepackage{courier}

% =========================
% Listings setup
% =========================
\lstset{
  basicstyle=\ttfamily\small,
  keywordstyle=\color{blue},
  commentstyle=\color{gray},
  stringstyle=\color{red},
  numbers=left,
  numberstyle=\tiny,
  stepnumber=1,
  numbersep=5pt,
  frame=single,
  breaklines=true,
  showstringspaces=false
}

% =========================
% Hyperref setup
% =========================
\hypersetup{
  colorlinks=true,
  linkcolor=blue,
  urlcolor=blue,
  pdftitle={Parallel Computing: From Linux to HPC},
  pdfauthor={IIT Indore}
}

% =========================
% Title Page
% =========================
\title{\textbf{Parallel Computing}}
\author{}
\date{}

\begin{document}

\maketitle
\thispagestyle{empty}
\newpage

\section*{Preface}
\addcontentsline{toc}{section}{Preface}

These notes are designed to teach \textbf{parallel computing from first principles}.

They assume:
\begin{itemize}
  \item no prior exposure to parallelism
  \item only basic programming knowledge
\end{itemize}

The course progresses through:
\begin{itemize}
  \item Linux fundamentals
  \item C++ programming
  \item Threads and synchronization
  \item OpenMP
  \item MPI
  \item Hybrid HPC programming
\end{itemize}

Emphasis is placed on:
\begin{itemize}
  \item intuition
  \item correctness
  \item performance reasoning
\end{itemize}

\newpage

\tableofcontents
\newpage

% ==================================================
\section*{PART 0: How Computers Really Work}
\addcontentsline{toc}{section}{PART 0: How Computers Really Work}

\subsection*{Lesson 0.1: What Is a Program \emph{Really} Doing?}
\addcontentsline{toc}{subsection}{Lesson 0.1: What Is a Program Really Doing?}

% --------------------------------------------------
\subsubsection*{0.1.1 The Big Lie We Are Told}
\addcontentsline{toc}{subsubsection}{0.1.1 The Big Lie We Are Told}

Most beginners believe:

\begin{quote}
\emph{``A program runs line by line, doing exactly what I wrote.''}
\end{quote}

This statement is \textbf{useful}, but it is also \textbf{deeply misleading}.

In reality:
\begin{itemize}
  \item Your program is \textbf{not} the thing doing work
  \item The CPU is doing the work
  \item Your code is only a \textbf{set of instructions}
\end{itemize}

A program is closer to a \textbf{recipe} than a worker.

% --------------------------------------------------
\subsubsection*{0.1.2 The CPU Is the Only Worker}
\addcontentsline{toc}{subsubsection}{0.1.2 The CPU Is the Only Worker}

At the lowest level, a CPU can only do a few things:

\begin{itemize}
  \item Load data from memory
  \item Perform arithmetic or logic
  \item Store results back to memory
  \item Jump to another instruction
\end{itemize}

That is all.

Even the most complex program reduces to billions of these tiny steps.

\textbf{Key Insight (Very Important):}
\begin{quote}
\emph{A CPU executes instructions one after another in time.}
\end{quote}

This is the root of the problem that parallel computing tries to solve.

% --------------------------------------------------
\subsubsection*{0.1.3 Time Is the Enemy}
\addcontentsline{toc}{subsubsection}{0.1.3 Time Is the Enemy}

Suppose a program takes:
\[
10^{12} \text{ operations}
\]

Even at:
\[
10^{9} \text{ operations per second}
\]

This still takes:
\[
1000 \text{ seconds } \approx 17 \text{ minutes}
\]

Now imagine:
\begin{itemize}
  \item weather simulation
  \item earthquake modeling
  \item machine learning training
\end{itemize}

These problems are \textbf{too large} for a single worker.

\textbf{Conclusion:}
\begin{quote}
\emph{Parallel computing exists because time exists.}
\end{quote}

% --------------------------------------------------
\subsubsection*{0.1.4 The Illusion of Simultaneity}
\addcontentsline{toc}{subsubsection}{0.1.4 The Illusion of Simultaneity}

When you run:
\begin{lstlisting}[language=bash]
./my_program
\end{lstlisting}

It \emph{feels} like:
\begin{itemize}
  \item everything happens at once
  \item the computer is ``thinking''
\end{itemize}

Reality:
\begin{itemize}
  \item instructions are executed extremely fast
  \item your brain cannot perceive the sequence
\end{itemize}

This illusion breaks down when:
\begin{itemize}
  \item programs become large
  \item data becomes huge
  \item waiting becomes visible
\end{itemize}

Parallel computing removes this illusion and replaces it with structure.

% --------------------------------------------------
\subsubsection*{0.1.5 Why This Matters for Teaching}
\addcontentsline{toc}{subsubsection}{0.1.5 Why This Matters for Teaching}

Students fail in parallel computing because they:
\begin{itemize}
  \item think code is magical
  \item do not think in terms of \textbf{work and time}
\end{itemize}

\begin{quote}
\emph{``Code does not run. Work runs.''}
\end{quote}

Once this clicks, parallelism becomes natural.

% --------------------------------------------------
\subsection*{Practice on Mac Terminal (Mandatory)}
\addcontentsline{toc}{subsection}{Practice on Mac Terminal}

\subsubsection*{Practice 1: Meet the Terminal}

Open Terminal and run:
\begin{lstlisting}[language=bash]
pwd
ls
whoami
\end{lstlisting}

Understand:
\begin{itemize}
  \item where you are
  \item what files exist
  \item which user is executing commands
\end{itemize}

\subsubsection*{Practice 2: Your First Program}

Create a file:
\begin{lstlisting}[language=bash]
nano hello.cpp
\end{lstlisting}

Write:
\begin{lstlisting}[language=C++]
#include <iostream>
using namespace std;

int main() {
    cout << "Hello, Parallel World!" << endl;
    return 0;
}
\end{lstlisting}

Compile and run:
\begin{lstlisting}[language=bash]
g++ hello.cpp -o hello
./hello
\end{lstlisting}

Think carefully:
\begin{itemize}
  \item Who did the work?
  \item Did your code run, or did the CPU run?
\end{itemize}

\subsubsection*{Practice 3: Slow Down Time}

Modify the program:
\begin{lstlisting}[language=C++]
for(long long i = 0; i < 1e9; i++) {}
\end{lstlisting}

Recompile and run.

\textbf{Observe:}
\begin{itemize}
  \item waiting becomes visible
  \item time becomes real
\end{itemize}

This loop is the seed of parallel thinking.

% --------------------------------------------------
\subsection*{Checkpoint Questions}
\addcontentsline{toc}{subsection}{Checkpoint Questions}

Answer these in words (not code):

\begin{enumerate}
  \item What actually executes a program?
  \item Why does increasing problem size force parallelism?
  \item Why is ``fast CPU'' not enough anymore?
\end{enumerate}
% ==================================================
\subsection*{Lesson 0.2: Memory Is the Real Bottleneck}
\addcontentsline{toc}{subsection}{Lesson 0.2: Memory Is the Real Bottleneck}

% --------------------------------------------------
\subsubsection*{0.2.1 The CPU Is Fast. Too Fast.}
\addcontentsline{toc}{subsubsection}{0.2.1 The CPU Is Fast. Too Fast.}

Modern CPUs are incredibly fast.

Rough intuition:
\begin{itemize}
  \item CPU can execute \textbf{billions of instructions per second}
  \item Memory access takes \textbf{hundreds of CPU cycles}
\end{itemize}

This means:
\begin{quote}
\emph{The CPU often spends most of its time waiting.}
\end{quote}

Waiting for what?

\textbf{Memory.}

% --------------------------------------------------
\subsubsection*{0.2.2 A Mental Model: The Office Desk}
\addcontentsline{toc}{subsubsection}{0.2.2 A Mental Model: The Office Desk}

Imagine a worker (CPU) in an office.

\begin{itemize}
  \item Papers on the desk $\rightarrow$ registers
  \item Cabinet beside desk $\rightarrow$ cache
  \item Store room downstairs $\rightarrow$ RAM
\end{itemize}

Fetching a paper from:
\begin{itemize}
  \item desk: instant
  \item cabinet: small delay
  \item store room: very slow
\end{itemize}

\textbf{Key insight:}
\begin{quote}
\emph{Computation is cheap. Data movement is expensive.}
\end{quote}

Parallel computing is largely about reducing waiting.

% --------------------------------------------------
\subsubsection*{0.2.3 Memory Hierarchy (No Hardware Details)}
\addcontentsline{toc}{subsubsection}{0.2.3 Memory Hierarchy (No Hardware Details)}

You do \textbf{not} need hardware engineering.

You only need this ordering:

\[
\text{Registers} \rightarrow \text{Cache} \rightarrow \text{RAM} \rightarrow \text{Disk}
\]

As we go right:
\begin{itemize}
  \item capacity increases
  \item speed decreases drastically
\end{itemize}

Parallel programs often fail because:
\begin{itemize}
  \item too many threads fight for memory
  \item memory becomes the bottleneck
\end{itemize}

% --------------------------------------------------
\subsubsection*{0.2.4 Why ``Faster CPU'' Stopped Working}
\addcontentsline{toc}{subsubsection}{0.2.4 Why Faster CPU Stopped Working}

Earlier strategy:
\begin{itemize}
  \item increase CPU clock speed
\end{itemize}

Problem:
\begin{itemize}
  \item heat
  \item power limits
  \item memory could not keep up
\end{itemize}

Solution industry chose:
\begin{quote}
\emph{Add more CPUs instead of making one faster.}
\end{quote}

This is why:
\begin{itemize}
  \item laptops
  \item servers
  \item phones
\end{itemize}
all became \textbf{multi-core}.

Parallel computing is not optional anymore.

% --------------------------------------------------
\subsubsection*{0.2.5 The Dangerous Student Assumption}
\addcontentsline{toc}{subsubsection}{0.2.5 The Dangerous Student Assumption}

Students often believe:
\begin{quote}
\emph{``More cores means faster code automatically.''}
\end{quote}

Reality:
\begin{itemize}
  \item memory is shared
  \item memory bandwidth is limited
  \item contention destroys performance
\end{itemize}

\textbf{Strang-style truth:}
\begin{quote}
\emph{Parallelism is not free. It must be earned.}
\end{quote}

% --------------------------------------------------
\subsection*{Practice on Mac Terminal (Mandatory)}
\addcontentsline{toc}{subsection}{Practice on Mac Terminal (Lesson 0.2)}

\subsubsection*{Practice 1: Observe Time Difference}

Create file:
\begin{lstlisting}[language=bash]
nano memory_test.cpp
\end{lstlisting}

Write:
\begin{lstlisting}[language=C++]
#include <iostream>
#include <vector>
#include <chrono>
using namespace std;
using namespace chrono;

int main() {
    const long long N = 100000000;
    vector<int> a(N, 1);

    auto start = high_resolution_clock::now();
    long long sum = 0;
    for (long long i = 0; i < N; i++) {
        sum += a[i];
    }
    auto end = high_resolution_clock::now();

    cout << "Sum = " << sum << endl;
    cout << "Time (ms): "
         << duration_cast<milliseconds>(end - start).count()
         << endl;

    return 0;
}
\end{lstlisting}

Compile and run:
\begin{lstlisting}[language=bash]
g++ -O2 memory_test.cpp -o memory_test
./memory_test
\end{lstlisting}

\textbf{Think:}
\begin{itemize}
  \item Is this computation-heavy?
  \item Or memory-heavy?
\end{itemize}

% --------------------------------------------------
\subsubsection*{Practice 2: Remove Memory Access}

Modify loop:
\begin{lstlisting}[language=C++]
sum += 1;
\end{lstlisting}

Recompile and run.

\textbf{Observe:}
\begin{itemize}
  \item dramatic speed difference
  \item same number of iterations
\end{itemize}

This experiment explains half of parallel computing failures.

% --------------------------------------------------
\subsection*{Checkpoint Questions}
\addcontentsline{toc}{subsection}{Checkpoint Questions (Lesson 0.2)}

Answer carefully:

\begin{enumerate}
  \item Why does the CPU wait even though it is fast?
  \item Why does memory dominate performance?
  \item Why can adding cores make performance worse?
\end{enumerate}
% ==================================================
\subsection*{Lesson 0.3: Why Parallel Computing Was Inevitable}
\addcontentsline{toc}{subsection}{Lesson 0.3: Why Parallel Computing Was Inevitable}

% --------------------------------------------------
\subsubsection*{0.3.1 The Old World: Free Speedups}
\addcontentsline{toc}{subsubsection}{0.3.1 The Old World: Free Speedups}

For many decades, programmers lived in a golden age.

You could:
\begin{itemize}
  \item write slow code
  \item wait a year
  \item run it faster on a new machine
\end{itemize}

This happened because:
\begin{itemize}
  \item transistor sizes shrank
  \item clock speeds increased
\end{itemize}

This trend is often summarized as:
\begin{quote}
\emph{``Moore's Law''}
\end{quote}

But this law had an expiration date.

% --------------------------------------------------
\subsubsection*{0.3.2 The Physical Wall}
\addcontentsline{toc}{subsubsection}{0.3.2 The Physical Wall}

Increasing clock speed caused serious problems:

\begin{itemize}
  \item heat dissipation
  \item power consumption
  \item signal delay
\end{itemize}

At some point:
\begin{quote}
\emph{The CPU could not be cooled fast enough.}
\end{quote}

Physics said: \textbf{stop}.

This is not a software problem.
This is a law-of-nature problem.

% --------------------------------------------------
\subsubsection*{0.3.3 The Industry's Only Option}
\addcontentsline{toc}{subsubsection}{0.3.3 The Industry's Only Option}

When speed could not increase, manufacturers asked:

\begin{quote}
\emph{``What if we add more CPUs instead?''}
\end{quote}

Result:
\begin{itemize}
  \item dual-core
  \item quad-core
  \item many-core
\end{itemize}

Every machine became parallel by default.

\textbf{Critical point:}
\begin{quote}
\emph{Software did not choose parallelism. Hardware forced it.}
\end{quote}

% --------------------------------------------------
\subsubsection*{0.3.4 The Software Crisis}
\addcontentsline{toc}{subsubsection}{0.3.4 The Software Crisis}

Old programs assumed:
\begin{itemize}
  \item one instruction stream
  \item one execution order
\end{itemize}

New hardware offered:
\begin{itemize}
  \item multiple execution units
  \item simultaneous work
\end{itemize}

Mismatch:
\begin{itemize}
  \item unused cores
  \item wasted silicon
\end{itemize}

Parallel computing was born to resolve this mismatch.

% --------------------------------------------------
\subsubsection*{0.3.5 The Shift in Programmer Thinking}
\addcontentsline{toc}{subsubsection}{0.3.5 The Shift in Programmer Thinking}

Sequential thinking:
\begin{quote}
\emph{``What happens next?''}
\end{quote}

Parallel thinking:
\begin{quote}
\emph{``What can happen at the same time?''}
\end{quote}

This requires:
\begin{itemize}
  \item rethinking algorithms
  \item rethinking data structures
  \item rethinking correctness
\end{itemize}

Parallel computing is not harder.
It is \textbf{different}.

% --------------------------------------------------
\subsection*{Practice on Mac Terminal (Mandatory)}
\addcontentsline{toc}{subsection}{Practice on Mac Terminal (Lesson 0.3)}

\subsubsection*{Practice 1: Know Your Machine}

Run:
\begin{lstlisting}[language=bash]
sysctl -n hw.ncpu
\end{lstlisting}

This shows how many CPU cores your Mac has.

\textbf{Think:}
\begin{itemize}
  \item How many cores are idle right now?
  \item Are you using all of them?
\end{itemize}

% --------------------------------------------------
\subsubsection*{Practice 2: Observe Single-Core Usage}

Run:
\begin{lstlisting}[language=bash]
top
\end{lstlisting}

Then execute any program you compiled earlier.

Observe:
\begin{itemize}
  \item one core spikes
  \item others remain mostly idle
\end{itemize}

This is the sequential default.

% --------------------------------------------------
\subsubsection*{Practice 3: Thought Experiment (No Code)}

Imagine:
\begin{itemize}
  \item 8 workers
  \item 1 task stream
\end{itemize}

Question:
\begin{quote}
\emph{Are you underutilizing resources?}
\end{quote}

Parallel computing answers this question systematically.

% --------------------------------------------------
\subsection*{Checkpoint Questions}
\addcontentsline{toc}{subsection}{Checkpoint Questions (Lesson 0.3)}

Answer in plain language:

\begin{enumerate}
  \item Why did clock-speed scaling fail?
  \item Why was adding cores the only viable option?
  \item Why did software need to change fundamentally?
\end{enumerate}
% ==================================================
\section*{PART 1: Linux as a Thinking Tool (Not Commands)}
\addcontentsline{toc}{section}{PART 1: Linux as a Thinking Tool (Not Commands)}

\subsection*{Lesson 1.1: What Is an Operating System Really Doing?}
\addcontentsline{toc}{subsection}{Lesson 1.1: What Is an Operating System Really Doing?}

% --------------------------------------------------
\subsubsection*{1.1.1 The Operating System Is a Referee}
\addcontentsline{toc}{subsubsection}{1.1.1 The Operating System Is a Referee}

A common beginner myth:

\begin{quote}
\emph{``My program directly controls the computer.''}
\end{quote}

Reality:
\begin{itemize}
  \item Your program controls \textbf{nothing} directly
  \item The operating system (OS) controls everything
\end{itemize}

Think of the OS as a \textbf{referee}:
\begin{itemize}
  \item programs request resources
  \item OS decides who gets what
\end{itemize}

This control is essential for safety and fairness.

% --------------------------------------------------
\subsubsection*{1.1.2 Why an OS Is Necessary}
\addcontentsline{toc}{subsubsection}{1.1.2 Why an OS Is Necessary}

Without an OS:
\begin{itemize}
  \item programs overwrite each other
  \item memory becomes corrupted
  \item one crash kills the whole machine
\end{itemize}

The OS provides:
\begin{itemize}
  \item memory isolation
  \item CPU scheduling
  \item file system abstraction
  \item device management
\end{itemize}

Parallel computing relies heavily on all four.

% --------------------------------------------------
\subsubsection*{1.1.3 Kernel vs User Space (Very Important)}
\addcontentsline{toc}{subsubsection}{1.1.3 Kernel vs User Space (Very Important)}

The OS is split into two worlds:

\begin{itemize}
  \item \textbf{Kernel space} — full power
  \item \textbf{User space} — restricted
\end{itemize}

Your programs run in \textbf{user space}.

They must ask the kernel for:
\begin{itemize}
  \item memory
  \item CPU time
  \item file access
\end{itemize}

This is done using \textbf{system calls}.

\textbf{Key insight:}
\begin{quote}
\emph{Parallel programs are really competing requests to the kernel.}
\end{quote}

% --------------------------------------------------
\subsubsection*{1.1.4 Processes: The Unit of Execution}
\addcontentsline{toc}{subsubsection}{1.1.4 Processes: The Unit of Execution}

A \textbf{process} is:
\begin{itemize}
  \item a running program
  \item with its own memory space
  \item managed by the OS
\end{itemize}

When you run:
\begin{lstlisting}[language=bash]
./hello
\end{lstlisting}

The OS:
\begin{itemize}
  \item creates a process
  \item assigns memory
  \item schedules CPU time
\end{itemize}

Parallel computing often means:
\begin{quote}
\emph{running many processes or threads simultaneously.}
\end{quote}

% --------------------------------------------------
\subsubsection*{1.1.5 Why Linux for Parallel Computing}
\addcontentsline{toc}{subsubsection}{1.1.5 Why Linux for Parallel Computing}

Linux dominates parallel computing because:
\begin{itemize}
  \item predictable process model
  \item powerful command-line tools
  \item strong resource control
  \item excellent compiler support
\end{itemize}

Most supercomputers run Linux for this reason.

Your Mac terminal behaves \textbf{almost exactly the same}.

% --------------------------------------------------
\subsection*{Practice on Mac Terminal (Mandatory)}
\addcontentsline{toc}{subsection}{Practice on Mac Terminal (Lesson 1.1)}

\subsubsection*{Practice 1: Meet the Shell}

Run:
\begin{lstlisting}[language=bash]
echo $SHELL
\end{lstlisting}

This shows which shell interprets your commands.

Then run:
\begin{lstlisting}[language=bash]
ps
\end{lstlisting}

Observe:
\begin{itemize}
  \item many processes
  \item not just yours
\end{itemize}

Every entry is managed by the OS.

% --------------------------------------------------
\subsubsection*{Practice 2: Your Program Is a Process}

Run:
\begin{lstlisting}[language=bash]
./hello &
ps
\end{lstlisting}

Observe:
\begin{itemize}
  \item your program appears in the process list
  \item it has a PID (process ID)
\end{itemize}

This PID is how the OS tracks execution.

% --------------------------------------------------
\subsubsection*{Practice 3: OS as Scheduler}

Run:
\begin{lstlisting}[language=bash]
top
\end{lstlisting}

Observe:
\begin{itemize}
  \item CPU usage changes
  \item processes compete for time
\end{itemize}

This competition becomes critical in parallel programs.

% --------------------------------------------------
\subsection*{Checkpoint Questions}
\addcontentsline{toc}{subsection}{Checkpoint Questions (Lesson 1.1)}

Answer clearly:

\begin{enumerate}
  \item Why can programs not control hardware directly?
  \item What is the role of the kernel?
  \item Why does parallel computing stress the OS?
\end{enumerate}
% ==================================================
\subsection*{Lesson 1.2: File System -- Directories Are Not Folders}
\addcontentsline{toc}{subsection}{Lesson 1.2: File System -- Directories Are Not Folders}

% --------------------------------------------------
\subsubsection*{1.2.1 The Biggest Misunderstanding}
\addcontentsline{toc}{subsubsection}{1.2.1 The Biggest Misunderstanding}

Beginners think:
\begin{quote}
\emph{``A folder contains files.''}
\end{quote}

This is visually convenient, but conceptually wrong.

Reality:
\begin{quote}
\emph{A directory is a mapping from names to locations.}
\end{quote}

Think of it like:
\begin{itemize}
  \item a dictionary
  \item a table
  \item a graph node
\end{itemize}

This perspective removes confusion forever.

% --------------------------------------------------
\subsubsection*{1.2.2 The File System Is a Tree}
\addcontentsline{toc}{subsubsection}{1.2.2 The File System Is a Tree}

The Linux file system starts at:
\[
/
\]

Called the \textbf{root}.

Everything else is connected beneath it:
\begin{itemize}
  \item \texttt{/home}
  \item \texttt{/Users}
  \item \texttt{/bin}
  \item \texttt{/usr}
\end{itemize}

This is not metaphorical.
It is a real tree structure.

Every file has:
\begin{itemize}
  \item exactly one absolute path
\end{itemize}

% --------------------------------------------------
\subsubsection*{1.2.3 Absolute Paths}
\addcontentsline{toc}{subsubsection}{1.2.3 Absolute Paths}

An absolute path starts from root:
\begin{lstlisting}[language=bash]
/Users/yourname/Desktop/hello.cpp
\end{lstlisting}

Properties:
\begin{itemize}
  \item unambiguous
  \item works from anywhere
  \item longer but safer
\end{itemize}

When debugging student code:
\begin{quote}
\emph{Absolute paths eliminate 80\% of errors.}
\end{quote}

% --------------------------------------------------
\subsubsection*{1.2.4 Relative Paths}
\addcontentsline{toc}{subsubsection}{1.2.4 Relative Paths}

A relative path depends on:
\begin{quote}
\emph{your current working directory}
\end{quote}

Special symbols:
\begin{itemize}
  \item \texttt{.}  (current directory)
  \item \texttt{..} (parent directory)
\end{itemize}

Example:
\begin{lstlisting}[language=bash]
../data/input.txt
\end{lstlisting}

Relative paths are powerful but dangerous for beginners.

% --------------------------------------------------
\subsubsection*{1.2.5 Why Programs ``Cannot Find Files''}
\addcontentsline{toc}{subsubsection}{1.2.5 Why Programs Cannot Find Files}

When students see:
\begin{quote}
\emph{file not found}
\end{quote}

The reason is almost always:
\begin{itemize}
  \item wrong working directory
  \item wrong relative path
\end{itemize}

Not:
\begin{itemize}
  \item compiler bug
  \item OS problem
\end{itemize}

Teaching this saves hours of frustration.

% --------------------------------------------------
\subsection*{Practice on Mac Terminal (Mandatory)}
\addcontentsline{toc}{subsection}{Practice on Mac Terminal (Lesson 1.2)}

\subsubsection*{Practice 1: Explore the Tree}

Run:
\begin{lstlisting}[language=bash]
pwd
ls
ls /
\end{lstlisting}

Observe:
\begin{itemize}
  \item your current position
  \item the global root structure
\end{itemize}

% --------------------------------------------------
\subsubsection*{Practice 2: Create Your Own Tree}

Run:
\begin{lstlisting}[language=bash]
mkdir parallel_course
cd parallel_course
mkdir src data output
ls
\end{lstlisting}

You have created a small file-system graph.

% --------------------------------------------------
\subsubsection*{Practice 3: Absolute vs Relative}

Create a file:
\begin{lstlisting}[language=bash]
nano src/test.txt
\end{lstlisting}

Then from \texttt{parallel\_course}:
\begin{lstlisting}[language=bash]
cat src/test.txt
cat ./src/test.txt
cat ../parallel_course/src/test.txt
\end{lstlisting}

Observe:
\begin{itemize}
  \item all point to the same file
  \item paths are just descriptions
\end{itemize}

% --------------------------------------------------
\subsubsection*{Practice 4: Break It On Purpose}

Move away:
\begin{lstlisting}[language=bash]
cd /
cat src/test.txt
\end{lstlisting}

Observe failure.

Now fix it using:
\begin{itemize}
  \item absolute path
\end{itemize}

This is controlled debugging.

% --------------------------------------------------
\subsection*{Checkpoint Questions}
\addcontentsline{toc}{subsection}{Checkpoint Questions (Lesson 1.2)}

Answer clearly:

\begin{enumerate}
  \item What is a directory conceptually?
  \item Why is the file system a tree?
  \item Why do relative paths fail so often?
\end{enumerate}
% ==================================================
\subsection*{Lesson 1.3: Files Are Streams -- stdin, stdout, stderr}
\addcontentsline{toc}{subsection}{Lesson 1.3: Files Are Streams -- stdin, stdout, stderr}

% --------------------------------------------------
\subsubsection*{1.3.1 The Wrong Mental Model}
\addcontentsline{toc}{subsubsection}{1.3.1 The Wrong Mental Model}

Beginners think:
\begin{quote}
\emph{``A file is a thing stored somewhere.''}
\end{quote}

This is visually true, but computationally incomplete.

Better model:
\begin{quote}
\emph{A file is a stream of bytes.}
\end{quote}

Programs do not see files.
They see \textbf{streams of data arriving over time}.

% --------------------------------------------------
\subsubsection*{1.3.2 What Is a Stream?}
\addcontentsline{toc}{subsubsection}{1.3.2 What Is a Stream?}

A stream is:
\begin{itemize}
  \item an ordered sequence of bytes
  \item read from beginning to end
  \item possibly infinite
\end{itemize}

Examples of streams:
\begin{itemize}
  \item keyboard input
  \item file contents
  \item network data
  \item output printed on screen
\end{itemize}

Parallel programs interact with many streams at once.

% --------------------------------------------------
\subsubsection*{1.3.3 The Three Standard Streams}
\addcontentsline{toc}{subsubsection}{1.3.3 The Three Standard Streams}

Every process starts with three streams:

\begin{itemize}
  \item \textbf{stdin}  — input stream
  \item \textbf{stdout} — normal output
  \item \textbf{stderr} — error output
\end{itemize}

These streams are created by the OS, not by your program.

Your program simply uses them.

% --------------------------------------------------
\subsubsection*{1.3.4 Why stdout and stderr Are Separate}
\addcontentsline{toc}{subsubsection}{1.3.4 Why stdout and stderr Are Separate}

This separation is deliberate.

\begin{itemize}
  \item stdout $\rightarrow$ program results
  \item stderr $\rightarrow$ diagnostics
\end{itemize}

Why this matters:
\begin{itemize}
  \item you can redirect results to a file
  \item while still seeing errors on screen
\end{itemize}

Parallel programs rely on this separation heavily.

% --------------------------------------------------
\subsubsection*{1.3.5 Redirection: Controlling Streams}
\addcontentsline{toc}{subsubsection}{1.3.5 Redirection: Controlling Streams}

The shell can redirect streams:

\begin{lstlisting}[language=bash]
./prog > output.txt
\end{lstlisting}

This means:
\begin{itemize}
  \item stdout goes to \texttt{output.txt}
  \item stderr stays on terminal
\end{itemize}

Redirect stderr:
\begin{lstlisting}[language=bash]
./prog 2> error.txt
\end{lstlisting}

Redirect both:
\begin{lstlisting}[language=bash]
./prog > all.txt 2>&1
\end{lstlisting}

This is essential for debugging parallel output.

% --------------------------------------------------
\subsubsection*{1.3.6 Why Parallel Output Looks Messy}
\addcontentsline{toc}{subsubsection}{1.3.6 Why Parallel Output Looks Messy}

In parallel programs:
\begin{itemize}
  \item many threads write to stdout
  \item writes interleave unpredictably
\end{itemize}

Result:
\begin{quote}
\emph{Jumbled, confusing output}
\end{quote}

This is not a bug.
It is the consequence of concurrency.

Understanding streams explains this behavior fully.

% --------------------------------------------------
\subsection*{Practice on Mac Terminal (Mandatory)}
\addcontentsline{toc}{subsection}{Practice on Mac Terminal (Lesson 1.3)}

\subsubsection*{Practice 1: stdout vs stderr}

Create file:
\begin{lstlisting}[language=bash]
nano streams.cpp
\end{lstlisting}

Write:
\begin{lstlisting}[language=C++]
#include <iostream>
using namespace std;

int main() {
    cout << "This is normal output" << endl;
    cerr << "This is an error message" << endl;
    return 0;
}
\end{lstlisting}

Compile and run:
\begin{lstlisting}[language=bash]
g++ streams.cpp -o streams
./streams
\end{lstlisting}

Observe:
\begin{itemize}
  \item both appear on screen
  \item but they are different streams
\end{itemize}

% --------------------------------------------------
\subsubsection*{Practice 2: Redirect Only stdout}

Run:
\begin{lstlisting}[language=bash]
./streams > out.txt
\end{lstlisting}

Observe:
\begin{itemize}
  \item message from \texttt{cout} is redirected
  \item message from \texttt{cerr} is still visible
\end{itemize}

% --------------------------------------------------
\subsubsection*{Practice 3: Redirect Only stderr}

Run:
\begin{lstlisting}[language=bash]
./streams 2> err.txt
\end{lstlisting}

Now inspect files:
\begin{lstlisting}[language=bash]
cat out.txt
cat err.txt
\end{lstlisting}

Understand exactly what went where.

% --------------------------------------------------
\subsection*{Checkpoint Questions}
\addcontentsline{toc}{subsection}{Checkpoint Questions (Lesson 1.3)}

Answer clearly:

\begin{enumerate}
  \item Why are files treated as streams?
  \item Why are stdout and stderr separated?
  \item Why does parallel output appear unordered?
\end{enumerate}
% ==================================================
\subsection*{Lesson 1.4: Compilation Is a Pipeline, Not a Command}
\addcontentsline{toc}{subsection}{Lesson 1.4: Compilation Is a Pipeline, Not a Command}

% --------------------------------------------------
\subsubsection*{1.4.1 The Beginner Illusion}
\addcontentsline{toc}{subsubsection}{1.4.1 The Beginner Illusion}

Beginners think:
\begin{quote}
\emph{``g++ converts my code into a program.''}
\end{quote}

This is dangerously incomplete.

Reality:
\begin{quote}
\emph{Compilation is a multi-stage pipeline.}
\end{quote}

Understanding this pipeline explains almost every compiler error you will see.

% --------------------------------------------------
\subsubsection*{1.4.2 Stage 1: Preprocessing}
\addcontentsline{toc}{subsubsection}{1.4.2 Stage 1: Preprocessing}

The preprocessor handles:
\begin{itemize}
  \item \texttt{\#include}
  \item \texttt{\#define}
  \item conditional compilation
\end{itemize}

It produces:
\begin{quote}
\emph{A huge expanded source file}
\end{quote}

Your compiler never sees your original code.
It sees the preprocessed result.

% --------------------------------------------------
\subsubsection*{1.4.3 Stage 2: Compilation}
\addcontentsline{toc}{subsubsection}{1.4.3 Stage 2: Compilation}

This stage:
\begin{itemize}
  \item checks syntax
  \item checks types
  \item translates code to object code
\end{itemize}

Output:
\begin{itemize}
  \item \texttt{.o} files
\end{itemize}

Errors here mean:
\begin{quote}
\emph{``Your code does not make sense.''}
\end{quote}

% --------------------------------------------------
\subsubsection*{1.4.4 Stage 3: Linking}
\addcontentsline{toc}{subsubsection}{1.4.4 Stage 3: Linking}

The linker:
\begin{itemize}
  \item combines object files
  \item resolves function references
  \item produces the final executable
\end{itemize}

Classic error:
\begin{quote}
\emph{undefined reference}
\end{quote}

Meaning:
\begin{itemize}
  \item function declared
  \item but definition missing
\end{itemize}

This is not a syntax problem.
It is a \textbf{connection problem}.

% --------------------------------------------------
\subsubsection*{1.4.5 Why This Matters for Parallel Computing}
\addcontentsline{toc}{subsubsection}{1.4.5 Why This Matters for Parallel Computing}

Parallel programs often require:
\begin{itemize}
  \item special compiler flags
  \item extra libraries
\end{itemize}

Example:
\begin{lstlisting}[language=bash]
g++ -fopenmp main.cpp
\end{lstlisting}

If you forget the flag:
\begin{itemize}
  \item compilation may succeed
  \item linking will fail
\end{itemize}

Understanding the pipeline explains why.

% --------------------------------------------------
\subsection*{Practice on Mac Terminal (Mandatory)}
\addcontentsline{toc}{subsection}{Practice on Mac Terminal (Lesson 1.4)}

\subsubsection*{Practice 1: See the Pipeline}

Create file:
\begin{lstlisting}[language=bash]
nano pipeline.cpp
\end{lstlisting}

Write:
\begin{lstlisting}[language=C++]
#include <iostream>
using namespace std;

int main() {
    cout << "Pipeline demo" << endl;
    return 0;
}
\end{lstlisting}

Run preprocessing only:
\begin{lstlisting}[language=bash]
g++ -E pipeline.cpp > preprocessed.cpp
\end{lstlisting}

Open \texttt{preprocessed.cpp} and observe its size.

% --------------------------------------------------
\subsubsection*{Practice 2: Compile Without Linking}

Run:
\begin{lstlisting}[language=bash]
g++ -c pipeline.cpp
ls
\end{lstlisting}

Observe:
\begin{itemize}
  \item \texttt{pipeline.o} exists
  \item no executable yet
\end{itemize}

% --------------------------------------------------
\subsubsection*{Practice 3: Link Manually}

Run:
\begin{lstlisting}[language=bash]
g++ pipeline.o -o pipeline
./pipeline
\end{lstlisting}

You have manually executed the pipeline.

% --------------------------------------------------
\subsection*{Checkpoint Questions}
\addcontentsline{toc}{subsection}{Checkpoint Questions (Lesson 1.4)}

Answer clearly:

\begin{enumerate}
  \item Why is compilation not a single step?
  \item What causes linker errors?
  \item Why do parallel programs require special flags?
\end{enumerate}
% ==================================================
\section*{PART 2: C++ from a Parallel Mindset}
\addcontentsline{toc}{section}{PART 2: C++ from a Parallel Mindset}

\subsection*{Lesson 2.1: Variables Live in Memory}
\addcontentsline{toc}{subsection}{Lesson 2.1: Variables Live in Memory}

% --------------------------------------------------
\subsubsection*{2.1.1 The Most Dangerous Illusion}
\addcontentsline{toc}{subsubsection}{2.1.1 The Most Dangerous Illusion}

Beginners think:
\begin{quote}
\emph{``A variable is a name that holds a value.''}
\end{quote}

This is convenient for exams — and disastrous for parallel thinking.

Reality:
\begin{quote}
\emph{A variable is a name that refers to a memory location.}
\end{quote}

Parallel programs do not fight over values.  
They fight over \textbf{memory locations}.

% --------------------------------------------------
\subsubsection*{2.1.2 Memory Is Just a Large Array}
\addcontentsline{toc}{subsubsection}{2.1.2 Memory Is Just a Large Array}

At the lowest level:
\begin{itemize}
  \item memory is a long sequence of bytes
  \item each byte has an address
\end{itemize}

A variable means:
\begin{quote}
\emph{``Use these addresses to store data.''}
\end{quote}

Two variables pointing to the same address is where chaos begins.

% --------------------------------------------------
\subsubsection*{2.1.3 The Stack: Fast and Organized}
\addcontentsline{toc}{subsubsection}{2.1.3 The Stack: Fast and Organized}

The \textbf{stack} is:
\begin{itemize}
  \item automatically managed
  \item created per function call
  \item destroyed when function returns
\end{itemize}

Example:
\begin{lstlisting}[language=C++]
void foo() {
    int x = 10;
}
\end{lstlisting}

Here:
\begin{itemize}
  \item \texttt{x} lives on the stack
  \item it disappears after \texttt{foo()} returns
\end{itemize}

Stack memory is:
\begin{itemize}
  \item fast
  \item private to a function call
\end{itemize}

This matters deeply for threads.

% --------------------------------------------------
\subsubsection*{2.1.4 The Heap: Flexible and Dangerous}
\addcontentsline{toc}{subsubsection}{2.1.4 The Heap: Flexible and Dangerous}

The \textbf{heap} is:
\begin{itemize}
  \item manually managed (directly or indirectly)
  \item long-lived
  \item shared across function calls
\end{itemize}

Example:
\begin{lstlisting}[language=C++]
int* p = new int(10);
\end{lstlisting}

Here:
\begin{itemize}
  \item memory persists until explicitly freed
  \item multiple parts of code can access it
\end{itemize}

Parallel programs love the heap — and suffer for it.

% --------------------------------------------------
\subsubsection*{2.1.5 Why Parallel Bugs Love the Heap}
\addcontentsline{toc}{subsubsection}{2.1.5 Why Parallel Bugs Love the Heap}

In parallel execution:
\begin{itemize}
  \item multiple threads
  \item same heap memory
  \item unsynchronized access
\end{itemize}

This leads to:
\begin{itemize}
  \item race conditions
  \item corrupted data
  \item nondeterministic behavior
\end{itemize}

\textbf{Key Strang-style insight:}
\begin{quote}
\emph{If two workers touch the same memory, order matters.}
\end{quote}

% --------------------------------------------------
\subsubsection*{2.1.6 Stack vs Heap Summary}
\addcontentsline{toc}{subsubsection}{2.1.6 Stack vs Heap Summary}

\begin{center}
\begin{tabular}{|c|c|c|}
\hline
 & Stack & Heap \\
\hline
Lifetime & Automatic & Manual/Long \\
Speed & Fast & Slower \\
Sharing & Private & Shared \\
Parallel Safety & High & Low \\
\hline
\end{tabular}
\end{center}

Parallel programming tries to:
\begin{quote}
\emph{Maximize stack usage, minimize shared heap access.}
\end{quote}

% --------------------------------------------------
\subsection*{Practice on Mac Terminal (Mandatory)}
\addcontentsline{toc}{subsection}{Practice on Mac Terminal (Lesson 2.1)}

\subsubsection*{Practice 1: Stack Behavior}

Create file:
\begin{lstlisting}[language=bash]
nano memory.cpp
\end{lstlisting}

Write:
\begin{lstlisting}[language=C++]
#include <iostream>
using namespace std;

void foo() {
    int x = 10;
    cout << "x inside foo: " << x << endl;
}

int main() {
    foo();
    foo();
    return 0;
}
\end{lstlisting}

Compile and run:
\begin{lstlisting}[language=bash]
g++ memory.cpp -o memory
./memory
\end{lstlisting}

Think:
\begin{itemize}
  \item Is \texttt{x} the same variable each time?
  \item Or same name, different memory?
\end{itemize}

% --------------------------------------------------
\subsubsection*{Practice 2: Heap Persistence}

Modify code:
\begin{lstlisting}[language=C++]
int* p;

void foo() {
    p = new int(10);
}
\end{lstlisting}

Print value in \texttt{main()}.

Think:
\begin{itemize}
  \item Why does the value persist?
  \item Who owns this memory?
\end{itemize}

This question becomes critical in parallel programs.

% --------------------------------------------------
\subsection*{Checkpoint Questions}
\addcontentsline{toc}{subsection}{Checkpoint Questions (Lesson 2.1)}

Answer clearly:

\begin{enumerate}
  \item Why is a variable really a memory location?
  \item Why is stack memory safer in parallel programs?
  \item Why does the heap require synchronization?
\end{enumerate}
% ==================================================
\subsection*{Lesson 2.2: Loops Are Work -- Independence Is the Key}
\addcontentsline{toc}{subsection}{Lesson 2.2: Loops Are Work -- Independence Is the Key}

% --------------------------------------------------
\subsubsection*{2.2.1 Stop Seeing Loops as Syntax}
\addcontentsline{toc}{subsubsection}{2.2.1 Stop Seeing Loops as Syntax}

Beginners see:
\begin{quote}
\emph{``A loop repeats code.''}
\end{quote}

Parallel thinkers see:
\begin{quote}
\emph{``A loop describes many units of work.''}
\end{quote}

Each iteration of a loop is a \textbf{task}.

Parallel computing asks one question:
\begin{quote}
\emph{Are these tasks independent?}
\end{quote}

If yes — they can run in parallel.

% --------------------------------------------------
\subsubsection*{2.2.2 Iterations as Workers}
\addcontentsline{toc}{subsubsection}{2.2.2 Iterations as Workers}

Consider:
\begin{lstlisting}[language=C++]
for (int i = 0; i < N; i++) {
    a[i] = 2 * i;
}
\end{lstlisting}

This is not one job.
It is \textbf{N independent jobs}.

Each iteration:
\begin{itemize}
  \item reads \texttt{i}
  \item writes \texttt{a[i]}
\end{itemize}

No iteration depends on another.

This is \textbf{perfect parallelism}.

% --------------------------------------------------
\subsubsection*{2.2.3 When Loops Are NOT Independent}
\addcontentsline{toc}{subsubsection}{2.2.3 When Loops Are NOT Independent}

Now consider:
\begin{lstlisting}[language=C++]
for (int i = 1; i < N; i++) {
    a[i] = a[i-1] + 1;
}
\end{lstlisting}

Iteration \texttt{i} depends on:
\begin{itemize}
  \item result of iteration \texttt{i-1}
\end{itemize}

This creates a \textbf{dependency chain}.

Parallel execution would break correctness.

\textbf{Key idea:}
\begin{quote}
\emph{Dependency kills parallelism.}
\end{quote}

% --------------------------------------------------
\subsubsection*{2.2.4 Data Dependency vs Loop Dependency}
\addcontentsline{toc}{subsubsection}{2.2.4 Data Dependency vs Loop Dependency}

Important distinction:

\begin{itemize}
  \item Loop dependency: order matters
  \item Data dependency: memory locations overlap
\end{itemize}

Example:
\begin{lstlisting}[language=C++]
sum += a[i];
\end{lstlisting}

Here:
\begin{itemize}
  \item all iterations write to \texttt{sum}
  \item shared memory location
\end{itemize}

Even if mathematically independent,
memory makes it unsafe.

This leads to race conditions.

% --------------------------------------------------
\subsubsection*{2.2.5 The Parallelism Test (Golden Rule)}
\addcontentsline{toc}{subsubsection}{2.2.5 The Parallelism Test (Golden Rule)}

Before parallelizing any loop, ask:

\begin{enumerate}
  \item Does each iteration read only its own data?
  \item Does each iteration write to its own memory?
  \item Does order matter for correctness?
\end{enumerate}

If all answers are:
\[
\text{NO, NO, NO}
\]

Then the loop is parallelizable.

This rule alone makes you dangerous.

% --------------------------------------------------
\subsubsection*{2.2.6 Why Most Real Code Is Partially Parallel}
\addcontentsline{toc}{subsubsection}{2.2.6 Why Most Real Code Is Partially Parallel}

Real programs:
\begin{itemize}
  \item mix independent and dependent work
  \item have sequential setup
  \item have parallel cores
\end{itemize}

Parallel computing is not:
\begin{quote}
\emph{Make everything parallel}
\end{quote}

It is:
\begin{quote}
\emph{Find and extract parallel regions}
\end{quote}

This mindset matters more than syntax.

% --------------------------------------------------
\subsection*{Practice on Mac Terminal (Mandatory)}
\addcontentsline{toc}{subsection}{Practice on Mac Terminal (Lesson 2.2)}

\subsubsection*{Practice 1: Identify Independence}

Create file:
\begin{lstlisting}[language=bash]
nano loops.cpp
\end{lstlisting}

Write:
\begin{lstlisting}[language=C++]
#include <iostream>
#include <vector>
using namespace std;

int main() {
    int N = 10;
    vector<int> a(N);

    for (int i = 0; i < N; i++) {
        a[i] = i * i;
    }

    for (int i = 0; i < N; i++) {
        cout << a[i] << " ";
    }
    cout << endl;

    return 0;
}
\end{lstlisting}

Compile and run:
\begin{lstlisting}[language=bash]
g++ loops.cpp -o loops
./loops
\end{lstlisting}

Ask yourself:
\begin{itemize}
  \item Is the first loop parallelizable?
  \item Why?
\end{itemize}

% --------------------------------------------------
\subsubsection*{Practice 2: Create a Dependency}

Modify loop:
\begin{lstlisting}[language=C++]
a[i] = a[i-1] + 1;
\end{lstlisting}

Recompile and think:
\begin{itemize}
  \item What breaks parallelism?
\end{itemize}

% --------------------------------------------------
\subsubsection*{Practice 3: Hidden Dependency}

Add:
\begin{lstlisting}[language=C++]
int sum = 0;
for (int i = 0; i < N; i++) {
    sum += a[i];
}
\end{lstlisting}

Ask:
\begin{itemize}
  \item Is math independent?
  \item Is memory independent?
\end{itemize}

This exact pattern leads to reductions later.

% --------------------------------------------------
\subsection*{Checkpoint Questions}
\addcontentsline{toc}{subsection}{Checkpoint Questions (Lesson 2.2)}

Answer carefully:

\begin{enumerate}
  \item Why is a loop a collection of tasks?
  \item What kind of dependency blocks parallelism?
  \item Why does shared memory matter even if math is simple?
\end{enumerate}
% ==================================================
\subsection*{Lesson 2.3: Functions Are Tasks -- Call Stack, Ownership, and Safety}
\addcontentsline{toc}{subsection}{Lesson 2.3: Functions Are Tasks -- Call Stack, Ownership, and Safety}

% --------------------------------------------------
\subsubsection*{2.3.1 Stop Seeing Functions as Syntax}
\addcontentsline{toc}{subsubsection}{2.3.1 Stop Seeing Functions as Syntax}

Beginners think:
\begin{quote}
\emph{``A function is a way to organize code.''}
\end{quote}

Parallel thinkers think:
\begin{quote}
\emph{``A function is a unit of work with inputs and outputs.''}
\end{quote}

This is crucial.

Parallel computing schedules:
\begin{itemize}
  \item tasks
  \item not lines of code
\end{itemize}

Functions are the most natural tasks we already have.

% --------------------------------------------------
\subsubsection*{2.3.2 What Really Happens During a Function Call}
\addcontentsline{toc}{subsubsection}{2.3.2 What Really Happens During a Function Call}

When a function is called:
\begin{itemize}
  \item a new stack frame is created
  \item parameters are copied (or referenced)
  \item local variables live in that frame
\end{itemize}

This stack frame:
\begin{itemize}
  \item belongs exclusively to that call
  \item is destroyed when the function returns
\end{itemize}

This makes stack-based functions naturally safe.

% --------------------------------------------------
\subsubsection*{2.3.3 Stack Frames and Parallel Safety}
\addcontentsline{toc}{subsubsection}{2.3.3 Stack Frames and Parallel Safety}

If two threads call the same function:

\begin{itemize}
  \item each gets its own stack frame
  \item local variables do NOT clash
\end{itemize}

Example:
\begin{lstlisting}[language=C++]
void work() {
    int x = 0;
    x++;
}
\end{lstlisting}

Calling \texttt{work()} in parallel is safe.

\textbf{Key insight:}
\begin{quote}
\emph{Local variables are private by default.}
\end{quote}

This is why task-based parallelism works.

% --------------------------------------------------
\subsubsection*{2.3.4 When Functions Become Dangerous}
\addcontentsline{toc}{subsubsection}{2.3.4 When Functions Become Dangerous}

Functions are NOT safe when they:
\begin{itemize}
  \item access global variables
  \item modify shared heap memory
  \item use static variables
\end{itemize}

Example:
\begin{lstlisting}[language=C++]
int counter = 0;

void work() {
    counter++;
}
\end{lstlisting}

Parallel calls to \texttt{work()} cause races.

Same function.
Different memory behavior.
Different outcome.

% --------------------------------------------------
\subsubsection*{2.3.5 Ownership: Who Owns the Data?}
\addcontentsline{toc}{subsubsection}{2.3.5 Ownership: Who Owns the Data?}

Parallel safety depends on ownership.

Ask:
\begin{itemize}
  \item Who creates the data?
  \item Who modifies it?
  \item Who destroys it?
\end{itemize}

Safe rule:
\begin{quote}
\emph{Each task should own its data.}
\end{quote}

Shared ownership requires synchronization.

This rule alone prevents most bugs.

% --------------------------------------------------
\subsubsection*{2.3.6 Functions as Tasks: The Big Picture}
\addcontentsline{toc}{subsubsection}{2.3.6 Functions as Tasks: The Big Picture}

Sequential view:
\begin{quote}
\emph{Call functions one after another}
\end{quote}

Parallel view:
\begin{quote}
\emph{Schedule independent function calls simultaneously}
\end{quote}

This idea will appear later as:
\begin{itemize}
  \item threads
  \item OpenMP sections
  \item task parallelism
\end{itemize}

You are now thinking correctly.

% --------------------------------------------------
\subsection*{Practice on Mac Terminal (Mandatory)}
\addcontentsline{toc}{subsection}{Practice on Mac Terminal (Lesson 2.3)}

\subsubsection*{Practice 1: Stack Safety}

Create file:
\begin{lstlisting}[language=bash]
nano functions.cpp
\end{lstlisting}

Write:
\begin{lstlisting}[language=C++]
#include <iostream>
using namespace std;

void work(int id) {
    int local = id * 10;
    cout << "Task " << id << " local = " << local << endl;
}

int main() {
    work(1);
    work(2);
    return 0;
}
\end{lstlisting}

Compile and run:
\begin{lstlisting}[language=bash]
g++ functions.cpp -o functions
./functions
\end{lstlisting}

Think:
\begin{itemize}
  \item Does each call have its own memory?
\end{itemize}

% --------------------------------------------------
\subsubsection*{Practice 2: Introduce Shared State}

Modify:
\begin{lstlisting}[language=C++]
int shared = 0;

void work(int id) {
    shared++;
    cout << shared << endl;
}
\end{lstlisting}

Think:
\begin{itemize}
  \item What breaks if this runs in parallel?
\end{itemize}

You don’t need threads yet to see the danger.

% --------------------------------------------------
\subsection*{Checkpoint Questions}
\addcontentsline{toc}{subsection}{Checkpoint Questions (Lesson 2.3)}

Answer clearly:

\begin{enumerate}
  \item Why are stack variables naturally thread-safe?
  \item Why do global variables break task safety?
  \item What does data ownership mean?
\end{enumerate}

% ==================================================
\subsection*{Lesson 2.4: Pointers \& References -- Aliasing Is the Silent Killer}
\addcontentsline{toc}{subsection}{Lesson 2.4: Pointers \& References -- Aliasing Is the Silent Killer}

% --------------------------------------------------
\subsubsection*{2.4.1 The Real Danger Is Not Pointers}
\addcontentsline{toc}{subsubsection}{2.4.1 The Real Danger Is Not Pointers}

Beginners fear:
\begin{quote}
\emph{``Pointers are dangerous.''}
\end{quote}

This is false.

The real danger is:
\begin{quote}
\emph{Multiple names referring to the same memory.}
\end{quote}

This is called \textbf{aliasing}.

Parallel bugs are almost always aliasing bugs.

% --------------------------------------------------
\subsubsection*{2.4.2 What Is a Pointer Really?}
\addcontentsline{toc}{subsubsection}{2.4.2 What Is a Pointer Really?}

A pointer is:
\begin{quote}
\emph{A variable that stores a memory address.}
\end{quote}

Example:
\begin{lstlisting}[language=C++]
int x = 10;
int* p = &x;
\end{lstlisting}

Here:
\begin{itemize}
  \item \texttt{x} is a value
  \item \texttt{p} stores the address of \texttt{x}
\end{itemize}

Now there are \textbf{two ways} to access the same memory.

% --------------------------------------------------
\subsubsection*{2.4.3 References: Safer Syntax, Same Problem}
\addcontentsline{toc}{subsubsection}{2.4.3 References: Safer Syntax, Same Problem}

References look harmless:
\begin{lstlisting}[language=C++]
int x = 10;
int& r = x;
\end{lstlisting}

But conceptually:
\begin{quote}
\emph{A reference is an alias.}
\end{quote}

There are now two names:
\begin{itemize}
  \item \texttt{x}
  \item \texttt{r}
\end{itemize}

Same memory.
Same danger in parallel code.

% --------------------------------------------------
\subsubsection*{2.4.4 Aliasing Breaks Reasoning}
\addcontentsline{toc}{subsubsection}{2.4.4 Aliasing Breaks Reasoning}

Consider:
\begin{lstlisting}[language=C++]
void update(int& a, int& b) {
    a = a + 1;
    b = b + 1;
}
\end{lstlisting}

If \texttt{a} and \texttt{b} refer to:
\begin{itemize}
  \item different memory → safe
  \item same memory → logic changes
\end{itemize}

The code does not tell you which is true.

This uncertainty is poison for parallelism.

% --------------------------------------------------
\subsubsection*{2.4.5 Why Aliasing Is Deadly in Parallel Programs}
\addcontentsline{toc}{subsubsection}{2.4.5 Why Aliasing Is Deadly in Parallel Programs}

Parallel execution assumes:
\begin{itemize}
  \item tasks operate on distinct data
\end{itemize}

Aliasing violates this assumption silently.

Results:
\begin{itemize}
  \item race conditions
  \item lost updates
  \item non-deterministic behavior
\end{itemize}

Worst part:
\begin{quote}
\emph{The program may work 99 times and fail once.}
\end{quote}

% --------------------------------------------------
\subsubsection*{2.4.6 The Golden Rule of Parallel Safety}
\addcontentsline{toc}{subsubsection}{2.4.6 The Golden Rule of Parallel Safety}

\textbf{Golden Rule:}
\begin{quote}
\emph{If two threads can reach the same memory location, you must think carefully.}
\end{quote}

Better rule:
\begin{quote}
\emph{Avoid shared writable memory unless absolutely necessary.}
\end{quote}

This rule alone eliminates most bugs.

% --------------------------------------------------
\subsection*{Practice on Mac Terminal (Mandatory)}
\addcontentsline{toc}{subsection}{Practice on Mac Terminal (Lesson 2.4)}

\subsubsection*{Practice 1: Observe Aliasing}

Create file:
\begin{lstlisting}[language=bash]
nano alias.cpp
\end{lstlisting}

Write:
\begin{lstlisting}[language=C++]
#include <iostream>
using namespace std;

void update(int& a, int& b) {
    a++;
    b++;
}

int main() {
    int x = 0;
    update(x, x);
    cout << x << endl;
    return 0;
}
\end{lstlisting}

Compile and run:
\begin{lstlisting}[language=bash]
g++ alias.cpp -o alias
./alias
\end{lstlisting}

Think:
\begin{itemize}
  \item Did you expect this result?
  \item Why did it happen?
\end{itemize}

% --------------------------------------------------
\subsubsection*{Practice 2: Pointer Aliasing}

Modify:
\begin{lstlisting}[language=C++]
int x = 0;
int* p = &x;
int* q = &x;

(*p)++;
(*q)++;
\end{lstlisting}

Observe:
\begin{itemize}
  \item same memory
  \item two access paths
\end{itemize}

Now imagine these happen in parallel.

% --------------------------------------------------
\subsection*{Checkpoint Questions}
\addcontentsline{toc}{subsection}{Checkpoint Questions (Lesson 2.4)}

Answer carefully:

\begin{enumerate}
  \item What is aliasing?
  \item Why are references not inherently safer than pointers?
  \item Why does aliasing destroy parallel reasoning?
\end{enumerate}
% ==================================================
\section*{PART 3: Time, Measurement, and Performance Thinking}
\addcontentsline{toc}{section}{PART 3: Time, Measurement, and Performance Thinking}

\subsection*{Lesson 3.1: What Does ``Fast'' Really Mean?}
\addcontentsline{toc}{subsection}{Lesson 3.1: What Does ``Fast'' Really Mean?}

% --------------------------------------------------
\subsubsection*{3.1.1 The Performance Illusion}
\addcontentsline{toc}{subsubsection}{3.1.1 The Performance Illusion}

Students often say:
\begin{quote}
\emph{``My program is fast.''}
\end{quote}

This sentence is meaningless without context.

Fast compared to:
\begin{itemize}
  \item what input size?
  \item what machine?
  \item what baseline?
\end{itemize}

Parallel computing forces precision.

% --------------------------------------------------
\subsubsection*{3.1.2 Two Different Notions of Time}
\addcontentsline{toc}{subsubsection}{3.1.2 Two Different Notions of Time}

There are two important kinds of time:

\begin{itemize}
  \item \textbf{Wall-clock time}
  \item \textbf{CPU time}
\end{itemize}

They are not the same.

Confusing them leads to wrong conclusions.

% --------------------------------------------------
\subsubsection*{3.1.3 Wall-Clock Time}
\addcontentsline{toc}{subsubsection}{3.1.3 Wall-Clock Time}

Wall-clock time is:
\begin{quote}
\emph{The time you measure with a stopwatch.}
\end{quote}

It includes:
\begin{itemize}
  \item computation
  \item waiting for memory
  \item waiting for OS scheduling
  \item waiting for other threads
\end{itemize}

For users, this is the only time that matters.

Parallel computing aims to reduce wall-clock time.

% --------------------------------------------------
\subsubsection*{3.1.4 CPU Time}
\addcontentsline{toc}{subsubsection}{3.1.4 CPU Time}

CPU time measures:
\begin{quote}
\emph{How long the CPU actually worked on your program.}
\end{quote}

Important detail:
\begin{itemize}
  \item one program
  \item multiple cores
  \item CPU time can exceed wall time
\end{itemize}

Example:
\begin{quote}
\emph{4 cores for 1 second $\Rightarrow$ 4 seconds of CPU time}
\end{quote}

This is not a bug.
It is parallelism.

% --------------------------------------------------
\subsubsection*{3.1.5 Why This Confuses Beginners}
\addcontentsline{toc}{subsubsection}{3.1.5 Why This Confuses Beginners}

Students see:
\begin{itemize}
  \item CPU usage above 100\%
  \item ``more work'' reported
\end{itemize}

They panic.

Reality:
\begin{quote}
\emph{More CPU time with less wall time is success.}
\end{quote}

Parallel programs trade CPU for time.

% --------------------------------------------------
\subsubsection*{3.1.6 What Parallel Speedup Really Means}
\addcontentsline{toc}{subsubsection}{3.1.6 What Parallel Speedup Really Means}

Speedup is defined as:
\[
\text{Speedup} = 
\frac{\text{Sequential Wall Time}}
{\text{Parallel Wall Time}}
\]

Not:
\begin{itemize}
  \item CPU usage
  \item number of threads
\end{itemize}

Only wall-clock time matters.

This definition will stay with us forever.

% --------------------------------------------------
\subsection*{Practice on Mac Terminal (Mandatory)}
\addcontentsline{toc}{subsection}{Practice on Mac Terminal (Lesson 3.1)}

\subsubsection*{Practice 1: Measure Wall Time}

Run any existing program using:
\begin{lstlisting}[language=bash]
time ./loops
\end{lstlisting}

Observe:
\begin{itemize}
  \item real (wall time)
  \item user (CPU time)
  \item sys (OS time)
\end{itemize}

Understand the difference.

% --------------------------------------------------
\subsubsection*{Practice 2: Observe CPU Usage}

Run:
\begin{lstlisting}[language=bash]
top
\end{lstlisting}

Then execute a CPU-heavy program.

Observe:
\begin{itemize}
  \item CPU percentage
  \item core usage
\end{itemize}

Relate this to wall-clock behavior.

% --------------------------------------------------
\subsubsection*{Practice 3: Thought Experiment}

Imagine:
\begin{itemize}
  \item sequential time = 8 seconds
  \item parallel time = 2 seconds
  \item CPU time = 8 seconds
\end{itemize}

Ask:
\begin{itemize}
  \item Is this good or bad?
\end{itemize}

If your answer is ``excellent'', your intuition is correct.

% --------------------------------------------------
\subsection*{Checkpoint Questions}
\addcontentsline{toc}{subsection}{Checkpoint Questions (Lesson 3.1)}

Answer clearly:

\begin{enumerate}
  \item Why is wall-clock time the primary metric?
  \item Why can CPU time exceed wall time?
  \item What does speedup really measure?
\end{enumerate}
% ==================================================
\subsection*{Lesson 3.2: Measuring Time Correctly in C++}
\addcontentsline{toc}{subsection}{Measuring Time Correctly in C++}

% --------------------------------------------------
\subsubsection*{3.2.1 Why Timing Is Subtle}
\addcontentsline{toc}{subsubsection}{3.2.1 Why Timing Is Subtle}

Beginners often do:
\begin{quote}
\emph{``I printed start time and end time.''}
\end{quote}

This usually gives:
\begin{itemize}
  \item noisy results
  \item misleading conclusions
\end{itemize}

Parallel computing magnifies timing mistakes.

Timing is an experiment.
Bad experiments give bad science.

% --------------------------------------------------
\subsubsection*{3.2.2 What a Good Timer Must Do}
\addcontentsline{toc}{subsubsection}{3.2.2 What a Good Timer Must Do}

A good timing method must:
\begin{itemize}
  \item measure wall-clock time
  \item have sufficient resolution
  \item be portable
  \item minimize overhead
\end{itemize}

In modern C++, this means:
\begin{quote}
\texttt{<chrono>}
\end{quote}

% --------------------------------------------------
\subsubsection*{3.2.3 The chrono Mental Model}
\addcontentsline{toc}{subsubsection}{3.2.3 The chrono Mental Model}

The \texttt{chrono} library provides:
\begin{itemize}
  \item clocks
  \item time points
  \item durations
\end{itemize}

Think of it as:
\begin{quote}
\emph{A very precise stopwatch managed by the OS.}
\end{quote}

For performance work, we usually use:
\begin{quote}
\texttt{high\_resolution\_clock}
\end{quote}

% --------------------------------------------------
\subsubsection*{3.2.4 A Correct Timing Pattern}
\addcontentsline{toc}{subsubsection}{3.2.4 A Correct Timing Pattern}

Canonical pattern:

\begin{lstlisting}[language=C++]
#include <chrono>
using namespace std::chrono;

auto start = high_resolution_clock::now();

/* code to measure */

auto end = high_resolution_clock::now();
auto elapsed = duration_cast<milliseconds>(end - start);
\end{lstlisting}

Key idea:
\begin{quote}
\emph{Only measure the region you care about.}
\end{quote}

Not setup.
Not printing.
Only work.

% --------------------------------------------------
\subsubsection*{3.2.5 Why Naive Timing Lies}
\addcontentsline{toc}{subsubsection}{3.2.5 Why Naive Timing Lies}

Common mistakes:
\begin{itemize}
  \item timing very small code blocks
  \item including I/O
  \item measuring once
  \item ignoring compiler optimizations
\end{itemize}

Especially dangerous:
\begin{itemize}
  \item printing inside timed loop
\end{itemize}

Printing dominates runtime and hides computation.

% --------------------------------------------------
\subsubsection*{3.2.6 Repeat, Average, and Warm Up}
\addcontentsline{toc}{subsubsection}{3.2.6 Repeat, Average, and Warm Up}

Good timing practice:
\begin{itemize}
  \item run once to warm up caches
  \item repeat multiple times
  \item average results
\end{itemize}

Parallel programs are noisy due to:
\begin{itemize}
  \item OS scheduling
  \
  \item background processes
\end{itemize}

Noise is normal.
Discipline handles it.

% --------------------------------------------------
\subsection*{Practice on Mac Terminal (Mandatory)}
\addcontentsline{toc}{subsection}{Practice on Mac Terminal (Lesson 3.2)}

\subsubsection*{Practice 1: Correct Timing}

Create file:
\begin{lstlisting}[language=bash]
nano timing.cpp
\end{lstlisting}

Write:
\begin{lstlisting}[language=C++]
#include <iostream>
#include <vector>
#include <chrono>
using namespace std;
using namespace chrono;

int main() {
    const int N = 100000000;
    vector<int> a(N, 1);

    auto start = high_resolution_clock::now();

    long long sum = 0;
    for (int i = 0; i < N; i++) {
        sum += a[i];
    }

    auto end = high_resolution_clock::now();
    cout << "Sum = " << sum << endl;
    cout << "Time (ms): "
         << duration_cast<milliseconds>(end - start).count()
         << endl;

    return 0;
}
\end{lstlisting}

Compile and run:
\begin{lstlisting}[language=bash]
g++ -O2 timing.cpp -o timing
./timing
\end{lstlisting}

Observe stability across runs.

% --------------------------------------------------
\subsubsection*{Practice 2: Break the Measurement}

Move the print inside the loop:
\begin{lstlisting}[language=C++]
cout << a[i] << endl;
\end{lstlisting}

Recompile and run.

Observe:
\begin{itemize}
  \item dramatic slowdown
  \item meaningless timing
\end{itemize}

This is a controlled failure.

% --------------------------------------------------
\subsection*{Checkpoint Questions}
\addcontentsline{toc}{subsection}{Checkpoint Questions (Lesson 3.2)}

Answer clearly:

\begin{enumerate}
  \item Why should I/O not be included in timing?
  \item Why must measurements be repeated?
  \item Why is timing a scientific experiment?
\end{enumerate}
% ==================================================
\subsection*{Lesson 3.3: When Optimization Hurts}
\addcontentsline{toc}{subsection}{Lesson 3.3: When Optimization Hurts}

% --------------------------------------------------
\subsubsection*{3.3.1 The Optimization Myth}
\addcontentsline{toc}{subsubsection}{3.3.1 The Optimization Myth}

Beginners believe:
\begin{quote}
\emph{``Optimization only makes code faster.''}
\end{quote}

Reality:
\begin{quote}
\emph{Optimization changes how code executes.}
\end{quote}

If your code relies on:
\begin{itemize}
  \item undefined behavior
  \item accidental ordering
  \item hidden side effects
\end{itemize}

Optimization will expose it.

Parallel computing amplifies this effect.

% --------------------------------------------------
\subsubsection*{3.3.2 What Compiler Optimization Really Does}
\addcontentsline{toc}{subsubsection}{3.3.2 What Compiler Optimization Really Does}

The compiler may:
\begin{itemize}
  \item reorder instructions
  \item remove ``unnecessary'' loads
  \item keep values in registers
  \item eliminate entire loops
\end{itemize}

All of this is legal if:
\begin{quote}
\emph{The observable behavior does not change (for correct code).}
\end{quote}

Parallel bugs often depend on behavior that was never guaranteed.

% --------------------------------------------------
\subsubsection*{3.3.3 Common Optimization Levels}
\addcontentsline{toc}{subsubsection}{3.3.3 Common Optimization Levels}

Important flags:
\begin{itemize}
  \item \texttt{-O0} : no optimization (debug-friendly)
  \item \texttt{-O1} : light optimization
  \item \texttt{-O2} : standard optimization
  \item \texttt{-O3} : aggressive optimization
\end{itemize}

Rule of thumb:
\begin{quote}
\emph{If code only works at -O0, it is broken.}
\end{quote}

% --------------------------------------------------
\subsubsection*{3.3.4 A Classic Optimization Trap}
\addcontentsline{toc}{subsubsection}{3.3.4 A Classic Optimization Trap}

Consider:
\begin{lstlisting}[language=C++]
bool done = false;

while (!done) {
    // wait
}
\end{lstlisting}

Compiler reasoning:
\begin{itemize}
  \item \texttt{done} never changes in this scope
  \item loop is infinite
\end{itemize}

Result:
\begin{itemize}
  \item loop optimized away or frozen
\end{itemize}

Parallel programs often change \texttt{done} in another thread.

Without proper synchronization, behavior is undefined.

% --------------------------------------------------
\subsubsection*{3.3.5 Optimization vs Parallel Correctness}
\addcontentsline{toc}{subsubsection}{3.3.5 Optimization vs Parallel Correctness}

Parallel correctness requires:
\begin{itemize}
  \item well-defined memory access
  \item explicit synchronization
\end{itemize}

Optimization assumes:
\begin{itemize}
  \item single-threaded semantics unless told otherwise
\end{itemize}

This mismatch causes:
\begin{itemize}
  \item race conditions surfacing
  \item bugs appearing only with optimization
\end{itemize}

This is expected, not mysterious.

% --------------------------------------------------
\subsubsection*{3.3.6 The Right Workflow}
\addcontentsline{toc}{subsubsection}{3.3.6 The Right Workflow}

Professional workflow:
\begin{enumerate}
  \item Write correct code
  \item Test with \texttt{-O0}
  \item Enable optimization
  \item Re-test correctness
  \item Measure performance
\end{enumerate}

Never optimize broken code.

Parallel computing punishes shortcuts.

% --------------------------------------------------
\subsection*{Practice on Mac Terminal (Mandatory)}
\addcontentsline{toc}{subsection}{Practice on Mac Terminal (Lesson 3.3)}

\subsubsection*{Practice 1: Compare Optimization Levels}

Compile the same program:
\begin{lstlisting}[language=bash]
g++ -O0 timing.cpp -o timing_O0
g++ -O2 timing.cpp -o timing_O2
\end{lstlisting}

Run both:
\begin{lstlisting}[language=bash]
./timing_O0
./timing_O2
\end{lstlisting}

Observe:
\begin{itemize}
  \item speed difference
  \item same correctness
\end{itemize}

This is healthy optimization.

% --------------------------------------------------
\subsubsection*{Practice 2: Dangerous Assumption}

Create:
\begin{lstlisting}[language=C++]
int flag = 0;
while (flag == 0) {}
\end{lstlisting}

Compile with \texttt{-O2}.

Think:
\begin{itemize}
  \item Why might this loop never exit?
\end{itemize}

This exact pattern breaks many naive parallel codes.

% --------------------------------------------------
\subsection*{Checkpoint Questions}
\addcontentsline{toc}{subsection}{Checkpoint Questions (Lesson 3.3)}

Answer clearly:

\begin{enumerate}
  \item Why can optimization change program behavior?
  \item Why do parallel bugs appear only with \texttt{-O2}?
  \item What is the correct order: optimize or verify?
\end{enumerate}
% ==================================================
\section*{PART 4: The Core Idea -- Parallelism}
\addcontentsline{toc}{section}{PART 4: The Core Idea -- Parallelism}

\subsection*{Lesson 4.1: Sequential vs Parallel Worldview}
\addcontentsline{toc}{subsection}{Lesson 4.1: Sequential vs Parallel Worldview}

% --------------------------------------------------
\subsubsection*{4.1.1 The Sequential Worldview}
\addcontentsline{toc}{subsubsection}{4.1.1 The Sequential Worldview}

Traditional programming assumes:
\begin{itemize}
  \item one worker
  \item one instruction at a time
  \item total order of execution
\end{itemize}

Mental model:
\begin{quote}
\emph{Finish this, then do the next thing.}
\end{quote}

This model is simple, predictable, and safe.

But it does not scale.

% --------------------------------------------------
\subsubsection*{4.1.2 The Cost of Sequential Thinking}
\addcontentsline{toc}{subsubsection}{4.1.2 The Cost of Sequential Thinking}

In the sequential model:
\begin{itemize}
  \item total time = sum of all task times
\end{itemize}

If you have:
\begin{itemize}
  \item 100 independent tasks
  \item each takes 1 second
\end{itemize}

Then:
\[
\text{Total time} = 100 \text{ seconds}
\]

Even if 99 other cores sit idle.

This is wasted potential.

% --------------------------------------------------
\subsubsection*{4.1.3 The Parallel Worldview}
\addcontentsline{toc}{subsubsection}{4.1.3 The Parallel Worldview}

Parallel thinking asks a different question:

\begin{quote}
\emph{What can happen at the same time?}
\end{quote}

Mental model:
\begin{itemize}
  \item many workers
  \item shared or distributed resources
  \item partial ordering
\end{itemize}

Tasks may:
\begin{itemize}
  \item start together
  \item finish at different times
\end{itemize}

Order is no longer automatic.
It must be designed.

% --------------------------------------------------
\subsubsection*{4.1.4 One Worker vs Many Workers}
\addcontentsline{toc}{subsubsection}{4.1.4 One Worker vs Many Workers}

Sequential execution:
\begin{quote}
Worker does Task 1 $\rightarrow$ Task 2 $\rightarrow$ Task 3
\end{quote}

Parallel execution:
\begin{quote}
Worker A does Task 1 \\
Worker B does Task 2 \\
Worker C does Task 3
\end{quote}

If tasks are independent:
\[
\text{Total time} \approx \max(\text{task times})
\]

This is the promise of parallelism.

% --------------------------------------------------
\subsubsection*{4.1.5 Independence Is Everything}
\addcontentsline{toc}{subsubsection}{4.1.5 Independence Is Everything}

Parallelism requires:
\begin{itemize}
  \item no data dependency
  \item no ordering constraint
\end{itemize}

If tasks share writable state:
\begin{itemize}
  \item synchronization is required
  \item speedup decreases
\end{itemize}

\textbf{Key insight:}
\begin{quote}
\emph{Parallelism is about structure, not threads.}
\end{quote}

Threads are an implementation detail.

% --------------------------------------------------
\subsubsection*{4.1.6 Partial Order, Not Chaos}
\addcontentsline{toc}{subsubsection}{4.1.6 Partial Order, Not Chaos}

Parallel programs are often misunderstood as:
\begin{quote}
\emph{``Everything runs randomly.''}
\end{quote}

Reality:
\begin{itemize}
  \item some things must happen before others
  \item many things are unordered
\end{itemize}

This creates a \textbf{partial order}.

Designing correct partial orders is the art of parallel computing.

% --------------------------------------------------
\subsubsection*{4.1.7 Why This Is Hard for Humans}
\addcontentsline{toc}{subsubsection}{4.1.7 Why This Is Hard for Humans}

Humans think sequentially:
\begin{itemize}
  \item stories
  \item steps
  \item cause then effect
\end{itemize}

Parallel programs require thinking in:
\begin{itemize}
  \item sets
  \item dependencies
  \item graphs
\end{itemize}

This is why parallelism feels unnatural at first.

It becomes natural with practice.

% --------------------------------------------------
\subsection*{Practice on Mac Terminal (Mandatory)}
\addcontentsline{toc}{subsection}{Practice on Mac Terminal (Lesson 4.1)}

\subsubsection*{Practice 1: Sequential Bottleneck}

Create file:
\begin{lstlisting}[language=bash]
nano seq.cpp
\end{lstlisting}

Write:
\begin{lstlisting}[language=C++]
#include <iostream>
#include <thread>
using namespace std;

void work() {
    for (volatile int i = 0; i < 100000000; i++) {}
}

int main() {
    work();
    work();
    work();
    return 0;
}
\end{lstlisting}

Compile and run:
\begin{lstlisting}[language=bash]
g++ -O2 seq.cpp -o seq
time ./seq
\end{lstlisting}

Observe total wall time.

% --------------------------------------------------
\subsubsection*{Practice 2: Thought Experiment}

Imagine:
\begin{itemize}
  \item three identical workers
  \item three independent tasks
\end{itemize}

Ask:
\begin{itemize}
  \item What is the theoretical minimum time?
\end{itemize}

This number becomes your speedup limit.

% --------------------------------------------------
\subsection*{Checkpoint Questions}
\addcontentsline{toc}{subsection}{Checkpoint Questions (Lesson 4.1)}

Answer clearly:

\begin{enumerate}
  \item What is the difference between sequential and parallel worldviews?
  \item Why is independence essential?
  \item What does partial order mean?
\end{enumerate}
% ==================================================
\subsection*{Lesson 4.2: Task Parallelism}
\addcontentsline{toc}{subsection}{Lesson 4.2: Task Parallelism}

% --------------------------------------------------
\subsubsection*{4.2.1 What Is a Task?}
\addcontentsline{toc}{subsubsection}{4.2.1 What Is a Task?}

A \textbf{task} is:
\begin{itemize}
  \item a unit of work
  \item with a clear beginning and end
  \item that may run independently
\end{itemize}

Key point:
\begin{quote}
\emph{Tasks describe work. Threads execute work.}
\end{quote}

Confusing these two leads to poor parallel design.

% --------------------------------------------------
\subsubsection*{4.2.2 Task Parallelism vs Loop Parallelism}
\addcontentsline{toc}{subsubsection}{4.2.2 Task Parallelism vs Loop Parallelism}

There are two major kinds of parallelism:

\begin{itemize}
  \item \textbf{Task parallelism} — different work
  \item \textbf{Data parallelism} — same work, different data
\end{itemize}

Task parallelism focuses on:
\begin{itemize}
  \item different functions
  \item different algorithms
  \item different stages
\end{itemize}

This is common in:
\begin{itemize}
  \item pipelines
  \item simulations
  \item coupled physics models
\end{itemize}

% --------------------------------------------------
\subsubsection*{4.2.3 A Simple Task Example}
\addcontentsline{toc}{subsubsection}{4.2.3 A Simple Task Example}

Consider:
\begin{lstlisting}[language=C++]
void read_data();
void process_data();
void write_output();
\end{lstlisting}

Sequential thinking:
\begin{lstlisting}[language=C++]
read_data();
process_data();
write_output();
\end{lstlisting}

Parallel thinking asks:
\begin{itemize}
  \item Can some of these overlap?
\end{itemize}

If:
\begin{itemize}
  \item processing can begin before all data is read
\end{itemize}

Then task parallelism exists.

% --------------------------------------------------
\subsubsection*{4.2.4 Independence and Communication}
\addcontentsline{toc}{subsubsection}{4.2.4 Independence and Communication}

Tasks are rarely completely independent.

They often:
\begin{itemize}
  \item produce data for other tasks
  \item consume data from others
\end{itemize}

Parallel design goal:
\begin{quote}
\emph{Minimize communication, maximize independent work.}
\end{quote}

Communication introduces:
\begin{itemize}
  \item waiting
  \item synchronization
\end{itemize}

Which reduces speedup.

% --------------------------------------------------
\subsubsection*{4.2.5 Task Graphs (DAGs)}
\addcontentsline{toc}{subsubsection}{4.2.5 Task Graphs (DAGs)}

Tasks and dependencies can be represented as a graph.

\begin{itemize}
  \item nodes $\rightarrow$ tasks
  \item edges $\rightarrow$ dependencies
\end{itemize}

This graph is usually a:
\begin{quote}
\emph{Directed Acyclic Graph (DAG)}
\end{quote}

Parallel execution means:
\begin{itemize}
  \item scheduling independent nodes together
\end{itemize}

This is how modern runtimes think.

% --------------------------------------------------
\subsubsection*{4.2.6 Why Task Parallelism Scales Well}
\addcontentsline{toc}{subsubsection}{4.2.6 Why Task Parallelism Scales Well}

Task parallelism:
\begin{itemize}
  \item reduces shared memory access
  \item matches human problem decomposition
\end{itemize}

It scales well when:
\begin{itemize}
  \item tasks are coarse-grained
  \item dependencies are few
\end{itemize}

This is why it dominates large systems.

% --------------------------------------------------
\subsection*{Practice on Mac Terminal (Mandatory)}
\addcontentsline{toc}{subsection}{Practice on Mac Terminal (Lesson 4.2)}

\subsubsection*{Practice 1: Identify Tasks}

Create file:
\begin{lstlisting}[language=bash]
nano tasks.txt
\end{lstlisting}

Write (no code, just text):
\begin{itemize}
  \item read input
  \item compute statistics
  \item write output
\end{itemize}

Now answer:
\begin{itemize}
  \item Which tasks can overlap?
  \item Which must wait?
\end{itemize}

This is task-graph thinking.

% --------------------------------------------------
\subsubsection*{Practice 2: Function-Level Tasks}

Look at any earlier C++ program you wrote.

Identify:
\begin{itemize}
  \item independent function calls
  \item shared data between them
\end{itemize}

This skill matters more than syntax.

% --------------------------------------------------
\subsection*{Checkpoint Questions}
\addcontentsline{toc}{subsection}{Checkpoint Questions (Lesson 4.2)}

Answer clearly:

\begin{enumerate}
  \item What is the difference between a task and a thread?
  \item Why is communication the enemy of speedup?
  \item Why are DAGs useful for parallel thinking?
\end{enumerate}
% ==================================================
\subsection*{Lesson 4.3: Data Parallelism -- Same Work, Many Data Points}
\addcontentsline{toc}{subsection}{Lesson 4.3: Data Parallelism -- Same Work, Many Data Points}

% --------------------------------------------------
\subsubsection*{4.3.1 The Core Idea}
\addcontentsline{toc}{subsubsection}{4.3.1 The Core Idea}

Data parallelism means:
\begin{quote}
\emph{Apply the same operation independently to many data elements.}
\end{quote}

Key characteristics:
\begin{itemize}
  \item same code
  \item different data
  \item independent iterations
\end{itemize}

This is the most common form of parallelism in scientific computing.

% --------------------------------------------------
\subsubsection*{4.3.2 Why Data Parallelism Is So Powerful}
\addcontentsline{toc}{subsubsection}{4.3.2 Why Data Parallelism Is So Powerful}

Data parallelism:
\begin{itemize}
  \item matches array-based math
  \item maps directly to hardware
  \item minimizes synchronization
\end{itemize}

Examples:
\begin{itemize}
  \item vector addition
  \item matrix operations
  \item image processing
  \item numerical simulations
\end{itemize}

This is why GPUs exist.

% --------------------------------------------------
\subsubsection*{4.3.3 Loops as Data-Parallel Descriptions}
\addcontentsline{toc}{subsubsection}{4.3.3 Loops as Data-Parallel Descriptions}

Consider:
\begin{lstlisting}[language=C++]
for (int i = 0; i < N; i++) {
    b[i] = 2 * a[i];
}
\end{lstlisting}

Interpretation:
\begin{itemize}
  \item iteration \texttt{i} works on element \texttt{i}
  \item no overlap in memory
\end{itemize}

This loop is:
\begin{quote}
\emph{Embarrassingly parallel}
\end{quote}

No communication. No ordering.

% --------------------------------------------------
\subsubsection*{4.3.4 Data Parallelism vs Task Parallelism}
\addcontentsline{toc}{subsubsection}{4.3.4 Data Parallelism vs Task Parallelism}

Compare:

\textbf{Task parallelism}:
\begin{itemize}
  \item different functions
  \item different logic
\end{itemize}

\textbf{Data parallelism}:
\begin{itemize}
  \item same function
  \item many data points
\end{itemize}

In practice:
\begin{itemize}
  \item task parallelism is coarse-grained
  \item data parallelism is fine-grained
\end{itemize}

Good programs combine both.

% --------------------------------------------------
\subsubsection*{4.3.5 The Hidden Enemy: Reductions}
\addcontentsline{toc}{subsubsection}{4.3.5 The Hidden Enemy: Reductions}

Consider:
\begin{lstlisting}[language=C++]
int sum = 0;
for (int i = 0; i < N; i++) {
    sum += a[i];
}
\end{lstlisting}

Math view:
\begin{itemize}
  \item independent additions
\end{itemize}

Memory view:
\begin{itemize}
  \item shared variable \texttt{sum}
\end{itemize}

This is a data race if parallelized naively.

Solution requires:
\begin{itemize}
  \item private partial sums
  \item controlled combination
\end{itemize}

We will return to this in OpenMP.

% --------------------------------------------------
\subsubsection*{4.3.6 Why Order Often Does Not Matter}
\addcontentsline{toc}{subsubsection}{4.3.6 Why Order Often Does Not Matter}

Many operations are:
\begin{itemize}
  \item associative
  \item commutative
\end{itemize}

Example:
\[
a + b = b + a
\]

This allows:
\begin{itemize}
  \item flexible execution order
  \item parallel combination
\end{itemize}

But not all operations have this property.

Parallelism must respect mathematics.

% --------------------------------------------------
\subsection*{Practice on Mac Terminal (Mandatory)}
\addcontentsline{toc}{subsection}{Practice on Mac Terminal (Lesson 4.3)}

\subsubsection*{Practice 1: Pure Data Parallel Loop}

Create file:
\begin{lstlisting}[language=bash]
nano data_parallel.cpp
\end{lstlisting}

Write:
\begin{lstlisting}[language=C++]
#include <iostream>
#include <vector>
using namespace std;

int main() {
    int N = 10;
    vector<int> a(N), b(N);

    for (int i = 0; i < N; i++) {
        a[i] = i;
    }

    for (int i = 0; i < N; i++) {
        b[i] = 2 * a[i];
    }

    for (int i = 0; i < N; i++) {
        cout << b[i] << " ";
    }
    cout << endl;

    return 0;
}
\end{lstlisting}

Compile and run:
\begin{lstlisting}[language=bash]
g++ data_parallel.cpp -o data_parallel
./data_parallel
\end{lstlisting}

Ask:
\begin{itemize}
  \item Why can iterations run in any order?
\end{itemize}

% --------------------------------------------------
\subsubsection*{Practice 2: Reduction Hazard}

Add:
\begin{lstlisting}[language=C++]
int sum = 0;
for (int i = 0; i < N; i++) {
    sum += a[i];
}
cout << sum << endl;
\end{lstlisting}

Ask:
\begin{itemize}
  \item Why is this not trivially parallel?
\end{itemize}

You are seeing the core reduction problem.

% --------------------------------------------------
\subsection*{Checkpoint Questions}
\addcontentsline{toc}{subsection}{Checkpoint Questions (Lesson 4.3)}

Answer clearly:

\begin{enumerate}
  \item What defines data parallelism?
  \item Why are independent loops ideal?
  \item Why do reductions require special handling?
\end{enumerate}
% ==================================================
\section*{PART 5: Threads -- Shared Memory Parallelism}
\addcontentsline{toc}{section}{PART 5: Threads -- Shared Memory Parallelism}

\subsection*{Lesson 5.1: What Is a Thread?}
\addcontentsline{toc}{subsection}{Lesson 5.1: What Is a Thread?}

% --------------------------------------------------
\subsubsection*{5.1.1 Why Threads Exist}
\addcontentsline{toc}{subsubsection}{5.1.1 Why Threads Exist}

Recall:
\begin{itemize}
  \item modern CPUs have many cores
  \item sequential programs use only one
\end{itemize}

Threads exist to answer one question:
\begin{quote}
\emph{How can one program use multiple cores at the same time?}
\end{quote}

Threads are the OS-level answer.

% --------------------------------------------------
\subsubsection*{5.1.2 Process vs Thread}
\addcontentsline{toc}{subsubsection}{5.1.2 Process vs Thread}

A \textbf{process} has:
\begin{itemize}
  \item its own address space
  \item its own memory
  \item strong isolation
\end{itemize}

A \textbf{thread} has:
\begin{itemize}
  \item its own execution stack
  \item shared address space with other threads
\end{itemize}

Key difference:
\begin{quote}
\emph{Threads share memory. Processes do not.}
\end{quote}

This is both the power and the danger.

% --------------------------------------------------
\subsubsection*{5.1.3 What Threads Share}
\addcontentsline{toc}{subsubsection}{5.1.3 What Threads Share}

All threads in a process share:
\begin{itemize}
  \item heap memory
  \item global variables
  \item file descriptors
\end{itemize}

Each thread has its own:
\begin{itemize}
  \item stack
  \item instruction pointer
  \item registers
\end{itemize}

This explains:
\begin{itemize}
  \item why local variables are safe
  \item why globals are dangerous
\end{itemize}

% --------------------------------------------------
\subsubsection*{5.1.4 The Illusion of Simultaneity (Again)}
\addcontentsline{toc}{subsubsection}{5.1.4 The Illusion of Simultaneity (Again)}

Threads appear to run simultaneously.

Reality:
\begin{itemize}
  \item true parallelism if cores are available
  \item time-slicing otherwise
\end{itemize}

The OS scheduler:
\begin{itemize}
  \item decides which thread runs
  \item can interrupt at any instruction
\end{itemize}

This unpredictability is why races exist.

% --------------------------------------------------
\subsubsection*{5.1.5 Why Threads Are Harder Than Processes}
\addcontentsline{toc}{subsubsection}{5.1.5 Why Threads Are Harder Than Processes}

Threads are harder because:
\begin{itemize}
  \item memory is shared
  \item ordering is not guaranteed
  \item bugs are non-deterministic
\end{itemize}

But threads are faster because:
\begin{itemize}
  \item no data copying
  \item cheap communication
\end{itemize}

Parallel computing is a trade-off:
\begin{quote}
\emph{Performance in exchange for complexity.}
\end{quote}

% --------------------------------------------------
\subsubsection*{5.1.6 The Mental Model You Must Use}
\addcontentsline{toc}{subsubsection}{5.1.6 The Mental Model You Must Use}

Correct mental model:
\begin{quote}
\emph{Many independent workers touching the same whiteboard.}
\end{quote}

Rules:
\begin{itemize}
  \item reading is usually safe
  \item writing must be controlled
\end{itemize}

Everything in thread programming follows from this.

% --------------------------------------------------
\subsection*{Practice on Mac Terminal (Mandatory)}
\addcontentsline{toc}{subsection}{Practice on Mac Terminal (Lesson 5.1)}

\subsubsection*{Practice 1: Your First Threaded Program}

Create file:
\begin{lstlisting}[language=bash]
nano threads.cpp
\end{lstlisting}

Write:
\begin{lstlisting}[language=C++]
#include <iostream>
#include <thread>
using namespace std;

void work(int id) {
    cout << "Hello from thread " << id << endl;
}

int main() {
    thread t1(work, 1);
    thread t2(work, 2);

    t1.join();
    t2.join();

    return 0;
}
\end{lstlisting}

Compile and run:
\begin{lstlisting}[language=bash]
g++ -std=c++17 threads.cpp -o threads
./threads
\end{lstlisting}

Observe:
\begin{itemize}
  \item order of output may change
\end{itemize}

This is concurrency.

% --------------------------------------------------
\subsubsection*{Practice 2: Shared State}

Modify:
\begin{lstlisting}[language=C++]
int counter = 0;

void work() {
    counter++;
}
\end{lstlisting}

Call \texttt{work()} from two threads.

Think:
\begin{itemize}
  \item What could go wrong?
\end{itemize}

Do not fix it yet.
We want to feel the problem first.

% --------------------------------------------------
\subsection*{Checkpoint Questions}
\addcontentsline{toc}{subsection}{Checkpoint Questions (Lesson 5.1)}

Answer clearly:

\begin{enumerate}
  \item What is the key difference between a process and a thread?
  \item What memory is shared between threads?
  \item Why does unpredictability create bugs?
\end{enumerate}
% ==================================================
\subsection*{Lesson 5.2: Race Conditions -- Why Correct Code Breaks in Parallel}
\addcontentsline{toc}{subsection}{Lesson 5.2: Race Conditions -- Why Correct Code Breaks in Parallel}

% --------------------------------------------------
\subsubsection*{5.2.1 The Most Dangerous Misbelief}
\addcontentsline{toc}{subsubsection}{5.2.1 The Most Dangerous Misbelief}

Students often believe:
\begin{quote}
\emph{``If my code is correct sequentially, it will be correct in parallel.''}
\end{quote}

This belief is false.

Parallel execution introduces:
\begin{itemize}
  \item interleaving
  \item reordering
  \item partial execution
\end{itemize}

Correctness must now be designed.

% --------------------------------------------------
\subsubsection*{5.2.2 What Is a Race Condition?}
\addcontentsline{toc}{subsubsection}{5.2.2 What Is a Race Condition?}

A \textbf{race condition} occurs when:
\begin{itemize}
  \item two or more threads
  \item access the same memory location
  \item at least one writes
  \item without synchronization
\end{itemize}

The final result depends on:
\begin{quote}
\emph{Who wins the race.}
\end{quote}

This makes behavior nondeterministic.

% --------------------------------------------------
\subsubsection*{5.2.3 The Classic Counter Example}
\addcontentsline{toc}{subsubsection}{5.2.3 The Classic Counter Example}

Consider:
\begin{lstlisting}[language=C++]
int counter = 0;

void work() {
    counter++;
}
\end{lstlisting}

Sequential execution:
\begin{itemize}
  \item counter becomes 1, then 2
\end{itemize}

Parallel execution:
\begin{itemize}
  \item both threads read counter = 0
  \item both compute 1
  \item both write 1
\end{itemize}

Final result:
\[
\texttt{counter} = 1 \quad \text{(wrong)}
\]

No line is wrong.
The interleaving is.

% --------------------------------------------------
\subsubsection*{5.2.4 Why This Is Not Randomness}
\addcontentsline{toc}{subsubsection}{5.2.4 Why This Is Not Randomness}

Race conditions are often described as:
\begin{quote}
\emph{``random behavior''}
\end{quote}

This is misleading.

The behavior is:
\begin{itemize}
  \item deterministic per execution
  \item unpredictable across executions
\end{itemize}

The OS scheduler decides the order.
Your code did not specify one.

% --------------------------------------------------
\subsubsection*{5.2.5 Read-Modify-Write Is Not Atomic}
\addcontentsline{toc}{subsubsection}{5.2.5 Read-Modify-Write Is Not Atomic}

The statement:
\begin{lstlisting}[language=C++]
counter++;
\end{lstlisting}

Actually means:
\begin{enumerate}
  \item read counter
  \item add 1
  \item write counter
\end{enumerate}

Threads can interleave between these steps.

This is the root cause of many race conditions.

% --------------------------------------------------
\subsubsection*{5.2.6 When Races Do NOT Occur}
\addcontentsline{toc}{subsubsection}{5.2.6 When Races Do NOT Occur}

No race condition if:
\begin{itemize}
  \item all threads only read shared data
  \item or each thread writes to private memory
\end{itemize}

This is why:
\begin{itemize}
  \item local variables are safe
  \item stack memory is safe
\end{itemize}

Designing for safety is better than fixing races later.

% --------------------------------------------------
\subsubsection*{5.2.7 Why Races Are So Hard to Debug}
\addcontentsline{toc}{subsubsection}{5.2.7 Why Races Are So Hard to Debug}

Race conditions:
\begin{itemize}
  \item may disappear when you add print statements
  \item may appear only under load
  \item may fail once in 1000 runs
\end{itemize}

Reason:
\begin{itemize}
  \item timing changes execution order
\end{itemize}

This is why print-debugging often lies.

% --------------------------------------------------
\subsection*{Practice on Mac Terminal (Mandatory)}
\addcontentsline{toc}{subsection}{Practice on Mac Terminal (Lesson 5.2)}

\subsubsection*{Practice 1: Observe the Race}

Create file:
\begin{lstlisting}[language=bash]
nano race.cpp
\end{lstlisting}

Write:
\begin{lstlisting}[language=C++]
#include <iostream>
#include <thread>
using namespace std;

int counter = 0;

void work() {
    for (int i = 0; i < 100000; i++) {
        counter++;
    }
}

int main() {
    thread t1(work);
    thread t2(work);

    t1.join();
    t2.join();

    cout << "Final counter: " << counter << endl;
    return 0;
}
\end{lstlisting}

Compile and run multiple times:
\begin{lstlisting}[language=bash]
g++ -O2 race.cpp -o race
./race
./race
./race
\end{lstlisting}

Observe:
\begin{itemize}
  \item different answers
  \item none equal to expected 200000
\end{itemize}

You are seeing a race condition.

% --------------------------------------------------
\subsubsection*{Practice 2: Remove Parallelism}

Run the same code with only one thread.

Observe:
\begin{itemize}
  \item correctness returns
\end{itemize}

The bug is not logic.
It is concurrency.

% --------------------------------------------------
\subsection*{Checkpoint Questions}
\addcontentsline{toc}{subsection}{Checkpoint Questions (Lesson 5.2)}

Answer carefully:

\begin{enumerate}
  \item What exactly defines a race condition?
  \item Why is \texttt{counter++} unsafe?
  \item Why does adding print statements change behavior?
\end{enumerate}
% ==================================================
\subsection*{Lesson 5.3: Synchronization -- Mutexes, Locks, and Critical Sections}
\addcontentsline{toc}{subsection}{Lesson 5.3: Synchronization -- Mutexes, Locks, and Critical Sections}

% --------------------------------------------------
\subsubsection*{5.3.1 What Synchronization Really Means}
\addcontentsline{toc}{subsubsection}{5.3.1 What Synchronization Really Means}

Synchronization does \textbf{not} mean:
\begin{quote}
\emph{``Make threads go faster.''}
\end{quote}

It means:
\begin{quote}
\emph{``Control access to shared resources.''}
\end{quote}

Threads are fast.
Uncontrolled sharing is dangerous.

Synchronization trades some speed for correctness.

% --------------------------------------------------
\subsubsection*{5.3.2 The Critical Section Concept}
\addcontentsline{toc}{subsubsection}{5.3.2 The Critical Section Concept}

A \textbf{critical section} is:
\begin{quote}
\emph{A region of code that must not be executed by more than one thread at a time.}
\end{quote}

Example:
\begin{lstlisting}[language=C++]
counter++;
\end{lstlisting}

This single line is a critical section.

The mistake beginners make:
\begin{itemize}
  \item thinking critical sections must be large
\end{itemize}

Reality:
\begin{quote}
\emph{Critical sections should be as small as possible.}
\end{quote}

% --------------------------------------------------
\subsubsection*{5.3.3 The Mutex: A Lock for Memory}
\addcontentsline{toc}{subsubsection}{5.3.3 The Mutex: A Lock for Memory}

A \textbf{mutex} (mutual exclusion) is:
\begin{itemize}
  \item a lock
  \item protecting a shared resource
\end{itemize}

Rule:
\begin{quote}
\emph{Only one thread can hold the mutex at a time.}
\end{quote}

Other threads must wait.

This enforces order where needed.

% --------------------------------------------------
\subsubsection*{5.3.4 Using a Mutex Correctly}
\addcontentsline{toc}{subsubsection}{5.3.4 Using a Mutex Correctly}

Canonical pattern:
\begin{lstlisting}[language=C++]
#include <mutex>

std::mutex m;

void work() {
    m.lock();
    // critical section
    m.unlock();
}
\end{lstlisting}

This guarantees correctness.

But it is dangerous if:
\begin{itemize}
  \item an exception occurs
  \item a return happens before unlock
\end{itemize}

This leads to deadlocks.

% --------------------------------------------------
\subsubsection*{5.3.5 RAII: Locking Without Fear}
\addcontentsline{toc}{subsubsection}{5.3.5 RAII: Locking Without Fear}

Correct modern C++ uses RAII:

\begin{lstlisting}[language=C++]
void work() {
    std::lock_guard<std::mutex> guard(m);
    // critical section
}
\end{lstlisting}

Properties:
\begin{itemize}
  \item lock acquired at construction
  \item lock released automatically
\end{itemize}

This is:
\begin{quote}
\emph{Exception-safe and human-error resistant.}
\end{quote}

Always prefer this style.

% --------------------------------------------------
\subsubsection*{5.3.6 Fixing the Counter Race}
\addcontentsline{toc}{subsubsection}{5.3.6 Fixing the Counter Race}

Original buggy code:
\begin{lstlisting}[language=C++]
counter++;
\end{lstlisting}

Correct synchronized version:
\begin{lstlisting}[language=C++]
std::mutex m;

void work() {
    std::lock_guard<std::mutex> guard(m);
    counter++;
}
\end{lstlisting}

Now:
\begin{itemize}
  \item correctness is guaranteed
  \item interleaving is controlled
\end{itemize}

Speed may decrease slightly.
Correctness is non-negotiable.

% --------------------------------------------------
\subsubsection*{5.3.7 The Cost of Locking}
\addcontentsline{toc}{subsubsection}{5.3.7 The Cost of Locking}

Locks introduce:
\begin{itemize}
  \item waiting
  \item contention
  \item serialization
\end{itemize}

Too much locking:
\begin{itemize}
  \item destroys parallel speedup
\end{itemize}

Design principle:
\begin{quote}
\emph{Protect data, not code.}
\end{quote}

Minimize shared writable state.

% --------------------------------------------------
\subsection*{Practice on Mac Terminal (Mandatory)}
\addcontentsline{toc}{subsection}{Practice on Mac Terminal (Lesson 5.3)}

\subsubsection*{Practice 1: Fix the Race}

Modify your earlier \texttt{race.cpp}:

\begin{lstlisting}[language=C++]
#include <mutex>

std::mutex m;

void work() {
    for (int i = 0; i < 100000; i++) {
        std::lock_guard<std::mutex> guard(m);
        counter++;
    }
}
\end{lstlisting}

Compile and run multiple times:
\begin{lstlisting}[language=bash]
g++ -O2 race.cpp -o race
./race
./race
\end{lstlisting}

Observe:
\begin{itemize}
  \item consistent correct result
\end{itemize}

You have eliminated the race.

% --------------------------------------------------
\subsubsection*{Practice 2: Think About Granularity}

Ask yourself:
\begin{itemize}
  \item Is locking inside the loop optimal?
  \item Can we reduce lock frequency?
\end{itemize}

Do not fix yet.
We will address this later.

% --------------------------------------------------
\subsection*{Checkpoint Questions}
\addcontentsline{toc}{subsection}{Checkpoint Questions (Lesson 5.3)}

Answer carefully:

\begin{enumerate}
  \item What is a critical section?
  \item Why does a mutex guarantee correctness?
  \item Why must locking be minimized?
\end{enumerate}
% ==================================================
\subsection*{Lesson 5.4: Deadlocks -- When Correct Locks Freeze Programs}
\addcontentsline{toc}{subsection}{Lesson 5.4: Deadlocks -- When Correct Locks Freeze Programs}

% --------------------------------------------------
\subsubsection*{5.4.1 What Is a Deadlock?}
\addcontentsline{toc}{subsubsection}{5.4.1 What Is a Deadlock?}

A \textbf{deadlock} occurs when:
\begin{itemize}
  \item two or more threads
  \item are waiting for each other
  \item forever
\end{itemize}

Each thread holds something the other needs.

Result:
\begin{quote}
\emph{The program stops making progress.}
\end{quote}

No crash.
No error.
Just silence.

% --------------------------------------------------
\subsubsection*{5.4.2 The Simplest Deadlock Example}
\addcontentsline{toc}{subsubsection}{5.4.2 The Simplest Deadlock Example}

Consider two mutexes:
\begin{lstlisting}[language=C++]
std::mutex A;
std::mutex B;
\end{lstlisting}

Thread 1:
\begin{lstlisting}[language=C++]
A.lock();
B.lock();
\end{lstlisting}

Thread 2:
\begin{lstlisting}[language=C++]
B.lock();
A.lock();
\end{lstlisting}

Possible execution:
\begin{itemize}
  \item Thread 1 locks A
  \item Thread 2 locks B
  \item Thread 1 waits for B
  \item Thread 2 waits for A
\end{itemize}

Nobody moves.
Deadlock achieved.

% --------------------------------------------------
\subsubsection*{5.4.3 The Four Necessary Conditions for Deadlock}
\addcontentsline{toc}{subsubsection}{5.4.3 The Four Necessary Conditions for Deadlock}

A deadlock can occur only if \textbf{all four} conditions hold:

\begin{enumerate}
  \item Mutual exclusion (locks exist)
  \item Hold and wait (threads hold one lock while waiting for another)
  \item No preemption (locks cannot be forcibly taken)
  \item Circular wait (a cycle of waiting)
\end{enumerate}

To prevent deadlock:
\begin{quote}
\emph{Break at least one of these conditions.}
\end{quote}

This is a powerful design principle.

% --------------------------------------------------
\subsubsection*{5.4.4 The Most Common Cause: Lock Order}
\addcontentsline{toc}{subsubsection}{5.4.4 The Most Common Cause: Lock Order}

The most frequent real-world cause is:
\begin{quote}
\emph{Inconsistent lock acquisition order.}
\end{quote}

If all threads acquire locks in the same order:
\begin{itemize}
  \item circular wait cannot occur
\end{itemize}

Rule:
\begin{quote}
\emph{Define a global lock ordering and never violate it.}
\end{quote}

This rule alone prevents most deadlocks.

% --------------------------------------------------
\subsubsection*{5.4.5 std::lock: Locking Without Deadlock}
\addcontentsline{toc}{subsubsection}{5.4.5 std::lock: Locking Without Deadlock}

C++ provides:
\begin{lstlisting}[language=C++]
std::lock(m1, m2);
\end{lstlisting}

This function:
\begin{itemize}
  \item locks multiple mutexes
  \item avoids deadlock internally
\end{itemize}

Used with:
\begin{lstlisting}[language=C++]
std::lock_guard<std::mutex> g1(m1, std::adopt_lock);
std::lock_guard<std::mutex> g2(m2, std::adopt_lock);
\end{lstlisting}

This is the safe modern pattern.

% --------------------------------------------------
\subsubsection*{5.4.6 Why Deadlocks Are Harder Than Races}
\addcontentsline{toc}{subsubsection}{5.4.6 Why Deadlocks Are Harder Than Races}

Race conditions:
\begin{itemize}
  \item show wrong output
\end{itemize}

Deadlocks:
\begin{itemize}
  \item show nothing
  \item look like slow programs
\end{itemize}

Students often misdiagnose deadlocks as:
\begin{itemize}
  \item infinite loops
  \item performance issues
\end{itemize}

They are synchronization bugs.

% --------------------------------------------------
\subsubsection*{5.4.7 Design to Avoid Deadlocks}
\addcontentsline{toc}{subsubsection}{5.4.7 Design to Avoid Deadlocks}

Best practices:
\begin{itemize}
  \item minimize shared state
  \item avoid nested locks
  \item keep critical sections small
  \item use higher-level abstractions
\end{itemize}

The best deadlock is:
\begin{quote}
\emph{The one that cannot happen by design.}
\end{quote}

% --------------------------------------------------
\subsection*{Practice on Mac Terminal (Mandatory)}
\addcontentsline{toc}{subsection}{Practice on Mac Terminal (Lesson 5.4)}

\subsubsection*{Practice 1: Create a Deadlock (On Purpose)}

Create file:
\begin{lstlisting}[language=bash]
nano deadlock.cpp
\end{lstlisting}

Write:
\begin{lstlisting}[language=C++]
#include <iostream>
#include <thread>
#include <mutex>
using namespace std;

mutex A, B;

void t1() {
    lock_guard<mutex> g1(A);
    this_thread::sleep_for(chrono::milliseconds(100));
    lock_guard<mutex> g2(B);
}

void t2() {
    lock_guard<mutex> g1(B);
    this_thread::sleep_for(chrono::milliseconds(100));
    lock_guard<mutex> g2(A);
}

int main() {
    thread x(t1);
    thread y(t2);

    x.join();
    y.join();
    return 0;
}
\end{lstlisting}

Compile and run:
\begin{lstlisting}[language=bash]
g++ -O2 deadlock.cpp -o deadlock
./deadlock
\end{lstlisting}

Observe:
\begin{itemize}
  \item program freezes
\end{itemize}

This is a deadlock.

% --------------------------------------------------
\subsubsection*{Practice 2: Fix with Ordering}

Modify both threads to lock A then B.

Recompile and run.

Observe:
\begin{itemize}
  \item deadlock disappears
\end{itemize}

This demonstrates lock ordering.

% --------------------------------------------------
\subsection*{Checkpoint Questions}
\addcontentsline{toc}{subsection}{Checkpoint Questions (Lesson 5.4)}

Answer carefully:

\begin{enumerate}
  \item What is a deadlock?
  \item What are the four necessary conditions?
  \item Why does consistent lock ordering work?
\end{enumerate}
% ==================================================
\subsection*{Lesson 5.5: Performance vs Correctness -- Why Locks Kill Speed}
\addcontentsline{toc}{subsection}{Lesson 5.5: Performance vs Correctness -- Why Locks Kill Speed}

% --------------------------------------------------
\subsubsection*{5.5.1 The Unavoidable Trade-Off}
\addcontentsline{toc}{subsubsection}{5.5.1 The Unavoidable Trade-Off}

Synchronization guarantees:
\begin{itemize}
  \item correctness
\end{itemize}

But it introduces:
\begin{itemize}
  \item waiting
  \item serialization
\end{itemize}

Parallel computing always balances:
\begin{quote}
\emph{Correctness vs Performance}
\end{quote}

Correctness is mandatory.  
Performance must be earned.

% --------------------------------------------------
\subsubsection*{5.5.2 What Happens When Threads Compete}
\addcontentsline{toc}{subsubsection}{5.5.2 What Happens When Threads Compete}

When multiple threads want the same lock:
\begin{itemize}
  \item one thread enters
  \item others wait
\end{itemize}

This creates:
\begin{itemize}
  \item contention
  \item idle cores
\end{itemize}

In the worst case:
\begin{quote}
\emph{Parallel code behaves sequentially.}
\end{quote}

This is called \textbf{lock contention}.

% --------------------------------------------------
\subsubsection*{5.5.3 Fine-Grained vs Coarse-Grained Locking}
\addcontentsline{toc}{subsubsection}{5.5.3 Fine-Grained vs Coarse-Grained Locking}

\textbf{Coarse-grained locking}:
\begin{itemize}
  \item one big lock
  \item easy correctness
  \item poor scalability
\end{itemize}

\textbf{Fine-grained locking}:
\begin{itemize}
  \item many small locks
  \item better parallelism
  \item harder reasoning
\end{itemize}

Design choice:
\begin{quote}
\emph{Start coarse, refine only if needed.}
\end{quote}

Premature complexity is dangerous.

% --------------------------------------------------
\subsubsection*{5.5.4 The Counter Example Revisited}
\addcontentsline{toc}{subsubsection}{5.5.4 The Counter Example Revisited}

Recall:
\begin{lstlisting}[language=C++]
for (int i = 0; i < N; i++) {
    std::lock_guard<std::mutex> g(m);
    counter++;
}
\end{lstlisting}

This is correct.

But:
\begin{itemize}
  \item every increment locks
  \item threads constantly wait
\end{itemize}

Speedup is minimal or negative.

Correct but slow.

% --------------------------------------------------
\subsubsection*{5.5.5 Reduce Lock Frequency}
\addcontentsline{toc}{subsubsection}{5.5.5 Reduce Lock Frequency}

Better approach:
\begin{itemize}
  \item each thread uses a local counter
  \item combine results once
\end{itemize}

Conceptually:
\begin{lstlisting}[language=C++]
local_sum++;
// later
global_sum += local_sum;
\end{lstlisting}

This:
\begin{itemize}
  \item reduces contention
  \item increases parallel work
\end{itemize}

This idea leads directly to:
\begin{itemize}
  \item reductions
  \item OpenMP constructs
\end{itemize}

% --------------------------------------------------
\subsubsection*{5.5.6 Amdahl’s Law (Intuition Only)}
\addcontentsline{toc}{subsubsection}{5.5.6 Amdahl’s Law (Intuition Only)}

If a fraction of a program is:
\begin{itemize}
  \item inherently serial
\end{itemize}

Then speedup is limited.

Even infinite cores cannot help.

Locks increase the serial fraction.

This law explains why:
\begin{itemize}
  \item perfect scaling is rare
\end{itemize}

We will formalize this later.

% --------------------------------------------------
\subsubsection*{5.5.7 The Right Mental Model}
\addcontentsline{toc}{subsubsection}{5.5.7 The Right Mental Model}

Correct thinking:
\begin{quote}
\emph{Do as much work as possible without locks.}
\end{quote}

Locks should:
\begin{itemize}
  \item protect brief updates
  \item not surround computation
\end{itemize}

Design for parallelism first.
Add synchronization last.

% --------------------------------------------------
\subsection*{Practice on Mac Terminal (Mandatory)}
\addcontentsline{toc}{subsection}{Practice on Mac Terminal (Lesson 5.5)}

\subsubsection*{Practice 1: Measure Lock Cost}

Modify your counter program to:
\begin{itemize}
  \item lock inside the loop
  \item then lock once per thread
\end{itemize}

Use:
\begin{lstlisting}[language=bash]
time ./race
\end{lstlisting}

Compare timings.

Observe:
\begin{itemize}
  \item dramatic performance difference
\end{itemize}

% --------------------------------------------------
\subsubsection*{Practice 2: Reason Without Code}

Ask:
\begin{itemize}
  \item What fraction of this program is serial?
  \item Where is contention happening?
\end{itemize}

This reasoning skill matters more than micro-optimizations.

% --------------------------------------------------
\subsection*{Checkpoint Questions}
\addcontentsline{toc}{subsection}{Checkpoint Questions (Lesson 5.5)}

Answer carefully:

\begin{enumerate}
  \item Why do locks reduce parallel speedup?
  \item What is lock contention?
  \item Why are local variables faster than shared ones?
\end{enumerate}
% ==================================================
\section*{PART 6: OpenMP -- Compiler-Assisted Parallelism}
\addcontentsline{toc}{section}{PART 6: OpenMP -- Compiler-Assisted Parallelism}

\subsection*{Lesson 6.1: Why OpenMP Exists}
\addcontentsline{toc}{subsection}{Lesson 6.1: Why OpenMP Exists}

% --------------------------------------------------
\subsubsection*{6.1.1 The Pain of Manual Threads}
\addcontentsline{toc}{subsubsection}{6.1.1 The Pain of Manual Threads}

From PART 5, you learned that threads require:
\begin{itemize}
  \item explicit creation
  \item explicit joining
  \item explicit locking
  \item careful deadlock avoidance
\end{itemize}

This gives:
\begin{itemize}
  \item full control
  \item maximum pain
\end{itemize}

For many scientific programs, this level of control is unnecessary.

% --------------------------------------------------
\subsubsection*{6.1.2 The Key Observation Behind OpenMP}
\addcontentsline{toc}{subsubsection}{6.1.2 The Key Observation Behind OpenMP}

Most parallel code looks like:
\begin{itemize}
  \item independent loops
  \item reductions
  \item simple task regions
\end{itemize}

So researchers asked:
\begin{quote}
\emph{``Why make programmers manage threads if the structure is obvious?''}
\end{quote}

OpenMP was born from this question.

% --------------------------------------------------
\subsubsection*{6.1.3 What OpenMP Really Is}
\addcontentsline{toc}{subsubsection}{6.1.3 What OpenMP Really Is}

OpenMP is:
\begin{itemize}
  \item a set of compiler directives
  \item a runtime library
  \item a programming model
\end{itemize}

Key idea:
\begin{quote}
\emph{You describe parallel intent. The compiler and runtime handle execution.}
\end{quote}

You do not create threads explicitly.
OpenMP does it for you.

% --------------------------------------------------
\subsubsection*{6.1.4 Directives, Not Magic}
\addcontentsline{toc}{subsubsection}{6.1.4 Directives, Not Magic}

OpenMP uses pragmas:
\begin{lstlisting}[language=C++]
#pragma omp parallel for
\end{lstlisting}

Properties:
\begin{itemize}
  \item ignored by non-OpenMP compilers
  \item do not change sequential semantics
\end{itemize}

This means:
\begin{itemize}
  \item same code can run sequentially
  \item parallelism is an annotation
\end{itemize}

This is extremely powerful for teaching and research.

% --------------------------------------------------
\subsubsection*{6.1.5 Fork–Join Model}
\addcontentsline{toc}{subsubsection}{6.1.5 Fork--Join Model}

OpenMP follows the \textbf{fork–join} model.

\begin{itemize}
  \item one master thread starts
  \item parallel region begins (fork)
  \item threads execute work
  \item threads synchronize (join)
\end{itemize}

Outside parallel regions:
\begin{itemize}
  \item execution is sequential
\end{itemize}

This matches how humans think about programs.

% --------------------------------------------------
\subsubsection*{6.1.6 Why OpenMP Is Perfect for Students}
\addcontentsline{toc}{subsubsection}{6.1.6 Why OpenMP Is Perfect for Students}

OpenMP:
\begin{itemize}
  \item minimizes boilerplate
  \item reduces synchronization errors
  \item highlights algorithmic structure
\end{itemize}

Students focus on:
\begin{itemize}
  \item which loops are parallel
  \item which variables are shared
\end{itemize}

Not:
\begin{itemize}
  \item thread APIs
  \item mutex misuse
\end{itemize}

This is pedagogically ideal.

% --------------------------------------------------
\subsubsection*{6.1.7 When NOT to Use OpenMP}
\addcontentsline{toc}{subsubsection}{6.1.7 When NOT to Use OpenMP}

OpenMP is not ideal when:
\begin{itemize}
  \item fine-grained synchronization is required
  \item irregular communication dominates
  \item distributed memory is involved
\end{itemize}

In those cases:
\begin{itemize}
  \item threads
  \item MPI
\end{itemize}
are more appropriate.

Tool choice matters.

% --------------------------------------------------
\subsection*{Practice on Mac Terminal (Mandatory)}
\addcontentsline{toc}{subsection}{Practice on Mac Terminal (Lesson 6.1)}

\subsubsection*{Practice 1: Check OpenMP Support}

On macOS (Apple Silicon), check compiler:
\begin{lstlisting}[language=bash]
clang --version
\end{lstlisting}

Note:
\begin{itemize}
  \item Apple clang may not support OpenMP by default
\end{itemize}

You may need:
\begin{itemize}
  \item Homebrew LLVM
\end{itemize}

Do not install yet.
We will handle setup cleanly next lesson.

% --------------------------------------------------
\subsubsection*{Practice 2: Mental Translation}

Take this loop:
\begin{lstlisting}[language=C++]
for (int i = 0; i < N; i++) {
    a[i] = b[i] + c[i];
}
\end{lstlisting}

Answer:
\begin{itemize}
  \item Why is the structure obvious?
  \item Why shouldn’t students manage threads manually here?
\end{itemize}

This reasoning is the essence of OpenMP.

% --------------------------------------------------
\subsection*{Checkpoint Questions}
\addcontentsline{toc}{subsection}{Checkpoint Questions (Lesson 6.1)}

Answer clearly:

\begin{enumerate}
  \item What problem does OpenMP solve?
  \item What does “describe intent” mean?
  \item Why is OpenMP good for teaching?
\end{enumerate}
% ==================================================
\subsection*{Lesson 6.2: Your First OpenMP Program}
\addcontentsline{toc}{subsection}{Lesson 6.2: Your First OpenMP Program}

% --------------------------------------------------
\subsubsection*{6.2.1 The OpenMP Programming Model (One Minute Recap)}
\addcontentsline{toc}{subsubsection}{6.2.1 The OpenMP Programming Model}

OpenMP works by:
\begin{itemize}
  \item starting with one master thread
  \item entering a parallel region
  \item creating a team of threads
  \item dividing work among them
\end{itemize}

You do \textbf{not} manage threads.
You annotate regions of code.

This is deliberate.

% --------------------------------------------------
\subsubsection*{6.2.2 OpenMP on macOS (Apple Silicon Reality)}
\addcontentsline{toc}{subsubsection}{6.2.2 OpenMP on macOS (Apple Silicon Reality)}

Important truth:
\begin{quote}
\emph{Apple's default clang does NOT support OpenMP out of the box.}
\end{quote}

Solution:
\begin{itemize}
  \item install LLVM via Homebrew
\end{itemize}

Run in terminal:
\begin{lstlisting}[language=bash]
brew install llvm
\end{lstlisting}

After installation, use:
\begin{lstlisting}[language=bash]
/opt/homebrew/opt/llvm/bin/clang++
\end{lstlisting}

This compiler supports OpenMP.

This is standard practice on macOS.

% --------------------------------------------------
\subsubsection*{6.2.3 Verifying OpenMP Support}
\addcontentsline{toc}{subsubsection}{6.2.3 Verifying OpenMP Support}

Check:
\begin{lstlisting}[language=bash]
/opt/homebrew/opt/llvm/bin/clang++ --version
\end{lstlisting}

Now test OpenMP flag:
\begin{lstlisting}[language=bash]
/opt/homebrew/opt/llvm/bin/clang++ -fopenmp --help
\end{lstlisting}

If no error appears, OpenMP is enabled.

% --------------------------------------------------
\subsubsection*{6.2.4 Your First Parallel Region}
\addcontentsline{toc}{subsubsection}{6.2.4 Your First Parallel Region}

Create file:
\begin{lstlisting}[language=bash]
nano omp_hello.cpp
\end{lstlisting}

Write:
\begin{lstlisting}[language=C++]
#include <iostream>
#include <omp.h>
using namespace std;

int main() {
#pragma omp parallel
    {
        cout << "Hello from thread "
             << omp_get_thread_num()
             << endl;
    }
    return 0;
}
\end{lstlisting}

Compile:
\begin{lstlisting}[language=bash]
/opt/homebrew/opt/llvm/bin/clang++ -fopenmp omp_hello.cpp -o omp_hello
\end{lstlisting}

Run:
\begin{lstlisting}[language=bash]
./omp_hello
\end{lstlisting}

Observe:
\begin{itemize}
  \item multiple lines printed
  \item order is unpredictable
\end{itemize}

This is real parallel execution.

% --------------------------------------------------
\subsubsection*{6.2.5 Understanding What Just Happened}
\addcontentsline{toc}{subsubsection}{6.2.5 Understanding What Just Happened}

Key points:
\begin{itemize}
  \item OpenMP created threads automatically
  \item each thread executed the block
  \item threads share memory
\end{itemize}

This is equivalent to:
\begin{itemize}
  \item creating threads manually
  \item joining them
\end{itemize}

But with far less code and fewer bugs.

% --------------------------------------------------
\subsubsection*{6.2.6 The Most Important OpenMP Construct: parallel for}
\addcontentsline{toc}{subsubsection}{6.2.6 The Most Important OpenMP Construct}

Most OpenMP programs use:
\begin{lstlisting}[language=C++]
#pragma omp parallel for
\end{lstlisting}

This:
\begin{itemize}
  \item parallelizes loop iterations
  \item distributes iterations across threads
\end{itemize}

OpenMP checks:
\begin{itemize}
  \item loop structure
  \item iteration independence
\end{itemize}

If unsafe, behavior is undefined.
Parallel reasoning still matters.

% --------------------------------------------------
\subsubsection*{6.2.7 Your First Data-Parallel Loop}
\addcontentsline{toc}{subsubsection}{6.2.7 Your First Data-Parallel Loop}

Create:
\begin{lstlisting}[language=bash]
nano omp_loop.cpp
\end{lstlisting}

Write:
\begin{lstlisting}[language=C++]
#include <iostream>
#include <vector>
#include <omp.h>
using namespace std;

int main() {
    int N = 20;
    vector<int> a(N);

#pragma omp parallel for
    for (int i = 0; i < N; i++) {
        a[i] = i * i;
        cout << "Thread "
             << omp_get_thread_num()
             << " computed a[" << i << "]"
             << endl;
    }

    return 0;
}
\end{lstlisting}

Compile:
\begin{lstlisting}[language=bash]
/opt/homebrew/opt/llvm/bin/clang++ -fopenmp omp_loop.cpp -o omp_loop
\end{lstlisting}

Run:
\begin{lstlisting}[language=bash]
./omp_loop
\end{lstlisting}

Observe:
\begin{itemize}
  \item different iterations run on different threads
  \item output order is jumbled
\end{itemize}

This is correct parallel behavior.

% --------------------------------------------------
\subsubsection*{6.2.8 How Many Threads Are Used?}
\addcontentsline{toc}{subsubsection}{6.2.8 How Many Threads Are Used?}

Check:
\begin{lstlisting}[language=bash]
export OMP_NUM_THREADS=4
./omp_loop
\end{lstlisting}

You can control:
\begin{itemize}
  \item number of threads
  \item experiment with scaling
\end{itemize}

OpenMP adapts to hardware automatically.

% --------------------------------------------------
\subsection*{Practice on Mac Terminal (Mandatory)}
\addcontentsline{toc}{subsection}{Practice on Mac Terminal (Lesson 6.2)}

\subsubsection*{Practice 1: Sequential vs OpenMP}

Remove the pragma and recompile.

Compare:
\begin{itemize}
  \item output order
  \item execution time (for large N)
\end{itemize}

Feel the difference.

% --------------------------------------------------
\subsubsection*{Practice 2: Reason About Safety}

Ask:
\begin{itemize}
  \item Why is \texttt{a[i] = i*i} safe?
  \item What would break if all threads wrote to \texttt{a[0]}?
\end{itemize}

This reasoning never goes away.

% --------------------------------------------------
\subsection*{Checkpoint Questions}
\addcontentsline{toc}{subsection}{Checkpoint Questions (Lesson 6.2)}

Answer clearly:

\begin{enumerate}
  \item What does \texttt{\#pragma omp parallel} do?
  \item What does \texttt{parallel for} assume about the loop?
  \item Why is output order unpredictable?
\end{enumerate}
% ==================================================
\subsection*{Lesson 6.3: Shared vs Private Variables}
\addcontentsline{toc}{subsection}{Lesson 6.3: Shared vs Private Variables}

% --------------------------------------------------
\subsubsection*{6.3.1 The Default Rule (Dangerous If Ignored)}
\addcontentsline{toc}{subsubsection}{6.3.1 The Default Rule (Dangerous If Ignored)}

In OpenMP:
\begin{itemize}
  \item variables declared \textbf{outside} a parallel region are \textbf{shared}
  \item variables declared \textbf{inside} a parallel region are \textbf{private}
\end{itemize}

This default rule is simple — and extremely dangerous if forgotten.

Shared variables can cause race conditions.

% --------------------------------------------------
\subsubsection*{6.3.2 What Does ``Shared'' Mean?}
\addcontentsline{toc}{subsubsection}{6.3.2 What Does ``Shared'' Mean?}

A \textbf{shared} variable:
\begin{itemize}
  \item has one memory location
  \item is visible to all threads
\end{itemize}

Example:
\begin{lstlisting}[language=C++]
int sum = 0;

#pragma omp parallel for
for (int i = 0; i < N; i++) {
    sum += a[i];
}
\end{lstlisting}

Here:
\begin{itemize}
  \item all threads update the same \texttt{sum}
  \item race condition occurs
\end{itemize}

This bug compiles cleanly.
It fails logically.

% --------------------------------------------------
\subsubsection*{6.3.3 What Does ``Private'' Mean?}
\addcontentsline{toc}{subsubsection}{6.3.3 What Does ``Private'' Mean?}

A \textbf{private} variable:
\begin{itemize}
  \item has a separate copy per thread
  \item is uninitialized unless specified
\end{itemize}

Example:
\begin{lstlisting}[language=C++]
#pragma omp parallel private(x)
{
    x = omp_get_thread_num();
}
\end{lstlisting}

Each thread gets:
\begin{itemize}
  \item its own \texttt{x}
\end{itemize}

No sharing.
No race.

% --------------------------------------------------
\subsubsection*{6.3.4 firstprivate: Copy the Initial Value}
\addcontentsline{toc}{subsubsection}{6.3.4 firstprivate: Copy the Initial Value}

Sometimes threads need:
\begin{itemize}
  \item a private copy
  \item initialized from a shared value
\end{itemize}

Use:
\begin{lstlisting}[language=C++]
#pragma omp parallel firstprivate(x)
\end{lstlisting}

This means:
\begin{itemize}
  \item each thread gets its own copy
  \item initialized to \texttt{x}'s value before the region
\end{itemize}

This avoids subtle initialization bugs.

% --------------------------------------------------
\subsubsection*{6.3.5 The Loop Index Rule}
\addcontentsline{toc}{subsubsection}{6.3.5 The Loop Index Rule}

In:
\begin{lstlisting}[language=C++]
#pragma omp parallel for
for (int i = 0; i < N; i++) {
    ...
}
\end{lstlisting}

The loop variable \texttt{i} is:
\begin{itemize}
  \item automatically \textbf{private}
\end{itemize}

This is intentional.

If \texttt{i} were shared:
\begin{itemize}
  \item chaos would result
\end{itemize}

Never manually share loop indices.

% --------------------------------------------------
\subsubsection*{6.3.6 default(none): The Professional Setting}
\addcontentsline{toc}{subsubsection}{6.3.6 default(none): The Professional Setting}

Best practice:
\begin{lstlisting}[language=C++]
#pragma omp parallel default(none) shared(a, N) private(i)
\end{lstlisting}

This forces you to:
\begin{itemize}
  \item explicitly declare variable scope
\end{itemize}

Advantages:
\begin{itemize}
  \item prevents accidental sharing
  \item improves readability
  \item catches bugs at compile time
\end{itemize}

This is what experts use.

% --------------------------------------------------
\subsubsection*{6.3.7 A Subtle but Common Bug}
\addcontentsline{toc}{subsubsection}{6.3.7 A Subtle but Common Bug}

Consider:
\begin{lstlisting}[language=C++]
int temp;

#pragma omp parallel for
for (int i = 0; i < N; i++) {
    temp = a[i] * 2;
    b[i] = temp;
}
\end{lstlisting}

Bug:
\begin{itemize}
  \item \texttt{temp} is shared
\end{itemize}

Fix:
\begin{lstlisting}[language=C++]
#pragma omp parallel for private(temp)
\end{lstlisting}

This single keyword fixes correctness.

% --------------------------------------------------
\subsection*{Practice on Mac Terminal (Mandatory)}
\addcontentsline{toc}{subsection}{Practice on Mac Terminal (Lesson 6.3)}

\subsubsection*{Practice 1: Create the Bug}

Write code with:
\begin{itemize}
  \item shared temporary variable
\end{itemize}

Run multiple times.

Observe:
\begin{itemize}
  \item incorrect results
  \item inconsistent behavior
\end{itemize}

% --------------------------------------------------
\subsubsection*{Practice 2: Fix with private}

Add:
\begin{lstlisting}[language=C++]
private(temp)
\end{lstlisting}

Recompile and rerun.

Observe:
\begin{itemize}
  \item correctness restored
\end{itemize}

This pattern repeats everywhere.

% --------------------------------------------------
\subsection*{Checkpoint Questions}
\addcontentsline{toc}{subsection}{Checkpoint Questions (Lesson 6.3)}

Answer carefully:

\begin{enumerate}
  \item What is the default OpenMP sharing rule?
  \item Why is a shared temporary variable dangerous?
  \item Why is \texttt{default(none)} a good idea?
\end{enumerate}
% ==================================================
\subsection*{Lesson 6.4: Reductions -- Parallel Sums Done Right}
\addcontentsline{toc}{subsection}{Lesson 6.4: Reductions -- Parallel Sums Done Right}

% --------------------------------------------------
\subsubsection*{6.4.1 The Classic Wrong Parallel Sum}
\addcontentsline{toc}{subsubsection}{6.4.1 The Classic Wrong Parallel Sum}

Consider:
\begin{lstlisting}[language=C++]
int sum = 0;

#pragma omp parallel for
for (int i = 0; i < N; i++) {
    sum += a[i];
}
\end{lstlisting}

This is:
\begin{itemize}
  \item logically correct
  \item mathematically correct
  \item \textbf{parallelly wrong}
\end{itemize}

Reason:
\begin{itemize}
  \item \texttt{sum} is shared
  \item multiple threads write to it
\end{itemize}

This creates a race condition.

% --------------------------------------------------
\subsubsection*{6.4.2 Why Locks Are the Wrong Fix}
\addcontentsline{toc}{subsubsection}{6.4.2 Why Locks Are the Wrong Fix}

You might try:
\begin{lstlisting}[language=C++]
#pragma omp parallel for
for (int i = 0; i < N; i++) {
#pragma omp critical
    sum += a[i];
}
\end{lstlisting}

This is:
\begin{itemize}
  \item correct
  \item extremely slow
\end{itemize}

Why?
\begin{itemize}
  \item every iteration serializes
  \item parallelism collapses
\end{itemize}

Correctness without performance is failure.

% --------------------------------------------------
\subsubsection*{6.4.3 The Key Insight Behind Reductions}
\addcontentsline{toc}{subsubsection}{6.4.3 The Key Insight Behind Reductions}

Key observation:
\begin{quote}
\emph{Addition is associative and commutative.}
\end{quote}

This allows:
\begin{itemize}
  \item partial sums
  \item arbitrary combination order
\end{itemize}

Parallel strategy:
\begin{enumerate}
  \item each thread computes a local sum
  \item local sums are combined safely
\end{enumerate}

This avoids shared writes during computation.

% --------------------------------------------------
\subsubsection*{6.4.4 The OpenMP reduction Clause}
\addcontentsline{toc}{subsubsection}{6.4.4 The OpenMP reduction Clause}

OpenMP provides:
\begin{lstlisting}[language=C++]
#pragma omp parallel for reduction(+:sum)
\end{lstlisting}

Meaning:
\begin{itemize}
  \item each thread gets a private \texttt{sum}
  \item initialized to zero
  \item OpenMP combines them at the end
\end{itemize}

You write:
\begin{lstlisting}[language=C++]
int sum = 0;

#pragma omp parallel for reduction(+:sum)
for (int i = 0; i < N; i++) {
    sum += a[i];
}
\end{lstlisting}

This is:
\begin{itemize}
  \item correct
  \item fast
  \item elegant
\end{itemize}

% --------------------------------------------------
\subsubsection*{6.4.5 Other Reduction Operators}
\addcontentsline{toc}{subsubsection}{6.4.5 Other Reduction Operators}

OpenMP supports reductions on:
\begin{itemize}
  \item \texttt{+} (sum)
  \item \texttt{*} (product)
  \item \texttt{max}, \texttt{min}
  \item \texttt{\&\&}, \texttt{||}
\end{itemize}

Example:
\begin{lstlisting}[language=C++]
#pragma omp parallel for reduction(max:maxval)
\end{lstlisting}

Rule:
\begin{quote}
\emph{The operation must be associative.}
\end{quote}

Floating-point reductions may differ slightly due to ordering.

This is expected.

% --------------------------------------------------
\subsubsection*{6.4.6 Reduction vs Atomic vs Critical}
\addcontentsline{toc}{subsubsection}{6.4.6 Reduction vs Atomic vs Critical}

Three ways to fix \texttt{sum +=}:

\begin{center}
\begin{tabular}{|c|c|c|}
\hline
Method & Correct & Fast \\
\hline
critical & Yes & No \\
atomic & Yes & Medium \\
reduction & Yes & Yes \\
\hline
\end{tabular}
\end{center}

Rule of thumb:
\begin{quote}
\emph{Use reduction whenever possible.}
\end{quote}

It expresses intent clearly and lets OpenMP optimize.

% --------------------------------------------------
\subsubsection*{6.4.7 Reduction Is a Pattern, Not a Trick}
\addcontentsline{toc}{subsubsection}{6.4.7 Reduction Is a Pattern, Not a Trick}

Reduction is not just syntax.

It reflects:
\begin{itemize}
  \item independent work
  \item delayed combination
\end{itemize}

This pattern appears in:
\begin{itemize}
  \item sums
  \item norms
  \item integrals
  \item statistics
\end{itemize}

Recognizing reductions is a core parallel skill.

% --------------------------------------------------
\subsection*{Practice on Mac Terminal (Mandatory)}
\addcontentsline{toc}{subsection}{Practice on Mac Terminal (Lesson 6.4)}

\subsubsection*{Practice 1: Correct Parallel Sum}

Create:
\begin{lstlisting}[language=bash]
nano omp_sum.cpp
\end{lstlisting}

Write:
\begin{lstlisting}[language=C++]
#include <iostream>
#include <vector>
#include <omp.h>
using namespace std;

int main() {
    int N = 1000000;
    vector<int> a(N, 1);
    int sum = 0;

#pragma omp parallel for reduction(+:sum)
    for (int i = 0; i < N; i++) {
        sum += a[i];
    }

    cout << "Sum = " << sum << endl;
    return 0;
}
\end{lstlisting}

Compile and run:
\begin{lstlisting}[language=bash]
/opt/homebrew/opt/llvm/bin/clang++ -fopenmp omp_sum.cpp -o omp_sum
./omp_sum
\end{lstlisting}

Verify:
\begin{itemize}
  \item correct result
  \item consistent across runs
\end{itemize}

% --------------------------------------------------
\subsubsection*{Practice 2: Compare with Critical}

Replace reduction with:
\begin{lstlisting}[language=C++]
#pragma omp critical
\end{lstlisting}

Time both versions.

Observe:
\begin{itemize}
  \item large performance gap
\end{itemize}

This demonstrates why reductions matter.

% --------------------------------------------------
\subsection*{Checkpoint Questions}
\addcontentsline{toc}{subsection}{Checkpoint Questions (Lesson 6.4)}

Answer carefully:

\begin{enumerate}
  \item Why is \texttt{sum += a[i]} unsafe in parallel?
  \item Why are reductions faster than locks?
  \item Why can floating-point reductions vary slightly?
\end{enumerate}
% ==================================================
\subsection*{Lesson 6.5: Scheduling -- Static vs Dynamic vs Guided}
\addcontentsline{toc}{subsection}{Lesson 6.5: Scheduling -- Static vs Dynamic vs Guided}

% --------------------------------------------------
\subsubsection*{6.5.1 The Hidden Enemy: Load Imbalance}
\addcontentsline{toc}{subsubsection}{6.5.1 The Hidden Enemy: Load Imbalance}

Parallel programs often assume:
\begin{quote}
\emph{``All iterations cost the same.''}
\end{quote}

Reality:
\begin{itemize}
  \item some iterations are expensive
  \item some are cheap
\end{itemize}

If work is uneven:
\begin{itemize}
  \item some threads finish early
  \item others keep working
\end{itemize}

Idle threads mean wasted cores.

This problem is called \textbf{load imbalance}.

% --------------------------------------------------
\subsubsection*{6.5.2 What Scheduling Means in OpenMP}
\addcontentsline{toc}{subsubsection}{6.5.2 What Scheduling Means in OpenMP}

Scheduling answers one question:
\begin{quote}
\emph{How are loop iterations assigned to threads?}
\end{quote}

OpenMP lets you control this using:
\begin{lstlisting}[language=C++]
schedule(type, chunk_size)
\end{lstlisting}

Different schedules trade:
\begin{itemize}
  \item overhead
  \item balance
\end{itemize}

There is no single best choice.

% --------------------------------------------------
\subsubsection*{6.5.3 Static Scheduling}
\addcontentsline{toc}{subsubsection}{6.5.3 Static Scheduling}

Static scheduling:
\begin{itemize}
  \item iterations divided upfront
  \item each thread gets a fixed block
\end{itemize}

Syntax:
\begin{lstlisting}[language=C++]
#pragma omp parallel for schedule(static)
\end{lstlisting}

Properties:
\begin{itemize}
  \item very low overhead
  \item excellent cache locality
\end{itemize}

Best when:
\begin{itemize}
  \item all iterations take similar time
\end{itemize}

This is the default.

% --------------------------------------------------
\subsubsection*{6.5.4 Static with Chunk Size}
\addcontentsline{toc}{subsubsection}{6.5.4 Static with Chunk Size}

You can control block size:
\begin{lstlisting}[language=C++]
schedule(static, chunk)
\end{lstlisting}

Meaning:
\begin{itemize}
  \item each thread gets chunks of given size
\end{itemize}

Smaller chunks:
\begin{itemize}
  \item better balance
  \item slightly higher overhead
\end{itemize}

Larger chunks:
\begin{itemize}
  \item better locality
  \item risk imbalance
\end{itemize}

% --------------------------------------------------
\subsubsection*{6.5.5 Dynamic Scheduling}
\addcontentsline{toc}{subsubsection}{6.5.5 Dynamic Scheduling}

Dynamic scheduling:
\begin{itemize}
  \item threads request work as they finish
  \item iterations assigned at runtime
\end{itemize}

Syntax:
\begin{lstlisting}[language=C++]
#pragma omp parallel for schedule(dynamic)
\end{lstlisting}

Properties:
\begin{itemize}
  \item good load balance
  \item higher runtime overhead
\end{itemize}

Best when:
\begin{itemize}
  \item iteration cost is unpredictable
\end{itemize}

% --------------------------------------------------
\subsubsection*{6.5.6 Guided Scheduling}
\addcontentsline{toc}{subsubsection}{6.5.6 Guided Scheduling}

Guided scheduling:
\begin{itemize}
  \item starts with large chunks
  \item chunk size decreases over time
\end{itemize}

Syntax:
\begin{lstlisting}[language=C++]
#pragma omp parallel for schedule(guided)
\end{lstlisting}

Goal:
\begin{itemize}
  \item reduce overhead early
  \item improve balance later
\end{itemize}

Good compromise for many real workloads.

% --------------------------------------------------
\subsubsection*{6.5.7 Choosing the Right Schedule}
\addcontentsline{toc}{subsubsection}{6.5.7 Choosing the Right Schedule}

Rule of thumb:

\begin{itemize}
  \item uniform work $\rightarrow$ static
  \item irregular work $\rightarrow$ dynamic
  \item unknown $\rightarrow$ guided
\end{itemize}

Always:
\begin{itemize}
  \item measure performance
\end{itemize}

Guessing is unreliable.

% --------------------------------------------------
\subsection*{Practice on Mac Terminal (Mandatory)}
\addcontentsline{toc}{subsection}{Practice on Mac Terminal (Lesson 6.5)}

\subsubsection*{Practice 1: Artificial Load Imbalance}

Create:
\begin{lstlisting}[language=bash]
nano omp_schedule.cpp
\end{lstlisting}

Write:
\begin{lstlisting}[language=C++]
#include <iostream>
#include <omp.h>
using namespace std;

int main() {
#pragma omp parallel for schedule(static)
    for (int i = 0; i < 16; i++) {
        if (i % 4 == 0) {
            for (volatile int j = 0; j < 100000000; j++) {}
        }
        cout << "Thread " << omp_get_thread_num()
             << " finished iteration " << i << endl;
    }
    return 0;
}
\end{lstlisting}

Compile and run:
\begin{lstlisting}[language=bash]
/opt/homebrew/opt/llvm/bin/clang++ -fopenmp omp_schedule.cpp -o omp_schedule
./omp_schedule
\end{lstlisting}

Observe:
\begin{itemize}
  \item some threads finish much later
\end{itemize}

% --------------------------------------------------
\subsubsection*{Practice 2: Switch to Dynamic}

Change:
\begin{lstlisting}[language=C++]
schedule(static)
\end{lstlisting}

to:
\begin{lstlisting}[language=C++]
schedule(dynamic,1)
\end{lstlisting}

Recompile and run.

Observe:
\begin{itemize}
  \item better load balance
  \item more even completion
\end{itemize}

% --------------------------------------------------
\subsection*{Checkpoint Questions}
\addcontentsline{toc}{subsection}{Checkpoint Questions (Lesson 6.5)}

Answer carefully:

\begin{enumerate}
  \item What is load imbalance?
  \item Why is static scheduling fast but risky?
  \item When should dynamic scheduling be used?
\end{enumerate}
% ==================================================
\subsection*{Lesson 6.6: OpenMP Tasks -- Irregular Parallelism Done Right}
\addcontentsline{toc}{subsection}{Lesson 6.6: OpenMP Tasks -- Irregular Parallelism Done Right}

% --------------------------------------------------
\subsubsection*{6.6.1 Why Loops Are Not Enough}
\addcontentsline{toc}{subsubsection}{6.6.1 Why Loops Are Not Enough}

Loop parallelism assumes:
\begin{itemize}
  \item fixed iteration space
  \item predictable structure
\end{itemize}

But many real algorithms are:
\begin{itemize}
  \item recursive
  \item data-dependent
  \item irregular
\end{itemize}

Examples:
\begin{itemize}
  \item divide-and-conquer algorithms
  \item tree traversals
  \item adaptive mesh refinement
\end{itemize}

These require \textbf{task parallelism}.

% --------------------------------------------------
\subsubsection*{6.6.2 What Is an OpenMP Task?}
\addcontentsline{toc}{subsubsection}{6.6.2 What Is an OpenMP Task?}

An OpenMP task is:
\begin{quote}
\emph{A unit of work created dynamically and scheduled by the runtime.}
\end{quote}

Key idea:
\begin{itemize}
  \item tasks describe work
  \item threads execute tasks
\end{itemize}

Tasks are not tied to loop indices.

This makes them extremely flexible.

% --------------------------------------------------
\subsubsection*{6.6.3 The Basic Task Syntax}
\addcontentsline{toc}{subsubsection}{6.6.3 The Basic Task Syntax}

Canonical pattern:
\begin{lstlisting}[language=C++]
#pragma omp task
{
    // work
}
\end{lstlisting}

Important rule:
\begin{quote}
\emph{Tasks must be created inside a parallel region.}
\end{quote}

Otherwise, only one thread exists and no parallelism occurs.

% --------------------------------------------------
\subsubsection*{6.6.4 Single + Tasks: The Standard Pattern}
\addcontentsline{toc}{subsubsection}{6.6.4 Single + Tasks: The Standard Pattern}

The correct structure is:
\begin{lstlisting}[language=C++]
#pragma omp parallel
{
#pragma omp single
    {
        // create tasks here
    }
}
\end{lstlisting}

Meaning:
\begin{itemize}
  \item one thread creates tasks
  \item all threads execute tasks
\end{itemize}

This avoids duplicate task creation.

This pattern appears everywhere.

% --------------------------------------------------
\subsubsection*{6.6.5 A Simple Task Example}
\addcontentsline{toc}{subsubsection}{6.6.5 A Simple Task Example}

Example:
\begin{lstlisting}[language=C++]
#pragma omp parallel
{
#pragma omp single
    {
#pragma omp task
        cout << "Task A" << endl;

#pragma omp task
        cout << "Task B" << endl;
    }
}
\end{lstlisting}

Properties:
\begin{itemize}
  \item order is not guaranteed
  \item tasks may run on any thread
\end{itemize}

This is expected and correct.

% --------------------------------------------------
\subsubsection*{6.6.6 Task Synchronization: taskwait}
\addcontentsline{toc}{subsubsection}{6.6.6 Task Synchronization: taskwait}

Sometimes tasks must finish before continuing.

Use:
\begin{lstlisting}[language=C++]
#pragma omp taskwait
\end{lstlisting}

This means:
\begin{itemize}
  \item wait until all child tasks complete
\end{itemize}

Without this:
\begin{itemize}
  \item parent may continue too early
\end{itemize}

This is a \textbf{local synchronization point}.

% --------------------------------------------------
\subsubsection*{6.6.7 Recursive Parallelism with Tasks}
\addcontentsline{toc}{subsubsection}{6.6.7 Recursive Parallelism with Tasks}

Classic example: recursive Fibonacci (for learning only).

\begin{lstlisting}[language=C++]
int fib(int n) {
    if (n < 2) return n;

    int x, y;

#pragma omp task shared(x)
    x = fib(n-1);

#pragma omp task shared(y)
    y = fib(n-2);

#pragma omp taskwait
    return x + y;
}
\end{lstlisting}

This demonstrates:
\begin{itemize}
  \item dynamic task creation
  \item task dependencies
\end{itemize}

Note:
\begin{itemize}
  \item this is not performance-optimal
  \item it is pedagogically powerful
\end{itemize}

% --------------------------------------------------
\subsubsection*{6.6.8 Task Granularity Matters}
\addcontentsline{toc}{subsubsection}{6.6.8 Task Granularity Matters}

Tasks have overhead.

Bad practice:
\begin{itemize}
  \item creating millions of tiny tasks
\end{itemize}

Good practice:
\begin{itemize}
  \item tasks should be coarse enough
  \item work per task $\gg$ task overhead
\end{itemize}

Rule of thumb:
\begin{quote}
\emph{Create tasks only when work is substantial.}
\end{quote}

This is critical for performance.

% --------------------------------------------------
\subsubsection*{6.6.9 Tasks vs parallel for}
\addcontentsline{toc}{subsubsection}{6.6.9 Tasks vs parallel for}

\begin{center}
\begin{tabular}{|c|c|c|}
\hline
Feature & parallel for & tasks \\
\hline
Structure & Regular & Irregular \\
Creation & Static & Dynamic \\
Overhead & Low & Higher \\
Flexibility & Limited & High \\
\hline
\end{tabular}
\end{center}

Rule:
\begin{quote}
\emph{Use parallel for when possible, tasks when necessary.}
\end{quote}

% --------------------------------------------------
\subsection*{Practice on Mac Terminal (Mandatory)}
\addcontentsline{toc}{subsection}{Practice on Mac Terminal (Lesson 6.6)}

\subsubsection*{Practice 1: Simple Tasks}

Create:
\begin{lstlisting}[language=bash]
nano omp_tasks.cpp
\end{lstlisting}

Write:
\begin{lstlisting}[language=C++]
#include <iostream>
#include <omp.h>
using namespace std;

int main() {
#pragma omp parallel
{
#pragma omp single
    {
#pragma omp task
        cout << "Task 1 on thread "
             << omp_get_thread_num() << endl;

#pragma omp task
        cout << "Task 2 on thread "
             << omp_get_thread_num() << endl;

#pragma omp taskwait
        cout << "All tasks finished" << endl;
    }
}
    return 0;
}
\end{lstlisting}

Compile and run:
\begin{lstlisting}[language=bash]
/opt/homebrew/opt/llvm/bin/clang++ -fopenmp omp_tasks.cpp -o omp_tasks
./omp_tasks
\end{lstlisting}

Observe:
\begin{itemize}
  \item tasks run on different threads
  \item final message prints last
\end{itemize}

% --------------------------------------------------
\subsubsection*{Practice 2: Think in Tasks}

Pick an algorithm you know:
\begin{itemize}
  \item merge sort
  \item tree traversal
  \item divide-and-conquer solver
\end{itemize}

Ask:
\begin{itemize}
  \item where can tasks be created?
  \item where must taskwait appear?
\end{itemize}

This is expert-level reasoning.

% --------------------------------------------------
\subsection*{Checkpoint Questions}
\addcontentsline{toc}{subsection}{Checkpoint Questions (Lesson 6.6)}

Answer carefully:

\begin{enumerate}
  \item Why are tasks needed beyond loops?
  \item Why must tasks be created inside a parallel region?
  \item Why does task granularity matter?
\end{enumerate}
% ==================================================
\section*{PART 7: Distributed Memory -- MPI Thinking}
\addcontentsline{toc}{section}{PART 7: Distributed Memory -- MPI Thinking}

\subsection*{Lesson 7.1: Why Threads Are Not Enough}
\addcontentsline{toc}{subsection}{Lesson 7.1: Why Threads Are Not Enough}

% --------------------------------------------------
\subsubsection*{7.1.1 The Illusion of Infinite Cores}
\addcontentsline{toc}{subsubsection}{7.1.1 The Illusion of Infinite Cores}

So far, we assumed:
\begin{itemize}
  \item one machine
  \item shared memory
  \item many cores
\end{itemize}

But real limits exist:
\begin{itemize}
  \item memory bandwidth
  \item cache coherence cost
  \item physical core count
\end{itemize}

You cannot scale threads indefinitely.

At some point:
\begin{quote}
\emph{Adding more threads makes the program slower.}
\end{quote}

This is not a software bug.
It is a hardware reality.

% --------------------------------------------------
\subsubsection*{7.1.2 The Memory Wall}
\addcontentsline{toc}{subsubsection}{7.1.2 The Memory Wall}

Modern CPUs are:
\begin{itemize}
  \item extremely fast at computation
  \item relatively slow at memory access
\end{itemize}

This gap is called:
\begin{quote}
\emph{The memory wall.}
\end{quote}

When many threads:
\begin{itemize}
  \item access shared memory
\end{itemize}

They:
\begin{itemize}
  \item compete for bandwidth
  \item invalidate caches
\end{itemize}

Performance collapses.

This limits shared-memory scaling.

% --------------------------------------------------
\subsubsection*{7.1.3 Cache Coherence Does Not Scale}
\addcontentsline{toc}{subsubsection}{7.1.3 Cache Coherence Does Not Scale}

Shared-memory machines maintain:
\begin{itemize}
  \item cache coherence
\end{itemize}

Meaning:
\begin{itemize}
  \item all cores agree on memory values
\end{itemize}

This requires:
\begin{itemize}
  \item constant communication between cores
\end{itemize}

As core count increases:
\begin{itemize}
  \item coherence traffic explodes
\end{itemize}

Eventually:
\begin{quote}
\emph{Coherence overhead dominates computation.}
\end{quote}

This is a fundamental scaling limit.

% --------------------------------------------------
\subsubsection*{7.1.4 The Only Way Forward: Distribute Memory}
\addcontentsline{toc}{subsubsection}{7.1.4 The Only Way Forward: Distribute Memory}

To scale further, systems do this:
\begin{itemize}
  \item give each processor its own memory
  \item remove hardware coherence
\end{itemize}

This creates:
\begin{quote}
\emph{Distributed memory systems.}
\end{quote}

Each processor:
\begin{itemize}
  \item owns its memory
  \item cannot directly access others' memory
\end{itemize}

Communication becomes explicit.

This is not a limitation.
It is a design choice.

% --------------------------------------------------
\subsubsection*{7.1.5 What Is a Cluster?}
\addcontentsline{toc}{subsubsection}{7.1.5 What Is a Cluster?}

A cluster is:
\begin{itemize}
  \item many independent machines (nodes)
  \item connected by a network
\end{itemize}

Each node has:
\begin{itemize}
  \item its own CPU
  \item its own memory
\end{itemize}

Nodes do NOT share memory.

They communicate by:
\begin{itemize}
  \item sending messages
\end{itemize}

This is the dominant architecture of supercomputers.

% --------------------------------------------------
\subsubsection*{7.1.6 Why Threads Cannot Work Across Machines}
\addcontentsline{toc}{subsubsection}{7.1.6 Why Threads Cannot Work Across Machines}

Threads assume:
\begin{itemize}
  \item shared address space
\end{itemize}

Across machines:
\begin{itemize}
  \item no shared memory exists
\end{itemize}

Therefore:
\begin{itemize}
  \item mutexes do not work
  \item shared variables do not exist
\end{itemize}

Trying to use threads across nodes is meaningless.

A new model is required.

% --------------------------------------------------
\subsubsection*{7.1.7 The MPI Worldview}
\addcontentsline{toc}{subsubsection}{7.1.7 The MPI Worldview}

MPI assumes:
\begin{itemize}
  \item no shared memory
  \item independent processes
\end{itemize}

Each process:
\begin{itemize}
  \item has its own memory
  \item executes its own program
\end{itemize}

All coordination happens via:
\begin{quote}
\emph{Explicit message passing.}
\end{quote}

This gives:
\begin{itemize}
  \item excellent scalability
  \item explicit control
\end{itemize}

At the cost of verbosity.

% --------------------------------------------------
\subsubsection*{7.1.8 Shared vs Distributed Memory (Big Picture)}
\addcontentsline{toc}{subsubsection}{7.1.8 Shared vs Distributed Memory (Big Picture)}

\begin{center}
\begin{tabular}{|c|c|c|}
\hline
Feature & Threads/OpenMP & MPI \\
\hline
Memory & Shared & Distributed \\
Communication & Implicit & Explicit \\
Scaling & Limited & Massive \\
Complexity & Lower & Higher \\
\hline
\end{tabular}
\end{center}

Modern HPC often uses:
\begin{quote}
\emph{Hybrid programming: MPI + OpenMP}
\end{quote}

Best of both worlds.

% --------------------------------------------------
\subsection*{Practice (Conceptual but Mandatory)}
\addcontentsline{toc}{subsection}{Practice (Lesson 7.1)}

\subsubsection*{Practice 1: Thought Experiment}

Imagine:
\begin{itemize}
  \item 1 machine with 64 cores
  \item 64 machines with 1 core each
\end{itemize}

Ask:
\begin{itemize}
  \item Which scales better?
  \item Which requires explicit communication?
\end{itemize}

This distinction motivates MPI.

% --------------------------------------------------
\subsubsection*{Practice 2: Cluster Awareness}

Search your institute resources:
\begin{itemize}
  \item Is there an HPC cluster?
  \item How many nodes?
\end{itemize}

You are preparing for real research infrastructure.

% --------------------------------------------------
\subsection*{Checkpoint Questions}
\addcontentsline{toc}{subsection}{Checkpoint Questions (Lesson 7.1)}

Answer clearly:

\begin{enumerate}
  \item What is the memory wall?
  \item Why does shared memory not scale indefinitely?
  \item Why are threads meaningless across machines?
\end{enumerate}
% ==================================================
\subsection*{Lesson 7.2: The MPI Mental Model -- Ranks, Communicators, SPMD}
\addcontentsline{toc}{subsection}{Lesson 7.2: The MPI Mental Model -- Ranks, Communicators, SPMD}

% --------------------------------------------------
\subsubsection*{7.2.1 The Biggest MPI Misconception}
\addcontentsline{toc}{subsubsection}{7.2.1 The Biggest MPI Misconception}

Beginners often believe:
\begin{quote}
\emph{``MPI programs are many different programs.''}
\end{quote}

This is false.

MPI follows the:
\begin{quote}
\emph{Single Program, Multiple Data (SPMD)}
\end{quote}

All processes:
\begin{itemize}
  \item run the same executable
  \item start at \texttt{main()}
\end{itemize}

They behave differently based on identity.

% --------------------------------------------------
\subsubsection*{7.2.2 What Is an MPI Process?}
\addcontentsline{toc}{subsubsection}{7.2.2 What Is an MPI Process?}

An MPI process:
\begin{itemize}
  \item is an OS process
  \item has its own memory
  \item does not share variables
\end{itemize}

Key consequence:
\begin{quote}
\emph{Global variables are NOT shared.}
\end{quote}

This eliminates:
\begin{itemize}
  \item race conditions on memory
\end{itemize}

But requires explicit communication.

% --------------------------------------------------
\subsubsection*{7.2.3 Rank: Process Identity}
\addcontentsline{toc}{subsubsection}{7.2.3 Rank: Process Identity}

Each MPI process has:
\begin{itemize}
  \item a unique integer ID
\end{itemize}

This ID is called the:
\begin{quote}
\emph{Rank}
\end{quote}

Ranks:
\begin{itemize}
  \item start from 0
  \item go up to \texttt{size - 1}
\end{itemize}

Typical pattern:
\begin{itemize}
  \item rank 0 = coordinator
  \item other ranks = workers
\end{itemize}

This is a convention, not a rule.

% --------------------------------------------------
\subsubsection*{7.2.4 Communicators: Who Can Talk to Whom}
\addcontentsline{toc}{subsubsection}{7.2.4 Communicators: Who Can Talk to Whom}

MPI does not assume:
\begin{itemize}
  \item all processes communicate together
\end{itemize}

A \textbf{communicator} defines:
\begin{itemize}
  \item a group of processes
  \item a communication context
\end{itemize}

The default communicator is:
\begin{lstlisting}[language=C++]
MPI_COMM_WORLD
\end{lstlisting}

Meaning:
\begin{itemize}
  \item all processes launched together
\end{itemize}

Advanced programs create sub-communicators.

% --------------------------------------------------
\subsubsection*{7.2.5 Size: How Many Processes Exist}
\addcontentsline{toc}{subsubsection}{7.2.5 Size: How Many Processes Exist}

Every communicator has:
\begin{itemize}
  \item a size
\end{itemize}

Size means:
\begin{quote}
\emph{How many processes are in this communicator?}
\end{quote}

MPI programs often branch logic based on:
\begin{itemize}
  \item rank
  \item size
\end{itemize}

This replaces thread counts in OpenMP.

% --------------------------------------------------
\subsubsection*{7.2.6 The SPMD Pattern in Code}
\addcontentsline{toc}{subsubsection}{7.2.6 The SPMD Pattern in Code}

Typical MPI structure:
\begin{lstlisting}[language=C++]
int rank, size;

MPI_Comm_rank(MPI_COMM_WORLD, &rank);
MPI_Comm_size(MPI_COMM_WORLD, &size);

if (rank == 0) {
    // coordinator work
} else {
    // worker work
}
\end{lstlisting}

Same program.
Different behavior.

This is SPMD in practice.

% --------------------------------------------------
\subsubsection*{7.2.7 No Implicit Synchronization}
\addcontentsline{toc}{subsubsection}{7.2.7 No Implicit Synchronization}

Unlike OpenMP:
\begin{itemize}
  \item MPI has no implicit barriers
\end{itemize}

Processes run:
\begin{itemize}
  \item independently
\end{itemize}

Synchronization occurs only when:
\begin{itemize}
  \item messages are sent or received
\end{itemize}

This gives:
\begin{itemize}
  \item full control
  \item full responsibility
\end{itemize}

MPI assumes you know what you are doing.

% --------------------------------------------------
\subsubsection*{7.2.8 MPI Is Deterministic by Design}
\addcontentsline{toc}{subsubsection}{7.2.8 MPI Is Deterministic by Design}

MPI programs:
\begin{itemize}
  \item have no shared memory races
  \item behave deterministically given the same messages
\end{itemize}

Bugs come from:
\begin{itemize}
  \item wrong communication patterns
  \item mismatched sends/receives
\end{itemize}

This makes MPI debugging different from threads.

Harder to write.
Easier to reason about.

% --------------------------------------------------
\subsection*{Practice (Conceptual but Mandatory)}
\addcontentsline{toc}{subsection}{Practice (Lesson 7.2)}

\subsubsection*{Practice 1: Think Like Rank 3}

Assume:
\begin{itemize}
  \item size = 8
  \item your rank = 3
\end{itemize}

Answer:
\begin{itemize}
  \item Which code paths execute?
  \item What memory do you see?
\end{itemize}

This mindset is essential.

% --------------------------------------------------
\subsubsection*{Practice 2: Compare With OpenMP}

Ask:
\begin{itemize}
  \item What does rank replace from OpenMP?
  \item What replaces shared variables?
\end{itemize}

This comparison clarifies MPI deeply.

% --------------------------------------------------
\subsection*{Checkpoint Questions}
\addcontentsline{toc}{subsection}{Checkpoint Questions (Lesson 7.2)}

Answer carefully:

\begin{enumerate}
  \item What does SPMD mean?
  \item What is a rank?
  \item Why does MPI avoid shared memory?
\end{enumerate}
% ==================================================
\subsection*{Lesson 7.3: Your First MPI Program -- Hello World Across Processes}
\addcontentsline{toc}{subsection}{Lesson 7.3: Your First MPI Program -- Hello World Across Processes}

% --------------------------------------------------
\subsubsection*{7.3.1 What MPI Programs Look Like at Runtime}
\addcontentsline{toc}{subsubsection}{7.3.1 What MPI Programs Look Like at Runtime}

An MPI program is:
\begin{itemize}
  \item compiled once
  \item launched multiple times
\end{itemize}

Each launch creates:
\begin{itemize}
  \item one independent process
\end{itemize}

These processes:
\begin{itemize}
  \item run the same binary
  \item get different ranks
\end{itemize}

This is how parallelism is created in MPI.

% --------------------------------------------------
\subsubsection*{7.3.2 MPI Program Lifecycle}
\addcontentsline{toc}{subsubsection}{7.3.2 MPI Program Lifecycle}

Every MPI program follows this structure:

\begin{enumerate}
  \item Initialize MPI
  \item Query rank and size
  \item Do parallel work
  \item Finalize MPI
\end{enumerate}

Missing any of these steps is an error.

MPI is strict by design.

% --------------------------------------------------
\subsubsection*{7.3.3 Required MPI Calls}
\addcontentsline{toc}{subsubsection}{7.3.3 Required MPI Calls}

Minimal MPI calls:

\begin{lstlisting}[language=C++]
MPI_Init(&argc, &argv);
MPI_Comm_rank(MPI_COMM_WORLD, &rank);
MPI_Comm_size(MPI_COMM_WORLD, &size);
MPI_Finalize();
\end{lstlisting}

These four calls appear in almost every MPI program.

They define the MPI execution context.

% --------------------------------------------------
\subsubsection*{7.3.4 Your First MPI Program}
\addcontentsline{toc}{subsubsection}{7.3.4 Your First MPI Program}

Create file:
\begin{lstlisting}[language=bash]
nano mpi_hello.cpp
\end{lstlisting}

Write:
\begin{lstlisting}[language=C++]
#include <mpi.h>
#include <iostream>
using namespace std;

int main(int argc, char** argv) {

    MPI_Init(&argc, &argv);

    int rank, size;
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    MPI_Comm_size(MPI_COMM_WORLD, &size);

    cout << "Hello from rank " << rank
         << " out of " << size << endl;

    MPI_Finalize();
    return 0;
}
\end{lstlisting}

This is the simplest valid MPI program.

% --------------------------------------------------
\subsubsection*{7.3.5 Compiling an MPI Program}
\addcontentsline{toc}{subsubsection}{7.3.5 Compiling an MPI Program}

MPI programs must be compiled with:
\begin{itemize}
  \item \texttt{mpic++}
\end{itemize}

Compile using:
\begin{lstlisting}[language=bash]
mpic++ mpi_hello.cpp -o mpi_hello
\end{lstlisting}

Important:
\begin{itemize}
  \item \texttt{mpic++} is a wrapper
  \item it links MPI libraries correctly
\end{itemize}

Do not use plain \texttt{g++}.

% --------------------------------------------------
\subsubsection*{7.3.6 Running an MPI Program}
\addcontentsline{toc}{subsubsection}{7.3.6 Running an MPI Program}

MPI programs are launched using:
\begin{itemize}
  \item \texttt{mpirun} or \texttt{mpiexec}
\end{itemize}

Run with 4 processes:
\begin{lstlisting}[language=bash]
mpirun -np 4 ./mpi_hello
\end{lstlisting}

Expected output:
\begin{itemize}
  \item 4 lines
  \item one from each rank
  \item order not guaranteed
\end{itemize}

This is real parallel execution.

% --------------------------------------------------
\subsubsection*{7.3.7 Important Observations}
\addcontentsline{toc}{subsubsection}{7.3.7 Important Observations}

Key points:
\begin{itemize}
  \item each rank printed independently
  \item no shared variables exist
  \item output order is unpredictable
\end{itemize}

This unpredictability is due to:
\begin{itemize}
  \item OS scheduling
  \item process execution timing
\end{itemize}

Not race conditions.

% --------------------------------------------------
\subsubsection*{7.3.8 Rank-Based Control}
\addcontentsline{toc}{subsubsection}{7.3.8 Rank-Based Control}

Modify output:
\begin{lstlisting}[language=C++]
if (rank == 0) {
    cout << "I am the master" << endl;
} else {
    cout << "I am worker " << rank << endl;
}
\end{lstlisting}

This demonstrates:
\begin{itemize}
  \item conditional execution by rank
\end{itemize}

This pattern appears everywhere in MPI.

% --------------------------------------------------
\subsection*{Practice on Terminal (Mandatory)}
\addcontentsline{toc}{subsection}{Practice (Lesson 7.3)}

\subsubsection*{Practice 1: Vary Process Count}

Run:
\begin{lstlisting}[language=bash]
mpirun -np 2 ./mpi_hello
mpirun -np 8 ./mpi_hello
\end{lstlisting}

Observe:
\begin{itemize}
  \item how rank and size change
\end{itemize}

This confirms SPMD behavior.

% --------------------------------------------------
\subsubsection*{Practice 2: Think About Memory}

Add:
\begin{lstlisting}[language=C++]
int x = 10;
x += rank;
cout << "Rank " << rank << " has x = " << x << endl;
\end{lstlisting}

Ask:
\begin{itemize}
  \item Does this affect other ranks?
\end{itemize}

Answer:
\begin{itemize}
  \item No — memory is private
\end{itemize}

This is the MPI guarantee.

% --------------------------------------------------
\subsection*{Checkpoint Questions}
\addcontentsline{toc}{subsection}{Checkpoint Questions (Lesson 7.3)}

Answer clearly:

\begin{enumerate}
  \item Why must MPI programs be launched with \texttt{mpirun}?
  \item What does rank identify?
  \item Why is output order unpredictable but correct?
\end{enumerate}
% ==================================================
\subsection*{Lesson 7.4: Point-to-Point Communication -- MPI\_Send and MPI\_Recv}
\addcontentsline{toc}{subsection}{Lesson 7.4: Point-to-Point Communication -- MPI\_Send and MPI\_Recv}

% --------------------------------------------------
\subsubsection*{7.4.1 MPI Is About Messages, Not Memory}
\addcontentsline{toc}{subsubsection}{7.4.1 MPI Is About Messages, Not Memory}

In MPI:
\begin{itemize}
  \item processes do not share memory
  \item data moves only via messages
\end{itemize}

You must explicitly say:
\begin{itemize}
  \item who sends
  \item who receives
  \item what data
\end{itemize}

Nothing happens implicitly.

This explicitness is MPI’s strength.

% --------------------------------------------------
\subsubsection*{7.4.2 The Basic Send/Receive Model}
\addcontentsline{toc}{subsubsection}{7.4.2 The Basic Send/Receive Model}

The simplest communication pattern:
\begin{itemize}
  \item one process sends data
  \item another process receives data
\end{itemize}

MPI functions:
\begin{lstlisting}[language=C++]
MPI_Send(...)
MPI_Recv(...)
\end{lstlisting}

These are \textbf{blocking} calls by default.

Blocking means:
\begin{itemize}
  \item the call does not return immediately
\end{itemize}

% --------------------------------------------------
\subsubsection*{7.4.3 MPI\_Send Syntax (Conceptual)}
\addcontentsline{toc}{subsubsection}{7.4.3 MPI\_Send Syntax (Conceptual)}

Conceptual form:
\begin{lstlisting}[language=C++]
MPI_Send(buffer, count, datatype,
         destination, tag,
         communicator);
\end{lstlisting}

Meaning:
\begin{itemize}
  \item \texttt{buffer}: address of data
  \item \texttt{count}: number of elements
  \item \texttt{datatype}: MPI type
  \item \texttt{destination}: rank
  \item \texttt{tag}: message label
  \item \texttt{communicator}: group
\end{itemize}

Every field matters.

% --------------------------------------------------
\subsubsection*{7.4.4 MPI\_Recv Syntax (Conceptual)}
\addcontentsline{toc}{subsubsection}{7.4.4 MPI\_Recv Syntax (Conceptual)}

Conceptual form:
\begin{lstlisting}[language=C++]
MPI_Recv(buffer, count, datatype,
         source, tag,
         communicator, status);
\end{lstlisting}

Important:
\begin{itemize}
  \item receive must match send
  \item source and tag must agree
\end{itemize}

If no matching send exists:
\begin{itemize}
  \item program waits forever
\end{itemize}

This is how MPI deadlocks occur.

% --------------------------------------------------
\subsubsection*{7.4.5 Your First Send/Receive Example}
\addcontentsline{toc}{subsubsection}{7.4.5 Your First Send/Receive Example}

Goal:
\begin{itemize}
  \item rank 0 sends an integer
  \item rank 1 receives it
\end{itemize}

Create file:
\begin{lstlisting}[language=bash]
nano mpi_send_recv.cpp
\end{lstlisting}

Write:
\begin{lstlisting}[language=C++]
#include <mpi.h>
#include <iostream>
using namespace std;

int main(int argc, char** argv) {

    MPI_Init(&argc, &argv);

    int rank;
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);

    int value;

    if (rank == 0) {
        value = 42;
        MPI_Send(&value, 1, MPI_INT, 1, 0, MPI_COMM_WORLD);
        cout << "Rank 0 sent value " << value << endl;
    }
    else if (rank == 1) {
        MPI_Recv(&value, 1, MPI_INT, 0, 0,
                 MPI_COMM_WORLD, MPI_STATUS_IGNORE);
        cout << "Rank 1 received value " << value << endl;
    }

    MPI_Finalize();
    return 0;
}
\end{lstlisting}

Compile:
\begin{lstlisting}[language=bash]
mpic++ mpi_send_recv.cpp -o mpi_send_recv
\end{lstlisting}

Run:
\begin{lstlisting}[language=bash]
mpirun -np 2 ./mpi_send_recv
\end{lstlisting}

This is your first real message passing.

% --------------------------------------------------
\subsubsection*{7.4.6 Why Tags Exist}
\addcontentsline{toc}{subsubsection}{7.4.6 Why Tags Exist}

The \texttt{tag}:
\begin{itemize}
  \item labels messages
  \item distinguishes multiple messages
\end{itemize}

Example:
\begin{itemize}
  \item tag 0: data
  \item tag 1: control
\end{itemize}

Tags prevent:
\begin{itemize}
  \item message confusion
\end{itemize}

They are cheap and powerful.

% --------------------------------------------------
\subsubsection*{7.4.7 Blocking Semantics (Very Important)}
\addcontentsline{toc}{subsubsection}{7.4.7 Blocking Semantics (Very Important)}

\texttt{MPI\_Send} blocks until:
\begin{itemize}
  \item the send buffer is safe to reuse
\end{itemize}

\texttt{MPI\_Recv} blocks until:
\begin{itemize}
  \item the message is received
\end{itemize}

Blocking does NOT mean:
\begin{itemize}
  \item data has reached destination memory
\end{itemize}

It means:
\begin{itemize}
  \item MPI guarantees correctness
\end{itemize}

Understanding this avoids subtle bugs.

% --------------------------------------------------
\subsubsection*{7.4.8 A Classic MPI Deadlock}
\addcontentsline{toc}{subsubsection}{7.4.8 A Classic MPI Deadlock}

Consider two ranks:

Rank 0:
\begin{lstlisting}[language=C++]
MPI_Send(..., 1);
MPI_Recv(..., 1);
\end{lstlisting}

Rank 1:
\begin{lstlisting}[language=C++]
MPI_Send(..., 0);
MPI_Recv(..., 0);
\end{lstlisting}

Both ranks:
\begin{itemize}
  \item try to send first
  \item wait forever
\end{itemize}

This is an MPI deadlock.

MPI requires careful ordering.

% --------------------------------------------------
\subsubsection*{7.4.9 How to Avoid Send/Recv Deadlocks}
\addcontentsline{toc}{subsubsection}{7.4.9 How to Avoid Send/Recv Deadlocks}

Common strategies:
\begin{itemize}
  \item enforce send/receive order
  \item alternate roles by rank
  \item use combined operations
\end{itemize}

Rule of thumb:
\begin{quote}
\emph{Every send must have a matching receive.}
\end{quote}

And the order must be compatible.

% --------------------------------------------------
\subsection*{Practice on Terminal (Mandatory)}
\addcontentsline{toc}{subsection}{Practice (Lesson 7.4)}

\subsubsection*{Practice 1: Break It on Purpose}

Modify code so:
\begin{itemize}
  \item both ranks call \texttt{MPI\_Send} first
\end{itemize}

Run and observe:
\begin{itemize}
  \item program hangs
\end{itemize}

This is a real MPI deadlock.

% --------------------------------------------------
\subsubsection*{Practice 2: Fix the Deadlock}

Fix by:
\begin{itemize}
  \item rank 0 sends then receives
  \item rank 1 receives then sends
\end{itemize}

Re-run and verify correctness.

This pattern appears constantly in MPI.

% --------------------------------------------------
\subsection*{Checkpoint Questions}
\addcontentsline{toc}{subsection}{Checkpoint Questions (Lesson 7.4)}

Answer carefully:

\begin{enumerate}
  \item Why must sends and receives match exactly?
  \item What does blocking mean in MPI?
  \item How do MPI deadlocks differ from thread deadlocks?
\end{enumerate}
% ==================================================
\subsection*{Lesson 7.5: Collective Communication -- MPI\_Bcast and MPI\_Reduce}
\addcontentsline{toc}{subsection}{Lesson 7.5: Collective Communication -- MPI\_Bcast and MPI\_Reduce}

% --------------------------------------------------
\subsubsection*{7.5.1 Why Collective Communication Exists}
\addcontentsline{toc}{subsubsection}{7.5.1 Why Collective Communication Exists}

Using only \texttt{MPI\_Send} and \texttt{MPI\_Recv}:
\begin{itemize}
  \item is verbose
  \item is error-prone
  \item does not scale well
\end{itemize}

Many common patterns involve:
\begin{itemize}
  \item one-to-many communication
  \item many-to-one communication
\end{itemize}

MPI provides \textbf{collective operations} to express these patterns clearly.

% --------------------------------------------------
\subsubsection*{7.5.2 What Does ``Collective'' Mean?}
\addcontentsline{toc}{subsubsection}{7.5.2 What Does ``Collective'' Mean?}

A collective operation:
\begin{itemize}
  \item involves \textbf{all processes} in a communicator
  \item must be called by \textbf{every rank}
\end{itemize}

Important rule:
\begin{quote}
\emph{If one rank skips a collective call, the program will hang.}
\end{quote}

Collectives are:
\begin{itemize}
  \item blocking
  \item synchronized by design
\end{itemize}

% --------------------------------------------------
\subsubsection*{7.5.3 Broadcasting Data: MPI\_Bcast}
\addcontentsline{toc}{subsubsection}{7.5.3 Broadcasting Data: MPI\_Bcast}

Problem:
\begin{itemize}
  \item rank 0 has data
  \item all ranks need the same data
\end{itemize}

Naive solution:
\begin{itemize}
  \item rank 0 sends data to each rank manually
\end{itemize}

Correct MPI solution:
\begin{lstlisting}[language=C++]
MPI_Bcast(buffer, count, datatype, root, communicator);
\end{lstlisting}

This sends data:
\begin{itemize}
  \item from root
  \item to all ranks
\end{itemize}

Efficient and safe.

% --------------------------------------------------
\subsubsection*{7.5.4 Example: Broadcasting a Value}
\addcontentsline{toc}{subsubsection}{7.5.4 Example: Broadcasting a Value}

Create file:
\begin{lstlisting}[language=bash]
nano mpi_bcast.cpp
\end{lstlisting}

Write:
\begin{lstlisting}[language=C++]
#include <mpi.h>
#include <iostream>
using namespace std;

int main(int argc, char** argv) {

    MPI_Init(&argc, &argv);

    int rank;
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);

    int x;

    if (rank == 0) {
        x = 100;
        cout << "Rank 0 initialized x = " << x << endl;
    }

    MPI_Bcast(&x, 1, MPI_INT, 0, MPI_COMM_WORLD);

    cout << "Rank " << rank << " sees x = " << x << endl;

    MPI_Finalize();
    return 0;
}
\end{lstlisting}

Compile and run:
\begin{lstlisting}[language=bash]
mpic++ mpi_bcast.cpp -o mpi_bcast
mpirun -np 4 ./mpi_bcast
\end{lstlisting}

Observe:
\begin{itemize}
  \item all ranks receive the same value
\end{itemize}

% --------------------------------------------------
\subsubsection*{7.5.5 Why MPI\_Bcast Is Better Than Manual Sends}
\addcontentsline{toc}{subsubsection}{7.5.5 Why MPI\_Bcast Is Better Than Manual Sends}

Advantages:
\begin{itemize}
  \item fewer lines of code
  \item no deadlock risk
  \item optimized internally (tree-based)
\end{itemize}

MPI libraries use:
\begin{itemize}
  \item hardware-aware algorithms
\end{itemize}

Manual sends cannot match this performance.

% --------------------------------------------------
\subsubsection*{7.5.6 Combining Values: MPI\_Reduce}
\addcontentsline{toc}{subsubsection}{7.5.6 Combining Values: MPI\_Reduce}

Problem:
\begin{itemize}
  \item each rank computes a partial value
  \item one rank needs the final result
\end{itemize}

Solution:
\begin{lstlisting}[language=C++]
MPI_Reduce(sendbuf, recvbuf, count,
           datatype, operation,
           root, communicator);
\end{lstlisting}

This:
\begin{itemize}
  \item combines values from all ranks
  \item applies an operation
  \item delivers result to root
\end{itemize}

This mirrors OpenMP reductions.

% --------------------------------------------------
\subsubsection*{7.5.7 Example: Parallel Sum with MPI\_Reduce}
\addcontentsline{toc}{subsubsection}{7.5.7 Example: Parallel Sum with MPI\_Reduce}

Create file:
\begin{lstlisting}[language=bash]
nano mpi_reduce.cpp
\end{lstlisting}

Write:
\begin{lstlisting}[language=C++]
#include <mpi.h>
#include <iostream>
using namespace std;

int main(int argc, char** argv) {

    MPI_Init(&argc, &argv);

    int rank, size;
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    MPI_Comm_size(MPI_COMM_WORLD, &size);

    int local = rank + 1;
    int global_sum = 0;

    MPI_Reduce(&local, &global_sum, 1,
               MPI_INT, MPI_SUM,
               0, MPI_COMM_WORLD);

    if (rank == 0) {
        cout << "Global sum = " << global_sum << endl;
    }

    MPI_Finalize();
    return 0;
}
\end{lstlisting}

Compile and run:
\begin{lstlisting}[language=bash]
mpic++ mpi_reduce.cpp -o mpi_reduce
mpirun -np 4 ./mpi_reduce
\end{lstlisting}

Expected result:
\[
1 + 2 + 3 + 4 = 10
\]

% --------------------------------------------------
\subsubsection*{7.5.8 Common Reduction Operations}
\addcontentsline{toc}{subsubsection}{7.5.8 Common Reduction Operations}

MPI supports:
\begin{itemize}
  \item \texttt{MPI\_SUM}
  \item \texttt{MPI\_MAX}
  \item \texttt{MPI\_MIN}
  \item \texttt{MPI\_PROD}
\end{itemize}

Operations must be:
\begin{itemize}
  \item associative
\end{itemize}

Just like OpenMP reductions.

% --------------------------------------------------
\subsubsection*{7.5.9 MPI\_Allreduce: Everyone Gets the Result}
\addcontentsline{toc}{subsubsection}{7.5.9 MPI\_Allreduce: Everyone Gets the Result}

Sometimes:
\begin{itemize}
  \item all ranks need the reduced value
\end{itemize}

Use:
\begin{lstlisting}[language=C++]
MPI_Allreduce(...)
\end{lstlisting}

This:
\begin{itemize}
  \item performs reduction
  \item broadcasts result to all ranks
\end{itemize}

Very common in iterative solvers.

% --------------------------------------------------
\subsection*{Practice on Terminal (Mandatory)}
\addcontentsline{toc}{subsection}{Practice (Lesson 7.5)}

\subsubsection*{Practice 1: Break the Rule}

Comment out \texttt{MPI\_Bcast} on one rank only.

Run and observe:
\begin{itemize}
  \item program hangs
\end{itemize}

This demonstrates:
\begin{itemize}
  \item collectives require participation from all ranks
\end{itemize}

% --------------------------------------------------
\subsubsection*{Practice 2: Replace Manual Communication}

Rewrite a program that:
\begin{itemize}
  \item sends values manually
\end{itemize}

Replace with:
\begin{itemize}
  \item \texttt{MPI\_Bcast} or \texttt{MPI\_Reduce}
\end{itemize}

Observe:
\begin{itemize}
  \item simpler code
  \item fewer bugs
\end{itemize}

% --------------------------------------------------
\subsection*{Checkpoint Questions}
\addcontentsline{toc}{subsection}{Checkpoint Questions (Lesson 7.5)}

Answer carefully:

\begin{enumerate}
  \item What makes a collective different from point-to-point?
  \item Why must all ranks call collectives?
  \item How does \texttt{MPI\_Reduce} mirror OpenMP reductions?
\end{enumerate}
% ==================================================
\section*{PART 8: Hybrid Parallelism -- Real HPC Thinking}
\addcontentsline{toc}{section}{PART 8: Hybrid Parallelism -- Real HPC Thinking}

\subsection*{Lesson 8.1: MPI + OpenMP -- Scaling Across Nodes and Cores}
\addcontentsline{toc}{subsection}{Lesson 8.1: MPI + OpenMP -- Scaling Across Nodes and Cores}

% --------------------------------------------------
\subsubsection*{8.1.1 The Reality of Modern Supercomputers}
\addcontentsline{toc}{subsubsection}{8.1.1 The Reality of Modern Supercomputers}

Modern supercomputers are:
\begin{itemize}
  \item clusters of nodes
  \item each node has many cores
\end{itemize}

Inside a node:
\begin{itemize}
  \item shared memory
\end{itemize}

Across nodes:
\begin{itemize}
  \item distributed memory
\end{itemize}

No single model is sufficient.

% --------------------------------------------------
\subsubsection*{8.1.2 Why Pure MPI Is Not Enough}
\addcontentsline{toc}{subsubsection}{8.1.2 Why Pure MPI Is Not Enough}

Using only MPI:
\begin{itemize}
  \item one MPI process per core
\end{itemize}

Problems:
\begin{itemize}
  \item too many processes
  \item memory duplication
  \item expensive intra-node communication
\end{itemize}

MPI is excellent across nodes.
It is inefficient inside a node.

% --------------------------------------------------
\subsubsection*{8.1.3 Why Pure OpenMP Is Not Enough}
\addcontentsline{toc}{subsubsection}{8.1.3 Why Pure OpenMP Is Not Enough}

Using only OpenMP:
\begin{itemize}
  \item limited to one node
\end{itemize}

Problems:
\begin{itemize}
  \item cannot scale across machines
  \item limited by memory wall
\end{itemize}

OpenMP is excellent inside a node.
It cannot cross node boundaries.

% --------------------------------------------------
\subsubsection*{8.1.4 The Hybrid Solution}
\addcontentsline{toc}{subsubsection}{8.1.4 The Hybrid Solution}

Hybrid programming uses:
\begin{itemize}
  \item MPI across nodes
  \item OpenMP inside nodes
\end{itemize}

Structure:
\begin{itemize}
  \item MPI rank per node (or per socket)
  \item OpenMP threads per rank
\end{itemize}

This matches hardware topology.

% --------------------------------------------------
\subsubsection*{8.1.5 The Mental Model}
\addcontentsline{toc}{subsubsection}{8.1.5 The Mental Model}

Think in two levels:

\textbf{Level 1 (MPI)}:
\begin{itemize}
  \item distribute data across nodes
  \item communicate coarse-grained data
\end{itemize}

\textbf{Level 2 (OpenMP)}:
\begin{itemize}
  \item parallelize loops locally
  \item exploit shared memory
\end{itemize}

Never mix the responsibilities.

% --------------------------------------------------
\subsubsection*{8.1.6 Hybrid Program Skeleton}
\addcontentsline{toc}{subsubsection}{8.1.6 Hybrid Program Skeleton}

Typical hybrid structure:
\begin{lstlisting}[language=C++]
#include <mpi.h>
#include <omp.h>

int main(int argc, char** argv) {

    MPI_Init(&argc, &argv);

    int rank, size;
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    MPI_Comm_size(MPI_COMM_WORLD, &size);

#pragma omp parallel
    {
        int tid = omp_get_thread_num();
        // OpenMP work here
    }

    MPI_Finalize();
    return 0;
}
\end{lstlisting}

MPI and OpenMP coexist cleanly.

% --------------------------------------------------
\subsubsection*{8.1.7 Data Decomposition Strategy}
\addcontentsline{toc}{subsubsection}{8.1.7 Data Decomposition Strategy}

Correct decomposition:
\begin{itemize}
  \item MPI divides the global problem
  \item OpenMP divides local chunks
\end{itemize}

Example:
\begin{itemize}
  \item MPI rank gets block of rows
  \item OpenMP parallelizes rows locally
\end{itemize}

Never:
\begin{itemize}
  \item communicate inside tight OpenMP loops
\end{itemize}

Communication is expensive.

% --------------------------------------------------
\subsubsection*{8.1.8 Environment Control}
\addcontentsline{toc}{subsubsection}{8.1.8 Environment Control}

Hybrid execution uses:
\begin{itemize}
  \item MPI process count
  \item OpenMP thread count
\end{itemize}

Example:
\begin{lstlisting}[language=bash]
export OMP_NUM_THREADS=8
mpirun -np 4 ./hybrid_program
\end{lstlisting}

This launches:
\begin{itemize}
  \item 4 MPI ranks
  \item each with 8 OpenMP threads
\end{itemize}

Total cores used = 32.

% --------------------------------------------------
\subsubsection*{8.1.9 Common Hybrid Mistakes}
\addcontentsline{toc}{subsubsection}{8.1.9 Common Hybrid Mistakes}

Avoid:
\begin{itemize}
  \item too many MPI ranks per node
  \item oversubscribing cores
  \item nested parallelism accidentally
\end{itemize}

Rule:
\begin{quote}
\emph{Map software parallelism to hardware hierarchy.}
\end{quote}

This is real HPC thinking.

% --------------------------------------------------
\subsection*{Practice (Conceptual but Mandatory)}
\addcontentsline{toc}{subsection}{Practice (Lesson 8.1)}

\subsubsection*{Practice 1: Hardware Mapping}

Assume:
\begin{itemize}
  \item 1 node has 32 cores
\end{itemize}

Design:
\begin{itemize}
  \item MPI ranks per node
  \item OpenMP threads per rank
\end{itemize}

Justify your choice.

% --------------------------------------------------
\subsubsection*{Practice 2: TA-Level Explanation}

Explain to a student:
\begin{itemize}
  \item why MPI + OpenMP is better than either alone
\end{itemize}

If you can explain this clearly, you are TA-ready.

% --------------------------------------------------
\subsection*{Checkpoint Questions}
\addcontentsline{toc}{subsection}{Checkpoint Questions (Lesson 8.1)}

Answer clearly:

\begin{enumerate}
  \item Why do real systems need hybrid parallelism?
  \item What problem does MPI solve that OpenMP cannot?
  \item Why should communication stay outside OpenMP loops?
\end{enumerate}
% ==================================================
\subsection*{Lesson 8.2: Performance Thinking, Profiling, and Scaling}
\addcontentsline{toc}{subsection}{Lesson 8.2: Performance Thinking, Profiling, and Scaling}

% --------------------------------------------------
\subsubsection*{8.2.1 Correct $\neq$ Fast}
\addcontentsline{toc}{subsubsection}{8.2.1 Correct $\neq$ Fast}

A common beginner mistake:
\begin{quote}
\emph{``My parallel code runs, so it must be fast.''}
\end{quote}

Reality:
\begin{itemize}
  \item parallel code can be slower than sequential
  \item overhead can dominate computation
\end{itemize}

Performance is:
\begin{quote}
\emph{A quantitative property, not a feeling.}
\end{quote}

It must be measured.

% --------------------------------------------------
\subsubsection*{8.2.2 Where Time Really Goes}
\addcontentsline{toc}{subsubsection}{8.2.2 Where Time Really Goes}

Execution time comes from:
\begin{itemize}
  \item computation
  \item memory access
  \item synchronization
  \item communication
\end{itemize}

Parallel programs often fail because of:
\begin{itemize}
  \item too much synchronization
  \item too much communication
  \item poor data locality
\end{itemize}

Speedup is lost here.

% --------------------------------------------------
\subsubsection*{8.2.3 Measuring Time Properly}
\addcontentsline{toc}{subsubsection}{8.2.3 Measuring Time Properly}

Never measure performance using:
\begin{itemize}
  \item print statements
  \item intuition
\end{itemize}

Use timers.

OpenMP timer:
\begin{lstlisting}[language=C++]
double t0 = omp_get_wtime();
// work
double t1 = omp_get_wtime();
\end{lstlisting}

MPI timer:
\begin{lstlisting}[language=C++]
double t0 = MPI_Wtime();
// work
double t1 = MPI_Wtime();
\end{lstlisting}

Always:
\begin{itemize}
  \item measure only the computation region
\end{itemize}

% --------------------------------------------------
\subsubsection*{8.2.4 Speedup and Efficiency}
\addcontentsline{toc}{subsubsection}{8.2.4 Speedup and Efficiency}

Definitions:

Speedup:
\[
S(p) = \frac{T(1)}{T(p)}
\]

Efficiency:
\[
E(p) = \frac{S(p)}{p}
\]

Where:
\begin{itemize}
  \item $T(1)$ = time on 1 core
  \item $T(p)$ = time on $p$ cores
\end{itemize}

Perfect scaling:
\begin{itemize}
  \item $S(p) = p$
  \item $E(p) = 1$
\end{itemize}

This almost never happens in practice.

% --------------------------------------------------
\subsubsection*{8.2.5 Strong Scaling}
\addcontentsline{toc}{subsubsection}{8.2.5 Strong Scaling}

Strong scaling asks:
\begin{quote}
\emph{What happens if I fix the problem size and increase cores?}
\end{quote}

Goal:
\begin{itemize}
  \item solve the same problem faster
\end{itemize}

Limitation:
\begin{itemize}
  \item serial fraction (Amdahl’s Law)
\end{itemize}

Strong scaling always saturates.

This reveals synchronization and communication overheads.

% --------------------------------------------------
\subsubsection*{8.2.6 Weak Scaling}
\addcontentsline{toc}{subsubsection}{8.2.6 Weak Scaling}

Weak scaling asks:
\begin{quote}
\emph{What happens if I increase problem size with cores?}
\end{quote}

Goal:
\begin{itemize}
  \item constant work per core
\end{itemize}

Ideal weak scaling:
\begin{itemize}
  \item runtime stays constant
\end{itemize}

Weak scaling is often:
\begin{itemize}
  \item more relevant for large simulations
\end{itemize}

Supercomputers are designed for weak scaling.

% --------------------------------------------------
\subsubsection*{8.2.7 Interpreting Scaling Results}
\addcontentsline{toc}{subsubsection}{8.2.7 Interpreting Scaling Results}

If strong scaling is poor:
\begin{itemize}
  \item too much synchronization
  \item too fine-grained parallelism
\end{itemize}

If weak scaling is poor:
\begin{itemize}
  \item communication grows too fast
  \item bad data decomposition
\end{itemize}

Scaling curves diagnose design flaws.

% --------------------------------------------------
\subsubsection*{8.2.8 Profiling vs Timing}
\addcontentsline{toc}{subsubsection}{8.2.8 Profiling vs Timing}

Timing tells:
\begin{itemize}
  \item how long
\end{itemize}

Profiling tells:
\begin{itemize}
  \item where time is spent
\end{itemize}

Common profiling questions:
\begin{itemize}
  \item which function dominates?
  \item where is communication expensive?
\end{itemize}

Real HPC work always profiles.

% --------------------------------------------------
\subsubsection*{8.2.9 The TA Mindset}
\addcontentsline{toc}{subsubsection}{8.2.9 The TA Mindset}

As a TA, always push students to:
\begin{itemize}
  \item measure before optimizing
  \item explain performance with reasoning
\end{itemize}

Correct answer is not:
\begin{quote}
\emph{``It is slow.''}
\end{quote}

Correct answer is:
\begin{quote}
\emph{``It is slow because communication dominates beyond 8 cores.''}
\end{quote}

This is scientific thinking.

% --------------------------------------------------
\subsection*{Practice (Mandatory)}
\addcontentsline{toc}{subsection}{Practice (Lesson 8.2)}

\subsubsection*{Practice 1: Strong Scaling Experiment}

Take any OpenMP loop.

Measure runtime for:
\begin{itemize}
  \item 1, 2, 4, 8 threads
\end{itemize}

Plot:
\begin{itemize}
  \item speedup vs threads
\end{itemize}

Explain:
\begin{itemize}
  \item where scaling saturates
\end{itemize}

% --------------------------------------------------
\subsubsection*{Practice 2: Weak Scaling Thought Experiment}

Imagine:
\begin{itemize}
  \item doubling problem size with cores
\end{itemize}

Ask:
\begin{itemize}
  \item what communication patterns break weak scaling?
\end{itemize}

Answering this correctly shows maturity.

% --------------------------------------------------
\subsection*{Checkpoint Questions}
\addcontentsline{toc}{subsection}{Checkpoint Questions (Lesson 8.2)}

Answer clearly:

\begin{enumerate}
  \item What is the difference between strong and weak scaling?
  \item Why does strong scaling always saturate?
  \item Why is profiling more informative than timing alone?
\end{enumerate}
% ==================================================
\subsection*{Lesson 8.3: Common Student Mistakes \& How to Teach Parallel Computing}
\addcontentsline{toc}{subsection}{Lesson 8.3: Common Student Mistakes \& How to Teach Parallel Computing}

% --------------------------------------------------
\subsubsection*{8.3.1 The Root Problem: Sequential Thinking}
\addcontentsline{toc}{subsubsection}{8.3.1 The Root Problem: Sequential Thinking}

The most common student mistake is:
\begin{quote}
\emph{Thinking sequentially while writing parallel code.}
\end{quote}

Symptoms:
\begin{itemize}
  \item assuming fixed execution order
  \item assuming shared variables are ``safe''
  \item expecting reproducible output order
\end{itemize}

As a TA, you must attack the \textbf{mental model}, not the syntax.

% --------------------------------------------------
\subsubsection*{8.3.2 Mistake \#1: ``Output Order Is Wrong''}
\addcontentsline{toc}{subsubsection}{8.3.2 Mistake \#1: ``Output Order Is Wrong''}

Students often complain:
\begin{quote}
\emph{``My output order is wrong in parallel code.''}
\end{quote}

Truth:
\begin{itemize}
  \item parallel programs do not guarantee order
\end{itemize}

Teaching strategy:
\begin{itemize}
  \item explain that order was never specified
  \item show that correctness $\neq$ ordering
\end{itemize}

Golden line to say:
\begin{quote}
\emph{``If you want order, you must program order.''}
\end{quote}

% --------------------------------------------------
\subsubsection*{8.3.3 Mistake \#2: Shared Temporary Variables}
\addcontentsline{toc}{subsubsection}{8.3.3 Mistake \#2: Shared Temporary Variables}

Classic bug:
\begin{lstlisting}[language=C++]
int temp;
#pragma omp parallel for
for (...) {
    temp = ...
    ...
}
\end{lstlisting}

Problem:
\begin{itemize}
  \item \texttt{temp} is shared
\end{itemize}

Teaching strategy:
\begin{itemize}
  \item draw memory boxes
  \item show one variable, many threads
\end{itemize}

Fix:
\begin{itemize}
  \item \texttt{private(temp)}
\end{itemize}

This visual explanation works every time.

% --------------------------------------------------
\subsubsection*{8.3.4 Mistake \#3: ``Locks Fix Everything''}
\addcontentsline{toc}{subsubsection}{8.3.4 Mistake \#3: ``Locks Fix Everything''}

Students often:
\begin{itemize}
  \item add locks everywhere
\end{itemize}

Result:
\begin{itemize}
  \item correct but slow code
\end{itemize}

Teaching strategy:
\begin{itemize}
  \item show performance collapse
  \item compare with reductions
\end{itemize}

Golden rule:
\begin{quote}
\emph{Locks are correctness tools, not performance tools.}
\end{quote}

% --------------------------------------------------
\subsubsection*{8.3.5 Mistake \#4: Confusing Threads and Processes}
\addcontentsline{toc}{subsubsection}{8.3.5 Mistake \#4: Confusing Threads and Processes}

Students confuse:
\begin{itemize}
  \item OpenMP threads
  \item MPI processes
\end{itemize}

Symptoms:
\begin{itemize}
  \item expecting MPI ranks to share memory
  \item using global variables incorrectly
\end{itemize}

Teaching strategy:
\begin{itemize}
  \item repeat: ``MPI has no shared memory''
  \item force students to predict outputs
\end{itemize}

Prediction exercises expose misunderstandings immediately.

% --------------------------------------------------
\subsubsection*{8.3.6 Mistake \#5: Ignoring Scaling}
\addcontentsline{toc}{subsubsection}{8.3.6 Mistake \#5: Ignoring Scaling}

Students often:
\begin{itemize}
  \item test only on 2 threads
  \item declare success
\end{itemize}

Teaching strategy:
\begin{itemize}
  \item require scaling plots
  \item ask ``why does it stop scaling?''
\end{itemize}

This turns coding into scientific analysis.

% --------------------------------------------------
\subsubsection*{8.3.7 How to Answer Student Questions Properly}
\addcontentsline{toc}{subsubsection}{8.3.7 How to Answer Student Questions Properly}

Bad TA answer:
\begin{quote}
\emph{``Just add a lock.''}
\end{quote}

Good TA answer:
\begin{quote}
\emph{``Which variable is shared? Which operation must be atomic? Can we restructure?''}
\end{quote}

Always redirect students to:
\begin{itemize}
  \item reasoning
  \item structure
\end{itemize}

Not copy-paste fixes.

% --------------------------------------------------
\subsubsection*{8.3.8 Teaching Order for Maximum Clarity}
\addcontentsline{toc}{subsubsection}{8.3.8 Teaching Order for Maximum Clarity}

Recommended order (never skip):
\begin{enumerate}
  \item Sequential correctness
  \item Task/data decomposition
  \item Parallel hazards
  \item Synchronization
  \item Performance
\end{enumerate}

Skipping steps causes fear and confusion.

You followed this order correctly.

% --------------------------------------------------
\subsubsection*{8.3.9 The Calm Authority Mindset}
\addcontentsline{toc}{subsubsection}{8.3.9 The Calm Authority Mindset}

As a TA:
\begin{itemize}
  \item never blame the student
  \item blame the model
\end{itemize}

Say:
\begin{quote}
\emph{``Your code is reasonable for sequential thinking. Now let's upgrade the model.''}
\end{quote}

This builds confidence instead of fear.

% --------------------------------------------------
\subsection*{Practice (Mandatory for TA Readiness)}
\addcontentsline{toc}{subsection}{Practice (Lesson 8.3)}

\subsubsection*{Practice 1: Diagnose a Bug}

Given:
\begin{itemize}
  \item wrong OpenMP output
\end{itemize}

Ask students:
\begin{itemize}
  \item which variable is shared?
  \item which operation is unsafe?
\end{itemize}

Do not fix immediately.
Force reasoning.

% --------------------------------------------------
\subsubsection*{Practice 2: Explain Without Code}

Explain to a student:
\begin{itemize}
  \item why MPI avoids race conditions by design
\end{itemize}

If you can do this verbally, you truly understand it.

% --------------------------------------------------
\subsection*{Checkpoint Questions}
\addcontentsline{toc}{subsection}{Checkpoint Questions (Lesson 8.3)}

Answer clearly:

\begin{enumerate}
  \item What is the most common student mental mistake?
  \item Why are locks overused by beginners?
  \item How should a TA respond to confusion?
\end{enumerate}

\end{document}